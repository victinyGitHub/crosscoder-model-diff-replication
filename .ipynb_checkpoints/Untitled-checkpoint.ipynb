{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a684e6b2-5b58-48fe-abef-bad304d8615e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "from utils import *\n",
    "from crosscoder import CrossCoder\n",
    "torch.set_grad_enabled(False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf6b0c9-5e3b-4dd7-831e-a7a34698833a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "cross_coder = CrossCoder.load_from_hf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7113799a-b8a7-4783-b7b5-fe2beffee6cc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84ba269b-3491-44da-95ce-702d2a9ba0ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "norms = cross_coder.W_dec.norm(dim=-1)\n",
    "norms.shape\n",
    "# %%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71d724b9-6889-42fe-86bd-2df7f661f429",
   "metadata": {},
   "outputs": [],
   "source": [
    "relative_norms = norms[:, 1] / norms.sum(dim=-1)\n",
    "relative_norms.shape\n",
    "# %%\n",
    "\n",
    "fig = px.histogram(\n",
    "    relative_norms.detach().cpu().numpy(), \n",
    "    title=\"Gemma 2 2B Base vs IT Model Diff\",\n",
    "    labels={\"value\": \"Relative decoder norm strength\"},\n",
    "    nbins=200,\n",
    ")\n",
    "\n",
    "fig.update_layout(showlegend=False)\n",
    "fig.update_yaxes(title_text=\"Number of Latents\")\n",
    "\n",
    "# Update x-axis ticks\n",
    "fig.update_xaxes(\n",
    "    tickvals=[0, 0.25, 0.5, 0.75, 1.0],\n",
    "    ticktext=['0', '0.25', '0.5', '0.75', '1.0']\n",
    ")\n",
    "\n",
    "# Save instead of show\n",
    "fig.write_image(\"plot1_histogram.png\")\n",
    "\n",
    "# %%\n",
    "shared_latent_mask = (relative_norms < 0.7) & (relative_norms > 0.3)\n",
    "shared_latent_mask.shape\n",
    "# %%\n",
    "# Cosine similarity of recoder vectors between models\n",
    "\n",
    "cosine_sims = (cross_coder.W_dec[:, 0, :] * cross_coder.W_dec[:, 1, :]).sum(dim=-1) / (cross_coder.W_dec[:, 0, :].norm(dim=-1) * cross_coder.W_dec[:, 1, :].norm(dim=-1))\n",
    "cosine_sims.shape\n",
    "# %%\n",
    "\n",
    "fig = px.histogram(\n",
    "    cosine_sims[shared_latent_mask].to(torch.float32).detach().cpu().numpy(), \n",
    "    log_y=True,  # Sets the y-axis to log scale\n",
    "    range_x=[-1, 1],  # Sets the x-axis range from -1 to 1\n",
    "    nbins=100,  # Adjust this value to change the number of bins\n",
    "    labels={\"value\": \"Cosine similarity of decoder vectors between models\"}\n",
    ")\n",
    "\n",
    "fig.update_layout(showlegend=False)\n",
    "fig.update_yaxes(title_text=\"Number of Latents (log scale)\")\n",
    "\n",
    "# Save instead of show\n",
    "fig.write_image(\"plot2_cosine_similarity.png\")\n",
    "\n",
    "# %%"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
