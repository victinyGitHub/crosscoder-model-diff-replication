{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a684e6b2-5b58-48fe-abef-bad304d8615e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# %%\n",
    "from utils import *\n",
    "from crosscoder import CrossCoder\n",
    "torch.set_grad_enabled(False);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5200a308-101a-4885-8d76-6be92001d4e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pythia19m 30vs60 checkpoint crosscoder\n",
    "# repo_id: str = \"victiny1223/crosscoder-checkpoints\"\n",
    "# currently hardcoded. need to change later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2bf6b0c9-5e3b-4dd7-831e-a7a34698833a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2bd70f7e2e7148c69729e7a950300b0d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "checkpoints/version_12/5_cfg.json:   0%|          | 0.00/521 [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "2753446e50a64b2b9a6e5c8c6ddbfc9d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "5.pt:   0%|          | 0.00/134M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/crosscoders/crosscoder-model-diff-replication/crosscoder.py:201: FutureWarning:\n",
      "\n",
      "You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# %%\n",
    "repo_id = \"victiny1223/crosscoder-checkpoints\"\n",
    "\n",
    "cross_coder = CrossCoder.load_from_hf()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "84ba269b-3491-44da-95ce-702d2a9ba0ad",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4096, 2])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %%\n",
    "norms = cross_coder.W_dec.norm(dim=-1)\n",
    "norms.shape\n",
    "# %%"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "b4415585-7fd2-4688-a4b8-d474a020c7d9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([4096])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "relative_norms = norms[:, 1] / norms.sum(dim=-1)\n",
    "relative_norms.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db6be12c-4102-40f4-9b28-867844e05508",
   "metadata": {},
   "source": [
    "# Graphing latents norm distribution and cosine similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "71d724b9-6889-42fe-86bd-2df7f661f429",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "alignmentgroup": "True",
         "bingroup": "x",
         "hovertemplate": "variable=0<br>Relative decoder norm strength=%{x}<br>count=%{y}<extra></extra>",
         "legendgroup": "0",
         "marker": {
          "color": "#636efa",
          "pattern": {
           "shape": ""
          }
         },
         "name": "0",
         "nbinsx": 200,
         "offsetgroup": "0",
         "orientation": "v",
         "showlegend": true,
         "type": "histogram",
         "x": [
          0.4919210970401764,
          0.4627123177051544,
          0.483542263507843,
          0.527014434337616,
          0.490825891494751,
          0.497461199760437,
          0.4856959581375122,
          0.4719470143318176,
          0.4699093699455261,
          0.48136106133461,
          0.4823356568813324,
          0.4924185276031494,
          0.469814658164978,
          0.4779764413833618,
          0.4879204034805298,
          0.48459336161613464,
          0.47295859456062317,
          0.47690269351005554,
          0.4640967547893524,
          0.4804984927177429,
          0.4890608489513397,
          0.43781203031539917,
          0.4780336320400238,
          0.48635777831077576,
          0.4982820153236389,
          0.45578134059906006,
          0.4855717718601227,
          0.4811970889568329,
          0.4585924744606018,
          0.5159808397293091,
          0.4859562814235687,
          0.48070594668388367,
          0.46330544352531433,
          0.4813883602619171,
          0.5063996315002441,
          0.5086499452590942,
          0.5027241706848145,
          0.49370208382606506,
          0.488035649061203,
          0.47879523038864136,
          0.4848620891571045,
          0.4851676821708679,
          0.48495152592658997,
          0.4603312313556671,
          0.4742084741592407,
          0.5016277432441711,
          0.5428881049156189,
          0.5212776064872742,
          0.47042548656463623,
          0.4648207128047943,
          0.5006994605064392,
          0.48795297741889954,
          0.49884381890296936,
          0.4895898401737213,
          0.5153927206993103,
          0.4988374412059784,
          0.5053920745849609,
          0.49510252475738525,
          0.4588167369365692,
          0.45534780621528625,
          0.5116754174232483,
          0.4909287691116333,
          0.46197253465652466,
          0.47033557295799255,
          0.5481983423233032,
          0.47993534803390503,
          0.4792167842388153,
          0.48075905442237854,
          0.4703562557697296,
          0.4808443486690521,
          0.488295316696167,
          0.4799578785896301,
          0.510574221611023,
          0.4974121153354645,
          0.4774417281150818,
          0.47888991236686707,
          0.47178953886032104,
          0.5525341033935547,
          0.4708268344402313,
          0.4722403883934021,
          0.4878826439380646,
          0.528457760810852,
          0.4694638252258301,
          0.5024629235267639,
          0.4779048562049866,
          0.4837483763694763,
          0.47403573989868164,
          0.4736621379852295,
          0.48749667406082153,
          0.5121827721595764,
          0.4677249491214752,
          0.4715626835823059,
          0.5054783821105957,
          0.4794286787509918,
          0.4964407980442047,
          0.4948910176753998,
          0.4684908390045166,
          0.47950151562690735,
          0.47565269470214844,
          0.4819849729537964,
          0.5054228901863098,
          0.4825027883052826,
          0.4778366684913635,
          0.47750934958457947,
          0.4692762792110443,
          0.4895623028278351,
          0.4694761037826538,
          0.49842530488967896,
          0.4978909492492676,
          0.4865931570529938,
          0.4861721992492676,
          0.4879230260848999,
          0.464434951543808,
          0.48711714148521423,
          0.5252529382705688,
          0.4898110032081604,
          0.4804820716381073,
          0.4831222593784332,
          0.46913817524909973,
          0.46558505296707153,
          0.4508155286312103,
          0.4840710759162903,
          0.5072025060653687,
          0.4992104172706604,
          0.48203545808792114,
          0.48341670632362366,
          0.49190276861190796,
          0.4565856456756592,
          0.4997483491897583,
          0.4933640956878662,
          0.49386730790138245,
          0.4363667070865631,
          0.4598511755466461,
          0.4658167064189911,
          0.5399116277694702,
          0.4767148196697235,
          0.4925234913825989,
          0.5057370662689209,
          0.49516117572784424,
          0.45159173011779785,
          0.4984643757343292,
          0.44217532873153687,
          0.4747408330440521,
          0.48228704929351807,
          0.49493464827537537,
          0.49914148449897766,
          0.4964527189731598,
          0.4878953993320465,
          0.46916815638542175,
          0.4929100275039673,
          0.47000595927238464,
          0.46411022543907166,
          0.46602943539619446,
          0.4572131931781769,
          0.49284812808036804,
          0.4767075181007385,
          0.4767965078353882,
          0.4632708430290222,
          0.5428667664527893,
          0.4808728098869324,
          0.464975506067276,
          0.5061990022659302,
          0.47163626551628113,
          0.4971063733100891,
          0.4877282977104187,
          0.48708653450012207,
          0.47989991307258606,
          0.4963410198688507,
          0.4923739731311798,
          0.4647391438484192,
          0.4679891765117645,
          0.4862360954284668,
          0.4815811216831207,
          0.5240998268127441,
          0.4703589975833893,
          0.4741658866405487,
          0.4804566502571106,
          0.4867136478424072,
          0.5021514892578125,
          0.4733145236968994,
          0.48206478357315063,
          0.49794986844062805,
          0.4907696843147278,
          0.4862728714942932,
          0.47944778203964233,
          0.5544988512992859,
          0.4785721004009247,
          0.49671345949172974,
          0.5321054458618164,
          0.5076074600219727,
          0.482805997133255,
          0.4687477946281433,
          0.4749089777469635,
          0.48074784874916077,
          0.4783366918563843,
          0.4628850817680359,
          0.49838903546333313,
          0.4734000563621521,
          0.48677170276641846,
          0.4802130162715912,
          0.4733935594558716,
          0.4917946457862854,
          0.4773018956184387,
          0.5134732127189636,
          0.49137839674949646,
          0.49488136172294617,
          0.49195772409439087,
          0.46723034977912903,
          0.4936204254627228,
          0.48530301451683044,
          0.4856211245059967,
          0.4560176134109497,
          0.4898068606853485,
          0.501255214214325,
          0.5033913850784302,
          0.4773721694946289,
          0.4963321387767792,
          0.4683248996734619,
          0.5010433793067932,
          0.4923468232154846,
          0.48921045660972595,
          0.5070679783821106,
          0.49216407537460327,
          0.492996484041214,
          0.9999915361404419,
          0.4891127347946167,
          0.4896758496761322,
          0.4689345061779022,
          0.45967262983322144,
          0.47507378458976746,
          0.47563114762306213,
          0.42687517404556274,
          0.4799939692020416,
          0.5141769647598267,
          0.4817022979259491,
          0.5141208171844482,
          0.4706973433494568,
          0.4590015709400177,
          0.4900415241718292,
          0.48358452320098877,
          0.48573270440101624,
          0.4865950047969818,
          0.4737094044685364,
          0.4800228774547577,
          0.48765829205513,
          0.45387256145477295,
          0.43720489740371704,
          0.5032846331596375,
          0.49689412117004395,
          0.47830674052238464,
          0.4510795772075653,
          0.5105175375938416,
          0.5161063075065613,
          0.5260829329490662,
          0.46652472019195557,
          0.486923485994339,
          0.4929434061050415,
          0.49728235602378845,
          0.4829452633857727,
          0.48112764954566956,
          0.49188727140426636,
          0.48914211988449097,
          0.48403608798980713,
          0.4768362045288086,
          0.5114724636077881,
          0.47634831070899963,
          0.4966264069080353,
          0.48862627148628235,
          0.47913238406181335,
          0.4980696141719818,
          0.4893154501914978,
          0.4060159921646118,
          0.46547746658325195,
          0.5083333849906921,
          0.47305411100387573,
          0.49274322390556335,
          0.457671582698822,
          0.5138981342315674,
          0.47514617443084717,
          0.508448600769043,
          0.4883273243904114,
          0.47272467613220215,
          0.47850722074508667,
          0.4941152334213257,
          0.49452537298202515,
          0.4886671006679535,
          0.500027060508728,
          0.4716695547103882,
          0.5055299401283264,
          0.47236305475234985,
          0.48350512981414795,
          0.471883624792099,
          0.47756126523017883,
          0.4915282130241394,
          0.4982586205005646,
          0.47936704754829407,
          0.48597899079322815,
          0.48149850964546204,
          0.45759209990501404,
          0.4765654504299164,
          0.45389699935913086,
          0.4665972888469696,
          0.4728476405143738,
          0.48538607358932495,
          0.48478949069976807,
          0.4881831109523773,
          0.5109863877296448,
          0.47364506125450134,
          0.48117372393608093,
          0.49305659532546997,
          0.46820586919784546,
          0.48551690578460693,
          0.5026859641075134,
          0.47578316926956177,
          0.47422435879707336,
          0.49437907338142395,
          0.46268847584724426,
          0.48926591873168945,
          0.526635468006134,
          0.5000460147857666,
          0.4896920919418335,
          0.48154976963996887,
          0.5003170371055603,
          0.4736669361591339,
          0.48900485038757324,
          0.504426121711731,
          0.45074662566185,
          0.47482869029045105,
          0.5008233785629272,
          0.47067978978157043,
          0.47485852241516113,
          0.49619659781455994,
          0.4950070083141327,
          0.48681697249412537,
          0.4943554401397705,
          0.4693728983402252,
          0.49889519810676575,
          0.5064180493354797,
          0.4533839225769043,
          0.47998619079589844,
          0.488803505897522,
          0.48388198018074036,
          0.48756223917007446,
          0.5497466325759888,
          0.47748157382011414,
          0.4826130270957947,
          0.498914510011673,
          0.4886986315250397,
          0.45730894804000854,
          0.5028538703918457,
          0.4782325029373169,
          0.5059635639190674,
          0.467639684677124,
          0.4736238420009613,
          0.507489800453186,
          0.4748930335044861,
          0.486518919467926,
          0.501179575920105,
          0.4694935381412506,
          0.47143441438674927,
          0.4783957600593567,
          0.46681907773017883,
          0.4844593405723572,
          0.48903173208236694,
          0.4658324420452118,
          0.5030884742736816,
          0.4611865282058716,
          0.48700615763664246,
          0.484394371509552,
          0.4683292806148529,
          0.5099762678146362,
          0.4908716082572937,
          0.9971224665641785,
          0.5009934902191162,
          0.4865945875644684,
          0.43293118476867676,
          0.48937496542930603,
          0.49622493982315063,
          0.4907030165195465,
          0.5269783735275269,
          0.4683994948863983,
          0.48528215289115906,
          0.4856729209423065,
          0.5121808648109436,
          0.4533423185348511,
          0.4663289487361908,
          0.47919875383377075,
          0.49885982275009155,
          0.4949636459350586,
          0.4936406910419464,
          0.4698859751224518,
          0.486624538898468,
          0.4792991876602173,
          0.4737379848957062,
          0.4786514937877655,
          0.45249539613723755,
          0.49885013699531555,
          0.4830891788005829,
          0.5081081986427307,
          0.49377164244651794,
          0.5509521961212158,
          0.45812174677848816,
          0.47986337542533875,
          0.46531590819358826,
          0.4787946939468384,
          0.4916515648365021,
          0.48871785402297974,
          0.4832687973976135,
          0.286825567483902,
          0.5072469115257263,
          0.47611871361732483,
          0.46126019954681396,
          0.48513898253440857,
          0.4769800305366516,
          0.49415314197540283,
          0.5066457986831665,
          0.45678356289863586,
          0.48493820428848267,
          0.478590190410614,
          0.4818585216999054,
          0.5025790333747864,
          0.4904327392578125,
          0.4700410068035126,
          0.48355868458747864,
          0.48354285955429077,
          0.48911812901496887,
          0.5033667087554932,
          0.45885488390922546,
          0.4886728525161743,
          0.461261510848999,
          0.49966302514076233,
          0.4435969293117523,
          0.4671255648136139,
          0.48170405626296997,
          0.49333617091178894,
          0.4611172676086426,
          0.4848622977733612,
          0.46924999356269836,
          4.4408184294297826e-06,
          0.4602430462837219,
          0.5099602937698364,
          0.4700189530849457,
          0.4851653575897217,
          0.4816046953201294,
          0.47112777829170227,
          0.5131321549415588,
          0.49031156301498413,
          0.474687397480011,
          0.4634718894958496,
          0.5140476822853088,
          0.5047988295555115,
          0.46742942929267883,
          0.4858100116252899,
          0.4483107924461365,
          0.47657498717308044,
          0.47309014201164246,
          0.4842235743999481,
          0.49572888016700745,
          0.48575088381767273,
          0.4359318017959595,
          0.47337135672569275,
          0.4799266457557678,
          0.48807674646377563,
          0.4735259413719177,
          0.5111599564552307,
          0.5080256462097168,
          0.48523208498954773,
          0.4765879213809967,
          0.4637870490550995,
          0.480034202337265,
          0.49523597955703735,
          0.47549518942832947,
          0.4744451940059662,
          0.4650181829929352,
          0.49165481328964233,
          0.48644495010375977,
          0.46180567145347595,
          0.4483587145805359,
          0.48601865768432617,
          0.4621855914592743,
          0.48529064655303955,
          0.5002107620239258,
          0.48135000467300415,
          0.47743016481399536,
          0.4594757854938507,
          0.4758353531360626,
          0.48178744316101074,
          0.533596932888031,
          0.4784768223762512,
          0.4887813925743103,
          0.5005890130996704,
          0.46481043100357056,
          0.4676641523838043,
          0.5089329481124878,
          0.48211854696273804,
          0.48090580105781555,
          0.48726969957351685,
          0.49041521549224854,
          0.45094233751296997,
          0.47791221737861633,
          0.4773739278316498,
          0.4814349114894867,
          0.4831610918045044,
          0.4833912253379822,
          0.487638920545578,
          0.49743765592575073,
          0.4871635437011719,
          0.5057846903800964,
          0.5063295960426331,
          0.47151705622673035,
          0.4524330198764801,
          0.48182740807533264,
          0.4918190836906433,
          0.5130024552345276,
          0.4846024215221405,
          0.46959149837493896,
          0.4992111623287201,
          0.4262557029724121,
          0.4776035249233246,
          0.4785330295562744,
          0.4797021448612213,
          0.47925809025764465,
          0.48947209119796753,
          0.4718053340911865,
          0.4903583228588104,
          0.466564804315567,
          0.4641537070274353,
          0.4715353846549988,
          0.437339723110199,
          0.4806545674800873,
          0.4853838384151459,
          0.48633500933647156,
          0.4903016686439514,
          0.4845646023750305,
          0.49031269550323486,
          0.44912517070770264,
          0.5050047039985657,
          0.44776254892349243,
          0.4676438570022583,
          0.47550350427627563,
          0.483039528131485,
          0.4916402995586395,
          0.4798377454280853,
          0.4780350625514984,
          0.49031978845596313,
          0.48872315883636475,
          0.492404043674469,
          0.48241639137268066,
          0.475528746843338,
          0.47489604353904724,
          0.99998939037323,
          0.481179416179657,
          0.488393634557724,
          0.4731244742870331,
          0.48753878474235535,
          0.4769919514656067,
          0.47190359234809875,
          0.4917890429496765,
          0.4611336588859558,
          0.5368727445602417,
          0.4989013075828552,
          0.5143821835517883,
          0.4995957911014557,
          0.48419979214668274,
          0.4876449406147003,
          0.5100941061973572,
          0.46767207980155945,
          0.5024397969245911,
          0.5038268566131592,
          0.47096118330955505,
          0.4610254168510437,
          0.49013227224349976,
          0.49978795647621155,
          0.4986654222011566,
          0.4791956841945648,
          0.4858705401420593,
          0.45774412155151367,
          0.4716373085975647,
          0.4837682247161865,
          0.4923339784145355,
          0.494835764169693,
          0.5006076693534851,
          0.4789155125617981,
          0.4728836417198181,
          0.4737195670604706,
          0.49138474464416504,
          0.4733491539955139,
          0.5067851543426514,
          0.4634828269481659,
          0.49050381779670715,
          0.4973798394203186,
          0.48145198822021484,
          0.5459456443786621,
          0.49115967750549316,
          0.5056546330451965,
          0.501748263835907,
          0.4644407033920288,
          0.49886825680732727,
          0.47218459844589233,
          0.4889242947101593,
          0.496365487575531,
          0.48949694633483887,
          0.4979318380355835,
          0.47569212317466736,
          0.4380609691143036,
          0.4925572872161865,
          0.48245859146118164,
          0.4844924807548523,
          0.4861419200897217,
          0.48928818106651306,
          0.4831157326698303,
          0.5172050595283508,
          0.47632700204849243,
          0.49429428577423096,
          0.4817947745323181,
          0.5001593232154846,
          0.49692049622535706,
          0.4662315845489502,
          0.4779649078845978,
          0.47893232107162476,
          0.4742860198020935,
          0.4743568003177643,
          0.48540955781936646,
          0.48372897505760193,
          0.48575323820114136,
          0.46773505210876465,
          0.5193091034889221,
          0.5106377601623535,
          0.4851571023464203,
          0.49225905537605286,
          0.46584591269493103,
          0.46946924924850464,
          0.47312766313552856,
          0.5090628862380981,
          0.5038176774978638,
          0.4878847599029541,
          0.45567047595977783,
          0.503976047039032,
          0.4917161762714386,
          0.4796462059020996,
          0.4638473093509674,
          0.47244396805763245,
          0.47412294149398804,
          0.49543800950050354,
          0.4964532256126404,
          0.4943963587284088,
          0.4841324985027313,
          0.4940294325351715,
          0.5042734146118164,
          0.49731576442718506,
          0.45962586998939514,
          0.4923754334449768,
          0.49692144989967346,
          0.4760839641094208,
          0.4869438409805298,
          0.48073315620422363,
          0.508813738822937,
          0.48059701919555664,
          0.45692873001098633,
          0.4709957242012024,
          0.47180771827697754,
          0.4801537096500397,
          0.4969109892845154,
          0.49017804861068726,
          0.4894316494464874,
          0.4957205653190613,
          0.48607489466667175,
          0.4845288395881653,
          0.46250325441360474,
          0.47433996200561523,
          0.486890971660614,
          0.47827690839767456,
          0.49258774518966675,
          0.46355459094047546,
          0.47604385018348694,
          0.49130508303642273,
          0.4415164291858673,
          0.48798665404319763,
          0.4838298261165619,
          0.44568943977355957,
          0.4737788140773773,
          0.45313483476638794,
          0.47593724727630615,
          0.4880993664264679,
          0.49295252561569214,
          0.47270503640174866,
          0.47389188408851624,
          0.49806854128837585,
          0.5047919154167175,
          0.4917285442352295,
          0.477740079164505,
          0.4748425781726837,
          0.5060552954673767,
          0.5231669545173645,
          0.516502320766449,
          0.47609126567840576,
          0.5053781270980835,
          0.4880951941013336,
          0.4783799648284912,
          0.48066410422325134,
          0.494935005903244,
          0.4568328559398651,
          0.5026369094848633,
          0.4849054217338562,
          0.5047982335090637,
          0.47793999314308167,
          0.46061405539512634,
          0.4662826657295227,
          0.5035316944122314,
          0.4965754747390747,
          0.5061049461364746,
          0.49492722749710083,
          0.4853021204471588,
          0.4696427583694458,
          0.4905792772769928,
          0.48139336705207825,
          0.4805562496185303,
          0.43983274698257446,
          0.4805108308792114,
          0.47084206342697144,
          0.48859840631484985,
          0.44243675470352173,
          0.4661603569984436,
          0.5016288161277771,
          0.48629942536354065,
          0.48370492458343506,
          0.4756666123867035,
          0.0034935816656798124,
          0.4726380705833435,
          0.48687925934791565,
          0.47419166564941406,
          0.47667133808135986,
          0.47355303168296814,
          0.48988670110702515,
          0.51189786195755,
          0.47921955585479736,
          0.48117420077323914,
          0.49531543254852295,
          0.49178603291511536,
          0.4772091805934906,
          0.4929714798927307,
          0.520965039730072,
          0.4628619849681854,
          0.48395824432373047,
          0.474700003862381,
          0.48171162605285645,
          0.47264283895492554,
          0.5249974727630615,
          0.4872320294380188,
          0.5039226412773132,
          0.4839038848876953,
          0.4972938895225525,
          0.4667329490184784,
          0.4681263267993927,
          0.4467811584472656,
          0.49328944087028503,
          0.4584645628929138,
          0.4562583267688751,
          0.4803379774093628,
          0.49745631217956543,
          0.6708118915557861,
          0.4816238284111023,
          0.48857980966567993,
          0.4686823785305023,
          0.478924423456192,
          0.4877944886684418,
          0.47846823930740356,
          0.4324900507926941,
          0.46034425497055054,
          0.5145150423049927,
          0.4792882204055786,
          0.5448261499404907,
          0.4869473874568939,
          0.4777269959449768,
          0.48784974217414856,
          0.4699873924255371,
          0.4828314483165741,
          0.516535222530365,
          0.5041148066520691,
          0.4883880019187927,
          0.4884917140007019,
          0.4500822126865387,
          0.4901271164417267,
          0.4741000533103943,
          0.5537747144699097,
          0.4693056344985962,
          0.4873838722705841,
          0.5025521516799927,
          0.49346989393234253,
          0.47563111782073975,
          0.5155242085456848,
          0.47582682967185974,
          0.4672183394432068,
          0.48167967796325684,
          0.4851419925689697,
          0.5043076276779175,
          0.48865506052970886,
          0.46127375960350037,
          0.45795658230781555,
          0.4758579730987549,
          0.512331485748291,
          0.4931481182575226,
          0.5248432755470276,
          0.999994695186615,
          0.5068230032920837,
          0.48644569516181946,
          0.49867185950279236,
          0.46619880199432373,
          0.4898418188095093,
          0.45789819955825806,
          0.47059366106987,
          0.4925457239151001,
          0.47162654995918274,
          0.48353713750839233,
          0.4956240952014923,
          0.47441738843917847,
          0.48963937163352966,
          0.4708738625049591,
          0.47518017888069153,
          0.44812723994255066,
          0.48585671186447144,
          0.46769627928733826,
          0.5038883090019226,
          0.4820791780948639,
          0.4851975440979004,
          0.4725536108016968,
          0.482558012008667,
          0.47531041502952576,
          0.4763616621494293,
          0.4809722304344177,
          0.48734572529792786,
          0.47171613574028015,
          0.48169198632240295,
          0.49271687865257263,
          0.5079488158226013,
          0.4571740925312042,
          0.47778934240341187,
          0.493913471698761,
          0.4932841360569,
          0.4825080335140228,
          0.4587583839893341,
          0.4872877299785614,
          0.4572611153125763,
          0.4872002601623535,
          0.4630339741706848,
          0.49477219581604004,
          0.48526838421821594,
          0.48074871301651,
          0.4684337079524994,
          0.49813470244407654,
          0.45389828085899353,
          0.49194902181625366,
          0.48676300048828125,
          0.4772096574306488,
          0.4981342852115631,
          0.48168662190437317,
          0.46474528312683105,
          0.4875532388687134,
          0.48552706837654114,
          0.47980502247810364,
          0.4907499849796295,
          0.49927574396133423,
          0.43853244185447693,
          0.5285460948944092,
          0.47292014956474304,
          0.498179167509079,
          0.5008842945098877,
          0.4860610365867615,
          0.4870436489582062,
          0.46234825253486633,
          0.4970194697380066,
          0.48769935965538025,
          0.44109591841697693,
          0.49515512585639954,
          0.48954659700393677,
          0.4896543323993683,
          0.49527058005332947,
          0.5146721601486206,
          0.4726979434490204,
          0.47399285435676575,
          0.42193979024887085,
          0.4595341682434082,
          0.4904501140117645,
          0.5055853128433228,
          0.5205028057098389,
          0.48418742418289185,
          0.4930475056171417,
          0.4758078455924988,
          0.5275445580482483,
          0.4836251139640808,
          0.47069743275642395,
          0.5035271644592285,
          0.47276368737220764,
          0.4884136915206909,
          0.5160411596298218,
          0.4989507794380188,
          0.5056922435760498,
          0.48020124435424805,
          0.4941394329071045,
          0.4878527522087097,
          0.47161024808883667,
          0.49420079588890076,
          0.512194037437439,
          0.49551311135292053,
          0.5021385550498962,
          0.4989672005176544,
          0.48031073808670044,
          0.4493523836135864,
          0.49565765261650085,
          0.49655893445014954,
          0.4691386818885803,
          0.5167335867881775,
          0.49470388889312744,
          0.4894273281097412,
          0.4849022924900055,
          0.46307626366615295,
          0.47020667791366577,
          0.491595059633255,
          0.4655107855796814,
          0.47636252641677856,
          0.5059184432029724,
          0.475905179977417,
          0.47512856125831604,
          0.48483705520629883,
          0.48466190695762634,
          0.49981576204299927,
          0.4752851128578186,
          0.47995424270629883,
          0.4628733992576599,
          0.47451719641685486,
          0.49522677063941956,
          0.47977355122566223,
          0.4785741865634918,
          0.4964217245578766,
          0.4858603775501251,
          0.47567859292030334,
          0.47080540657043457,
          0.49393752217292786,
          0.49304449558258057,
          0.4808255136013031,
          0.4894212484359741,
          0.4694632589817047,
          0.47662296891212463,
          0.48541614413261414,
          0.49105945229530334,
          0.5055716633796692,
          0.5184471607208252,
          0.46418023109436035,
          0.4980344772338867,
          0.49830561876296997,
          0.47853848338127136,
          0.4991271197795868,
          0.5050309300422668,
          0.4764842391014099,
          0.47380679845809937,
          0.47048231959342957,
          0.4892500936985016,
          0.4718727469444275,
          0.48479828238487244,
          0.4925897419452667,
          0.528347909450531,
          0.466940313577652,
          0.6845372319221497,
          0.4777543544769287,
          0.5274472236633301,
          0.4685799181461334,
          0.46421635150909424,
          0.4959201514720917,
          0.4775508642196655,
          0.48020485043525696,
          0.4959108233451843,
          0.4753618836402893,
          0.49245738983154297,
          0.4738776385784149,
          0.49356868863105774,
          0.47715795040130615,
          0.4657497704029083,
          0.7714582085609436,
          0.5549683570861816,
          0.49193865060806274,
          0.470790833234787,
          0.4797012507915497,
          0.4944766163825989,
          0.4869839549064636,
          0.4866262674331665,
          0.5141234993934631,
          0.47598156332969666,
          0.45215466618537903,
          0.47380974888801575,
          0.49059444665908813,
          0.5125086903572083,
          0.4813734292984009,
          0.4669865667819977,
          0.4949531555175781,
          0.5089163184165955,
          0.4823603630065918,
          0.4652751386165619,
          0.49436312913894653,
          0.4998175799846649,
          0.4839108884334564,
          0.5012537837028503,
          0.4649239778518677,
          0.48531460762023926,
          0.4898890554904938,
          0.4763219654560089,
          0.5027740597724915,
          0.5006982684135437,
          0.4772558808326721,
          0.4857845902442932,
          0.4941796064376831,
          0.49840018153190613,
          0.4992869198322296,
          0.5018107295036316,
          0.500320315361023,
          0.5293775200843811,
          0.47476470470428467,
          0.4923032522201538,
          0.5171831846237183,
          0.49313512444496155,
          0.4897993505001068,
          0.4704403281211853,
          0.4876856803894043,
          0.4795735478401184,
          0.44890284538269043,
          0.4857347905635834,
          0.48421043157577515,
          0.4770340919494629,
          0.4918965995311737,
          0.4890362024307251,
          0.4673648476600647,
          0.4768996834754944,
          0.48197031021118164,
          0.4885115325450897,
          0.4807290732860565,
          0.47281575202941895,
          0.5066769123077393,
          0.46598443388938904,
          0.48231905698776245,
          0.5074993371963501,
          0.4984847605228424,
          0.490715891122818,
          0.48164430260658264,
          0.519981861114502,
          0.4791656732559204,
          0.5037791728973389,
          0.5219380855560303,
          0.4914957284927368,
          0.4639010429382324,
          0.4668426811695099,
          0.5026671290397644,
          0.5372141003608704,
          0.47186729311943054,
          0.4952913820743561,
          0.5003370642662048,
          0.5001134872436523,
          0.44969773292541504,
          0.5081896781921387,
          0.49796828627586365,
          0.5012896656990051,
          0.5015515685081482,
          0.4788703918457031,
          0.5023474097251892,
          0.4834752082824707,
          0.4851968288421631,
          0.48209479451179504,
          0.4921334683895111,
          0.4980010986328125,
          0.47666847705841064,
          0.49312344193458557,
          0.4784076511859894,
          0.47483643889427185,
          0.4802807867527008,
          0.458727091550827,
          0.48010173439979553,
          0.5081233978271484,
          0.46832653880119324,
          0.4610818326473236,
          0.46442386507987976,
          0.48766976594924927,
          0.45330315828323364,
          0.4826238453388214,
          0.6430702805519104,
          0.515794575214386,
          0.5098639130592346,
          0.48888739943504333,
          0.5071876645088196,
          0.4681428372859955,
          0.48537367582321167,
          0.49330371618270874,
          0.5093970894813538,
          0.4774412214756012,
          0.491226464509964,
          0.5185615420341492,
          0.4998367130756378,
          0.45690056681632996,
          0.48477858304977417,
          0.4949479401111603,
          0.5215407013893127,
          0.45166802406311035,
          0.4915161430835724,
          0.4881437122821808,
          0.4867735803127289,
          0.4876188635826111,
          0.4766104519367218,
          0.4969073534011841,
          0.49398481845855713,
          0.4901309609413147,
          0.4740607440471649,
          0.507556140422821,
          0.4717314541339874,
          0.5036187767982483,
          0.5129033327102661,
          0.5077232122421265,
          0.48234236240386963,
          0.4874499440193176,
          0.48270919919013977,
          0.4879317283630371,
          0.4856341779232025,
          0.4684649705886841,
          0.466884583234787,
          0.45922112464904785,
          0.45794543623924255,
          0.49622809886932373,
          0.4480868875980377,
          0.4722486734390259,
          0.4729744493961334,
          0.47846612334251404,
          0.48813846707344055,
          0.4744475781917572,
          0.4836740791797638,
          0.5058330297470093,
          0.5228956937789917,
          0.5049774646759033,
          0.4625283181667328,
          0.4635210335254669,
          0.44656747579574585,
          0.5228715538978577,
          0.46763110160827637,
          0.47309011220932007,
          0.4730853736400604,
          0.46447792649269104,
          0.4726850986480713,
          0.46426695585250854,
          0.479872465133667,
          0.4697014093399048,
          0.49361181259155273,
          0.4644560217857361,
          0.48360946774482727,
          0.4729110300540924,
          0.5083850622177124,
          0.46069881319999695,
          0.4721532166004181,
          0.477434366941452,
          0.4511999487876892,
          0.4937129318714142,
          0.48838889598846436,
          0.4817279577255249,
          0.44437047839164734,
          0.47337010502815247,
          0.4580175280570984,
          0.48167693614959717,
          0.4703092873096466,
          0.4805770218372345,
          0.035948485136032104,
          0.5044568181037903,
          0.4760246276855469,
          0.519960880279541,
          0.43932560086250305,
          0.4485027492046356,
          0.4802961051464081,
          0.4805470407009125,
          1.980605156859383e-05,
          0.5017412900924683,
          0.44427284598350525,
          0.4967104196548462,
          0.47842806577682495,
          0.47642165422439575,
          0.46955469250679016,
          0.4720994234085083,
          0.4887446165084839,
          0.486052006483078,
          0.48556166887283325,
          0.47821754217147827,
          0.4959963858127594,
          0.491546630859375,
          0.4803451597690582,
          0.5283862948417664,
          0.46748480200767517,
          0.4521179795265198,
          0.5309917330741882,
          0.4790123701095581,
          0.516325831413269,
          0.48084765672683716,
          0.4895823299884796,
          0.49464115500450134,
          0.4922105669975281,
          0.4922700822353363,
          0.5780082941055298,
          0.4518299102783203,
          0.49569830298423767,
          0.504164457321167,
          0.4162878394126892,
          0.49470779299736023,
          0.49348583817481995,
          0.5167368054389954,
          0.48016542196273804,
          0.45068565011024475,
          0.4880317449569702,
          0.999926745891571,
          0.4470514953136444,
          0.4875538647174835,
          0.49161624908447266,
          0.5584762692451477,
          0.48900750279426575,
          0.48976510763168335,
          0.4676857888698578,
          0.47687000036239624,
          0.4643164873123169,
          0.5211785435676575,
          0.4930616021156311,
          0.5786821246147156,
          0.462844580411911,
          0.4840001165866852,
          0.4751187562942505,
          0.4980499744415283,
          0.4665409028530121,
          0.47666969895362854,
          0.4731200337409973,
          0.5146582722663879,
          0.509941577911377,
          0.44019588828086853,
          0.48986268043518066,
          0.4995633065700531,
          0.49229851365089417,
          0.45328330993652344,
          0.47310855984687805,
          0.47619858384132385,
          0.46612104773521423,
          0.4784465432167053,
          0.44929826259613037,
          0.4957473576068878,
          0.4823586940765381,
          0.4596408009529114,
          0.48715445399284363,
          0.4935057461261749,
          0.4891255795955658,
          0.48205462098121643,
          0.48039016127586365,
          0.4786669611930847,
          0.5019421577453613,
          0.48382997512817383,
          0.47395679354667664,
          0.5021793246269226,
          0.47861722111701965,
          0.4148373007774353,
          0.5029728412628174,
          0.4982641637325287,
          0.4997595548629761,
          0.5008381605148315,
          0.4771246612071991,
          0.5385783910751343,
          0.47166958451271057,
          0.46761566400527954,
          0.5044128894805908,
          0.46617695689201355,
          0.507960319519043,
          0.4915699064731598,
          0.48392581939697266,
          0.4432075023651123,
          0.4757407605648041,
          0.4717371165752411,
          0.47075405716896057,
          0.4615170359611511,
          0.5033180117607117,
          0.4789464771747589,
          0.47880303859710693,
          0.4944305419921875,
          0.48126012086868286,
          0.4824478328227997,
          0.48650336265563965,
          0.4899272918701172,
          0.45420965552330017,
          0.481334924697876,
          0.48096778988838196,
          0.4750460386276245,
          0.45183050632476807,
          0.46705928444862366,
          0.49156227707862854,
          0.4979707598686218,
          0.4740290641784668,
          0.47938159108161926,
          0.5059424638748169,
          0.5030580163002014,
          0.4923247694969177,
          0.4856646656990051,
          0.5088853240013123,
          0.4860660433769226,
          0.4832324981689453,
          0.47741472721099854,
          0.4814104437828064,
          0.500036358833313,
          0.5149974226951599,
          0.48127487301826477,
          0.4693218469619751,
          0.475130558013916,
          0.4927665591239929,
          0.470613956451416,
          0.4644888639450073,
          0.4568939805030823,
          0.5028104186058044,
          0.495208740234375,
          0.4792986810207367,
          0.4822271764278412,
          0.4715385437011719,
          0.5122308135032654,
          0.4992174208164215,
          0.44476377964019775,
          0.49787667393684387,
          0.47411200404167175,
          0.49544528126716614,
          0.48587265610694885,
          0.4703075587749481,
          0.498492032289505,
          0.4828009009361267,
          0.48326489329338074,
          0.4820171892642975,
          0.4684259295463562,
          0.4634060263633728,
          0.47758179903030396,
          0.4976996183395386,
          0.5025256872177124,
          0.488319456577301,
          0.4814940094947815,
          0.4908115565776825,
          0.47705399990081787,
          0.4867677390575409,
          0.5145788192749023,
          0.47345492243766785,
          0.4935309886932373,
          0.4982004463672638,
          0.47938087582588196,
          0.4693383574485779,
          0.45777276158332825,
          0.49247488379478455,
          0.48970913887023926,
          0.4985926151275635,
          0.4982960522174835,
          6.2094268287182786e-06,
          0.4768446385860443,
          0.4851914048194885,
          0.4795108735561371,
          0.4767976403236389,
          0.4814067780971527,
          0.4643118679523468,
          0.5037739872932434,
          0.5028372406959534,
          0.49043673276901245,
          0.48327139019966125,
          0.4819473624229431,
          0.4785434603691101,
          0.46633651852607727,
          0.4998733401298523,
          0.4929732084274292,
          0.4867420196533203,
          0.5103065371513367,
          0.4900692403316498,
          0.4774045944213867,
          0.47950875759124756,
          0.49279800057411194,
          0.4892776608467102,
          0.4693308472633362,
          0.4887732267379761,
          0.48894941806793213,
          0.4826447665691376,
          0.48287272453308105,
          0.4994218349456787,
          0.4813133478164673,
          0.5081303119659424,
          0.4703957140445709,
          0.4790481626987457,
          0.4613869786262512,
          0.4695606827735901,
          0.45422881841659546,
          0.48859286308288574,
          0.48356032371520996,
          0.4709603488445282,
          0.4498897194862366,
          0.47006016969680786,
          0.5008179545402527,
          0.4953100383281708,
          0.49465450644493103,
          0.47206979990005493,
          0.48939049243927,
          0.4906787872314453,
          0.46973103284835815,
          0.45597460865974426,
          0.5004053711891174,
          0.5132985711097717,
          0.5090983510017395,
          0.47587379813194275,
          0.46668949723243713,
          0.4768221974372864,
          0.4784061908721924,
          0.47007808089256287,
          0.49530312418937683,
          0.4905203878879547,
          0.4865803122520447,
          0.0004190029576420784,
          0.44814541935920715,
          0.4786713421344757,
          0.46179264783859253,
          0.4541710615158081,
          0.47340163588523865,
          0.4713326096534729,
          0.5051512122154236,
          0.46664804220199585,
          0.4851742386817932,
          0.4923858642578125,
          0.4975523352622986,
          0.4754517078399658,
          0.5025203227996826,
          0.4625212252140045,
          0.47828713059425354,
          0.4521612823009491,
          0.4954184591770172,
          0.4572846293449402,
          0.49471965432167053,
          0.5073777437210083,
          0.5089930891990662,
          0.44125857949256897,
          0.4796433448791504,
          0.4931127429008484,
          0.49069398641586304,
          0.5188909769058228,
          0.4798264503479004,
          0.5020148754119873,
          0.48196548223495483,
          0.46818575263023376,
          0.47114574909210205,
          0.45960158109664917,
          0.5091539025306702,
          0.502027690410614,
          0.48916351795196533,
          0.5020411610603333,
          0.5001040697097778,
          0.4852462410926819,
          0.4807107150554657,
          0.4854189157485962,
          0.48385247588157654,
          0.5006526708602905,
          0.4783710539340973,
          0.49367570877075195,
          0.47739556431770325,
          0.46147552132606506,
          0.4904888868331909,
          0.48017382621765137,
          0.47152990102767944,
          0.46222376823425293,
          0.4497740864753723,
          0.493601530790329,
          0.4785936772823334,
          0.4566361904144287,
          0.5063181519508362,
          0.4895213544368744,
          0.4907079339027405,
          0.4781741797924042,
          0.4601598083972931,
          0.4674793779850006,
          0.44752630591392517,
          0.481188029050827,
          0.49050748348236084,
          0.4760855436325073,
          0.5030949711799622,
          0.4872659742832184,
          0.4814566969871521,
          0.4725496172904968,
          0.7044758796691895,
          0.49325695633888245,
          0.4491186738014221,
          0.5002012252807617,
          0.4613746106624603,
          0.5058973431587219,
          0.44140857458114624,
          0.4945678114891052,
          0.49521610140800476,
          0.48225629329681396,
          0.4858081638813019,
          0.49977320432662964,
          0.4913075566291809,
          0.481597363948822,
          0.4591391682624817,
          0.47929513454437256,
          0.4961945116519928,
          0.5664482116699219,
          0.4881635308265686,
          0.4835626184940338,
          0.45958250761032104,
          0.4533568322658539,
          0.49857935309410095,
          0.4793626070022583,
          0.4961664080619812,
          0.4912475049495697,
          0.514369547367096,
          0.4650869369506836,
          0.48688676953315735,
          0.48809030652046204,
          0.4502612054347992,
          0.4759747385978699,
          0.4844469726085663,
          0.49911758303642273,
          0.4605189859867096,
          0.47035664319992065,
          0.4908715486526489,
          0.504488468170166,
          0.47197824716567993,
          0.4716688096523285,
          0.49803438782691956,
          0.4965467154979706,
          0.4506165087223053,
          0.4905874729156494,
          0.4838886260986328,
          0.5281551480293274,
          0.49943676590919495,
          0.45909202098846436,
          0.47991830110549927,
          0.511103630065918,
          0.5567195415496826,
          0.5022137761116028,
          0.46714115142822266,
          0.4878694713115692,
          0.4865356385707855,
          0.5300040245056152,
          0.4958479106426239,
          0.4749554395675659,
          0.48394277691841125,
          0.47906240820884705,
          0.4489831030368805,
          0.479037344455719,
          0.4510176479816437,
          0.48509448766708374,
          0.47032639384269714,
          0.4909685552120209,
          0.4877905249595642,
          0.4878086447715759,
          0.5192659497261047,
          0.47387129068374634,
          0.5095716118812561,
          0.48261263966560364,
          0.4656873047351837,
          0.5009985566139221,
          0.4935917258262634,
          0.49644234776496887,
          0.5003657341003418,
          0.47723498940467834,
          0.4690519869327545,
          0.47880393266677856,
          0.46715056896209717,
          0.4277811646461487,
          0.4779585003852844,
          0.4450755715370178,
          0.47574785351753235,
          0.5123229026794434,
          0.5013985633850098,
          0.48551419377326965,
          0.49040883779525757,
          0.48079848289489746,
          0.5188906192779541,
          0.48451268672943115,
          0.48671185970306396,
          0.47186079621315,
          0.47651076316833496,
          0.46794867515563965,
          0.46941184997558594,
          0.4961916208267212,
          0.4925428032875061,
          0.4409661591053009,
          0.4272547960281372,
          0.48736700415611267,
          0.4635443687438965,
          0.4781733751296997,
          0.43862393498420715,
          0.5083929896354675,
          0.4756677448749542,
          0.4936089813709259,
          0.49280694127082825,
          0.4827018678188324,
          0.49474552273750305,
          0.4741632342338562,
          0.4756948947906494,
          0.4721384048461914,
          0.5040400624275208,
          0.48352736234664917,
          0.49454227089881897,
          0.4832391142845154,
          0.4757380187511444,
          0.49299779534339905,
          0.4889979362487793,
          0.4972180128097534,
          0.49234357476234436,
          0.48706337809562683,
          0.5177749395370483,
          0.48284226655960083,
          0.4798661470413208,
          0.48189103603363037,
          0.4893187880516052,
          0.4705945551395416,
          0.46141430735588074,
          0.4637455940246582,
          0.4931095838546753,
          0.46779805421829224,
          0.4904347360134125,
          0.5194728374481201,
          0.500123143196106,
          0.4949677288532257,
          0.48111197352409363,
          0.4890343248844147,
          0.49471792578697205,
          0.4760361611843109,
          0.4592169225215912,
          0.4618789553642273,
          0.47900429368019104,
          0.48817503452301025,
          0.45218905806541443,
          0.4881591498851776,
          0.4828868508338928,
          0.4662010371685028,
          0.3417463004589081,
          0.48092982172966003,
          0.4659300446510315,
          0.4846144914627075,
          0.4776436388492584,
          0.47743621468544006,
          0.4943458139896393,
          0.458172470331192,
          0.45637598633766174,
          0.4801938235759735,
          0.45363524556159973,
          0.4763728082180023,
          0.4882916808128357,
          0.4873509109020233,
          0.47829702496528625,
          0.4831213653087616,
          0.4677315950393677,
          0.4679841995239258,
          0.4649284780025482,
          0.477445125579834,
          0.49800220131874084,
          0.47290679812431335,
          0.9999939203262329,
          0.4840436279773712,
          0.4670245051383972,
          0.48893287777900696,
          0.4927521049976349,
          0.4801257252693176,
          0.5020243525505066,
          0.4855231046676636,
          0.5017590522766113,
          0.5161365866661072,
          0.49038922786712646,
          0.47396203875541687,
          0.502120316028595,
          0.4619997441768646,
          0.4801276624202728,
          0.49440693855285645,
          0.46181827783584595,
          0.4964248239994049,
          0.4985170066356659,
          0.46031954884529114,
          0.46300485730171204,
          0.4639333188533783,
          0.468434602022171,
          0.5093398690223694,
          0.48196515440940857,
          0.47140321135520935,
          0.6354905962944031,
          0.47376570105552673,
          0.5321871042251587,
          0.4770990014076233,
          0.509740948677063,
          0.4794550836086273,
          0.4822978973388672,
          0.4808541536331177,
          0.5016893744468689,
          0.4695613384246826,
          0.46928879618644714,
          0.4694080650806427,
          0.4778107702732086,
          0.5003483891487122,
          0.47198817133903503,
          0.5315275192260742,
          0.5039469003677368,
          0.4977368712425232,
          0.5094190835952759,
          0.4809584319591522,
          0.4932711124420166,
          0.5282854437828064,
          0.4557377099990845,
          0.4724387526512146,
          0.479753315448761,
          0.48746439814567566,
          0.4891105890274048,
          0.481678307056427,
          0.4837070107460022,
          0.49946027994155884,
          0.48032131791114807,
          0.49858784675598145,
          0.4727036952972412,
          0.5110820531845093,
          0.4948500990867615,
          0.4974910616874695,
          0.4894806146621704,
          0.4904126226902008,
          0.5178683996200562,
          0.4728885293006897,
          0.48542314767837524,
          0.4636606276035309,
          0.4921382665634155,
          0.49416807293891907,
          0.48811960220336914,
          0.46933209896087646,
          0.47435787320137024,
          0.5135086178779602,
          0.4975394904613495,
          0.4784322679042816,
          0.501045823097229,
          0.4812982678413391,
          0.49220511317253113,
          0.4866640269756317,
          0.5121585726737976,
          0.4656512141227722,
          0.5055289268493652,
          0.4680752754211426,
          0.48615023493766785,
          0.4675407409667969,
          0.4752865433692932,
          0.4886375367641449,
          0.48225924372673035,
          0.493325799703598,
          0.4699602723121643,
          0.4976857900619507,
          0.4866520166397095,
          0.4929508864879608,
          0.4973113536834717,
          0.47245556116104126,
          0.5140370726585388,
          0.49924638867378235,
          0.46013158559799194,
          0.47638577222824097,
          0.48372966051101685,
          0.43068015575408936,
          0.48098522424697876,
          0.47472378611564636,
          0.3772064447402954,
          0.4868617653846741,
          0.46397873759269714,
          0.4914725720882416,
          0.4943646490573883,
          0.4776216745376587,
          0.4757024049758911,
          0.4691382348537445,
          0.47102487087249756,
          0.47464993596076965,
          0.4756883978843689,
          0.4743759334087372,
          0.5019774436950684,
          0.5073018670082092,
          0.4808303415775299,
          0.4916207194328308,
          0.47727635502815247,
          0.46251145005226135,
          0.4800214469432831,
          0.4803403615951538,
          0.47761064767837524,
          0.4920811951160431,
          0.4933253228664398,
          0.4688272774219513,
          0.4970482289791107,
          0.5395865440368652,
          0.4748390316963196,
          0.49217239022254944,
          0.5209192633628845,
          0.4783713221549988,
          0.48255833983421326,
          0.4872133433818817,
          0.4602952301502228,
          0.46132946014404297,
          0.4667551815509796,
          0.49041813611984253,
          0.504814863204956,
          0.48383408784866333,
          0.4516656696796417,
          0.4601903259754181,
          0.5004616975784302,
          0.4925442636013031,
          0.4710453748703003,
          0.4716509282588959,
          0.4889073371887207,
          0.4699539542198181,
          0.5005834102630615,
          0.4365968704223633,
          0.4690406024456024,
          0.4695495367050171,
          0.48352503776550293,
          0.49023595452308655,
          0.4756227433681488,
          0.46244335174560547,
          0.49997180700302124,
          0.4673059582710266,
          0.47601717710494995,
          0.4737163484096527,
          0.4710051715373993,
          0.47988858819007874,
          0.4981493055820465,
          0.4652369022369385,
          0.4873548746109009,
          0.45552879571914673,
          0.42366600036621094,
          0.478010892868042,
          0.45731213688850403,
          0.49566102027893066,
          0.4789535701274872,
          0.4845718741416931,
          0.00021093353279866278,
          0.4762338399887085,
          0.5043672323226929,
          0.4863895773887634,
          0.4944290518760681,
          0.49103617668151855,
          0.4977473020553589,
          0.4878225028514862,
          0.47687363624572754,
          0.46955299377441406,
          0.4637647271156311,
          0.48769611120224,
          0.5120522975921631,
          0.48000892996788025,
          0.47374099493026733,
          0.473494291305542,
          0.5130285024642944,
          0.45637279748916626,
          0.49550333619117737,
          0.5061944127082825,
          0.4719872772693634,
          0.4447999596595764,
          0.46140170097351074,
          0.4767962098121643,
          0.4939393699169159,
          0.4763263463973999,
          0.45776012539863586,
          0.4745040535926819,
          0.4637070298194885,
          0.4718252122402191,
          0.5031184554100037,
          0.5110970735549927,
          0.49489232897758484,
          0.4858859181404114,
          0.4942372739315033,
          0.5198721289634705,
          0.4875326454639435,
          0.49921712279319763,
          0.49133622646331787,
          0.4830636978149414,
          0.4716099500656128,
          0.5189820528030396,
          0.49759048223495483,
          0.4930427074432373,
          0.4885532259941101,
          0.4804548919200897,
          0.48427677154541016,
          0.49468037486076355,
          0.455633282661438,
          0.49219179153442383,
          0.4935447573661804,
          0.47735777497291565,
          0.49008145928382874,
          0.4856145679950714,
          0.48429563641548157,
          0.471732497215271,
          0.4725450575351715,
          0.47117096185684204,
          0.46962106227874756,
          0.5036595463752747,
          0.4701375663280487,
          0.47940918803215027,
          0.5035651326179504,
          0.4697188138961792,
          0.5066814422607422,
          0.5065171718597412,
          0.48612549901008606,
          0.4365990459918976,
          2.469318133080378e-06,
          0.45114651322364807,
          0.4765172004699707,
          0.48925235867500305,
          0.49160945415496826,
          0.4771256148815155,
          0.4924667179584503,
          0.48898833990097046,
          0.4566381275653839,
          0.476118266582489,
          0.4615245461463928,
          0.47279995679855347,
          0.48864954710006714,
          0.4776667654514313,
          0.49330058693885803,
          0.4936583340167999,
          0.4977266788482666,
          0.999980092048645,
          0.45834994316101074,
          0.48812776803970337,
          0.48006191849708557,
          0.47813719511032104,
          0.5036823153495789,
          0.4825015962123871,
          0.4625268876552582,
          0.5109228491783142,
          0.5009675621986389,
          0.48121917247772217,
          0.46448180079460144,
          0.4739314615726471,
          0.4882456362247467,
          0.4950842261314392,
          0.4704490602016449,
          0.45943132042884827,
          0.44978731870651245,
          0.4745721220970154,
          0.5282919406890869,
          0.49120187759399414,
          0.4799303710460663,
          0.5048820972442627,
          0.49368855357170105,
          0.4860202968120575,
          0.4658155143260956,
          0.5076813697814941,
          0.49635669589042664,
          0.44732123613357544,
          0.4896368086338043,
          0.49454164505004883,
          0.4813082814216614,
          0.4708717465400696,
          0.4823591709136963,
          0.48189786076545715,
          0.47563037276268005,
          0.45878860354423523,
          0.5193292498588562,
          0.4885058104991913,
          0.4907030761241913,
          0.47972553968429565,
          0.4869399666786194,
          0.48636287450790405,
          0.47943103313446045,
          0.48960593342781067,
          0.4600587785243988,
          0.4854710102081299,
          0.46515634655952454,
          0.47483575344085693,
          0.48006293177604675,
          0.4968310594558716,
          0.48565247654914856,
          0.4902370274066925,
          0.5047898888587952,
          0.4359404742717743,
          0.4911830425262451,
          0.49696385860443115,
          0.4824711084365845,
          0.47362351417541504,
          0.47097447514533997,
          0.4837849736213684,
          0.48189207911491394,
          0.4658001661300659,
          0.48294031620025635,
          0.4614841043949127,
          0.48588117957115173,
          0.4769566059112549,
          0.4744690954685211,
          0.4883107542991638,
          0.4580918550491333,
          0.5067833065986633,
          0.5110152363777161,
          0.48820534348487854,
          0.4899344742298126,
          0.48857933282852173,
          0.4832465946674347,
          0.4719473421573639,
          0.4898652136325836,
          0.5121021270751953,
          0.4769528806209564,
          0.4584084451198578,
          0.47668853402137756,
          0.49102044105529785,
          0.49379056692123413,
          0.5016487836837769,
          0.49008846282958984,
          0.5089819431304932,
          0.3445277512073517,
          0.49671274423599243,
          0.5036879181861877,
          0.4942477345466614,
          0.4755835235118866,
          0.4848408102989197,
          0.4805743098258972,
          0.4746643006801605,
          0.48189860582351685,
          0.49482226371765137,
          0.5044540762901306,
          0.49468767642974854,
          0.4728929400444031,
          0.463337242603302,
          0.4840296804904938,
          0.5180062055587769,
          0.4667249023914337,
          0.4925808906555176,
          0.5188103318214417,
          0.44592201709747314,
          0.49054989218711853,
          0.1731840819120407,
          0.49869316816329956,
          0.47222238779067993,
          0.4852650761604309,
          0.47898271679878235,
          0.534568727016449,
          0.471367746591568,
          0.4810575544834137,
          0.4917074143886566,
          0.4983277916908264,
          0.46765467524528503,
          0.45622536540031433,
          0.47834691405296326,
          0.5031970143318176,
          0.4896254539489746,
          0.47566238045692444,
          0.47653600573539734,
          0.46192672848701477,
          0.49195921421051025,
          0.4920385777950287,
          0.47032687067985535,
          0.5058387517929077,
          0.4764973521232605,
          0.4846627414226532,
          0.4943977892398834,
          0.4888079762458801,
          0.46873241662979126,
          0.46656808257102966,
          0.4762427806854248,
          0.4795159697532654,
          0.453906774520874,
          0.5059390068054199,
          0.9999855160713196,
          0.5054435729980469,
          0.4822167754173279,
          0.48830360174179077,
          0.4873764216899872,
          0.4826592803001404,
          0.461420476436615,
          0.47532007098197937,
          0.4942309260368347,
          0.4934327304363251,
          0.4819798767566681,
          0.4951520264148712,
          0.49425575137138367,
          0.4926316738128662,
          0.4897327423095703,
          0.4979797303676605,
          0.46486133337020874,
          0.47170111536979675,
          0.5316647887229919,
          0.4875822961330414,
          0.45031553506851196,
          0.4975613057613373,
          0.4932064712047577,
          0.4819740355014801,
          0.474666029214859,
          0.4914303123950958,
          0.48793408274650574,
          0.9999889135360718,
          0.47286346554756165,
          0.4720308780670166,
          0.5051865577697754,
          0.4928356111049652,
          0.4719676375389099,
          0.46591871976852417,
          0.47373706102371216,
          0.4810445308685303,
          0.4992745816707611,
          0.7309713363647461,
          0.48330777883529663,
          0.46625402569770813,
          0.4667038917541504,
          0.500819981098175,
          0.5177400708198547,
          0.5217282176017761,
          0.4787454903125763,
          0.46123823523521423,
          0.47626814246177673,
          0.4668676257133484,
          0.4774029552936554,
          0.48961341381073,
          0.482906699180603,
          0.5112248659133911,
          0.4973810017108917,
          0.494526207447052,
          0.481326162815094,
          0.48808467388153076,
          0.48973822593688965,
          0.48007452487945557,
          0.4734961688518524,
          0.5040914416313171,
          0.486833393573761,
          0.9999834895133972,
          0.4627223610877991,
          0.4820610284805298,
          0.47013357281684875,
          0.4892716407775879,
          0.4732464551925659,
          0.49630045890808105,
          0.47235095500946045,
          0.46473366022109985,
          0.48385196924209595,
          0.5296720266342163,
          0.4926832914352417,
          0.473227858543396,
          0.4953617751598358,
          0.474812388420105,
          0.4891035258769989,
          0.43458545207977295,
          0.49296560883522034,
          0.4942537844181061,
          0.48338547348976135,
          0.47341448068618774,
          0.48094844818115234,
          0.473646879196167,
          0.5487772226333618,
          0.509393572807312,
          0.48129498958587646,
          0.47560369968414307,
          0.4527144432067871,
          0.4594687819480896,
          0.470473974943161,
          0.484443336725235,
          0.4799952507019043,
          0.48371535539627075,
          0.4765084683895111,
          0.4975835978984833,
          0.4920864999294281,
          0.46437814831733704,
          0.45856332778930664,
          0.47411492466926575,
          0.4662141501903534,
          0.48420119285583496,
          0.47076648473739624,
          0.49492621421813965,
          0.47452956438064575,
          0.47569018602371216,
          0.483016699552536,
          0.4995591342449188,
          0.4903121292591095,
          0.46125856041908264,
          0.5011909008026123,
          0.5112881660461426,
          0.45637571811676025,
          0.47373977303504944,
          0.47541916370391846,
          0.5061064958572388,
          0.502447247505188,
          0.48992374539375305,
          0.49699705839157104,
          0.4790962338447571,
          0.46147698163986206,
          0.5001813769340515,
          0.471489816904068,
          0.47840967774391174,
          0.45972564816474915,
          0.5039249658584595,
          0.48647385835647583,
          0.49507173895835876,
          0.493826299905777,
          0.49095550179481506,
          0.48835259675979614,
          0.5043767094612122,
          0.5060329437255859,
          0.516840398311615,
          0.46788427233695984,
          0.47126519680023193,
          0.4966956377029419,
          0.4657784700393677,
          0.5148831605911255,
          0.4696657359600067,
          0.5052074790000916,
          0.48821088671684265,
          0.47297847270965576,
          0.5133561491966248,
          0.5070609450340271,
          0.4825177490711212,
          0.48502954840660095,
          0.47406843304634094,
          0.45023682713508606,
          0.4878380298614502,
          0.4623379111289978,
          0.5118981599807739,
          0.49387359619140625,
          0.48168766498565674,
          0.5057108402252197,
          0.4836154580116272,
          0.487345427274704,
          0.4551500678062439,
          0.48867130279541016,
          0.4642001986503601,
          0.5024617314338684,
          0.4848063588142395,
          0.5077579021453857,
          0.5042265057563782,
          0.5004897713661194,
          0.48551276326179504,
          0.49781501293182373,
          0.48332685232162476,
          0.4830435514450073,
          0.49213460087776184,
          0.48743727803230286,
          0.4894943833351135,
          0.4726838171482086,
          0.46063557267189026,
          0.46893632411956787,
          0.5297366976737976,
          0.47336527705192566,
          0.4889528751373291,
          0.4785694181919098,
          0.4842279255390167,
          0.47916457056999207,
          0.4599808156490326,
          0.47999486327171326,
          0.47394606471061707,
          0.4838043451309204,
          0.46466585993766785,
          0.47651591897010803,
          0.4950483739376068,
          0.4574672281742096,
          0.5070932507514954,
          0.478145569562912,
          0.5086073279380798,
          0.47536778450012207,
          0.4676697552204132,
          0.4689071774482727,
          0.4808973968029022,
          0.4800036549568176,
          0.4900020658969879,
          0.52937912940979,
          0.4963386058807373,
          0.5090090036392212,
          0.47808539867401123,
          0.46113714575767517,
          0.4990861415863037,
          0.4970235228538513,
          0.49561360478401184,
          0.4716881811618805,
          0.493694931268692,
          0.44601455330848694,
          0.44600245356559753,
          0.47659945487976074,
          0.5003041625022888,
          0.4913283586502075,
          0.5243009924888611,
          0.47992461919784546,
          0.5032613277435303,
          0.4858083128929138,
          0.4863559603691101,
          0.4783633351325989,
          0.47234389185905457,
          0.4759230613708496,
          0.4741082787513733,
          0.45863690972328186,
          0.49979689717292786,
          0.4898897707462311,
          0.47396159172058105,
          0.48436468839645386,
          0.46702104806900024,
          0.48179295659065247,
          0.492732435464859,
          0.486829936504364,
          6.683629635517718e-06,
          0.4864434003829956,
          0.4999863803386688,
          0.49097979068756104,
          0.4972911477088928,
          0.4831424057483673,
          0.49985170364379883,
          0.7335197925567627,
          0.4855266213417053,
          0.4665609300136566,
          0.5210835933685303,
          0.510698676109314,
          0.48184773325920105,
          0.4962928891181946,
          0.49486932158470154,
          0.5046606659889221,
          0.46721628308296204,
          0.4943692684173584,
          0.49902334809303284,
          0.48502302169799805,
          0.4892337918281555,
          0.47170063853263855,
          0.49826574325561523,
          0.4721841812133789,
          0.4680999219417572,
          0.4854517877101898,
          0.4945741593837738,
          0.4808805286884308,
          0.48786890506744385,
          0.4911244511604309,
          0.4704447388648987,
          0.48628512024879456,
          0.47824862599372864,
          0.4607778787612915,
          0.48588088154792786,
          0.49104544520378113,
          0.5036202669143677,
          0.4881611764431,
          0.4856952130794525,
          0.48254695534706116,
          0.48124444484710693,
          0.4947659969329834,
          0.48867884278297424,
          0.49078068137168884,
          0.48370125889778137,
          0.49411389231681824,
          0.47521886229515076,
          0.47452041506767273,
          0.47200796008110046,
          0.4736400246620178,
          0.491881787776947,
          0.49259358644485474,
          0.9999784827232361,
          0.4902474880218506,
          0.4607638716697693,
          0.47970423102378845,
          0.507265567779541,
          0.5052575469017029,
          0.48755186796188354,
          0.5015824437141418,
          0.4952230751514435,
          0.47378793358802795,
          0.49058035016059875,
          0.46879926323890686,
          0.4640667736530304,
          0.4955298900604248,
          0.43741175532341003,
          0.49417611956596375,
          0.44415542483329773,
          0.4763403534889221,
          0.48089611530303955,
          0.4600255787372589,
          0.48888376355171204,
          0.49398180842399597,
          0.4679822623729706,
          0.4853660464286804,
          0.519832968711853,
          0.4790906012058258,
          0.4808368682861328,
          0.500245988368988,
          0.46663936972618103,
          0.491947740316391,
          0.4801308810710907,
          0.4735667109489441,
          0.4770072102546692,
          0.4921914339065552,
          0.4809335470199585,
          0.19046644866466522,
          0.4739871025085449,
          0.5361455678939819,
          0.49959835410118103,
          0.46608397364616394,
          0.4797642230987549,
          0.5143961310386658,
          0.4957062602043152,
          0.4719681143760681,
          0.4815455377101898,
          0.47787076234817505,
          0.48721373081207275,
          0.4845237135887146,
          0.4752378463745117,
          0.43790870904922485,
          0.49180829524993896,
          0.4812215268611908,
          0.4844026267528534,
          0.49725452065467834,
          0.4533558785915375,
          0.5001524686813354,
          0.48979344964027405,
          0.5381631255149841,
          0.5407768487930298,
          0.4354383945465088,
          0.4746387004852295,
          0.48847630620002747,
          0.48110899329185486,
          0.48843321204185486,
          0.5033880472183228,
          0.48982885479927063,
          0.480048269033432,
          0.47613203525543213,
          0.48305100202560425,
          0.46840474009513855,
          0.5000990033149719,
          0.485073059797287,
          0.4581119120121002,
          0.4754459857940674,
          0.46491721272468567,
          0.4881032705307007,
          0.49283674359321594,
          0.4849958121776581,
          0.45003172755241394,
          0.5131799578666687,
          0.47312304377555847,
          0.4841080605983734,
          0.48018762469291687,
          0.492729514837265,
          0.46938636898994446,
          0.5138564705848694,
          0.47749561071395874,
          0.4907843768596649,
          0.4591650664806366,
          0.4724445939064026,
          0.4936774969100952,
          0.4621703326702118,
          0.5031834840774536,
          0.5188911557197571,
          0.47306889295578003,
          0.5085750222206116,
          0.5059159994125366,
          0.47778043150901794,
          0.4864601790904999,
          0.4921955168247223,
          0.4791845977306366,
          0.4706263542175293,
          0.44994616508483887,
          0.4752222001552582,
          0.4698571264743805,
          0.4831702709197998,
          0.48654285073280334,
          0.4991298317909241,
          0.46870532631874084,
          0.47915923595428467,
          0.47014787793159485,
          0.5125473141670227,
          0.4816480576992035,
          0.4501066505908966,
          0.5143670439720154,
          0.4971010684967041,
          0.5184808969497681,
          0.47077977657318115,
          0.48356038331985474,
          0.4777318835258484,
          0.4650077223777771,
          0.48089703917503357,
          0.49749472737312317,
          0.487167626619339,
          0.47983160614967346,
          0.4804695248603821,
          0.5075235366821289,
          0.46305862069129944,
          0.496019184589386,
          0.4818504750728607,
          0.46653351187705994,
          0.4763776957988739,
          0.4829607903957367,
          0.49303850531578064,
          0.48797351121902466,
          0.503654956817627,
          0.46656012535095215,
          0.8860247731208801,
          0.4923177659511566,
          0.48856645822525024,
          0.46307623386383057,
          0.4525326192378998,
          0.4706694483757019,
          0.49362754821777344,
          0.4759664237499237,
          0.4980716407299042,
          0.44923165440559387,
          0.4820677638053894,
          0.45723757147789,
          0.4995404779911041,
          0.4814716875553131,
          0.47209659218788147,
          0.4737635552883148,
          0.4612300992012024,
          0.46599438786506653,
          0.53838050365448,
          0.4515719413757324,
          0.4709310829639435,
          0.46854525804519653,
          0.48994582891464233,
          0.4800776243209839,
          0.4763701260089874,
          0.482773095369339,
          0.4991663694381714,
          0.4806978106498718,
          0.4861646592617035,
          0.4791967272758484,
          0.4737493097782135,
          0.4733295440673828,
          0.48395639657974243,
          0.46716365218162537,
          0.5132791996002197,
          0.480848491191864,
          0.4882964491844177,
          0.4599999487400055,
          0.5049338340759277,
          0.47899478673934937,
          0.4712635576725006,
          0.4711696207523346,
          0.4889262318611145,
          0.49908584356307983,
          0.47375091910362244,
          0.4819382131099701,
          0.488686740398407,
          0.4988122582435608,
          0.4703625738620758,
          0.4740709960460663,
          0.5148524641990662,
          0.4951115548610687,
          0.48808738589286804,
          0.4892702102661133,
          0.495249480009079,
          0.4944484233856201,
          0.496695339679718,
          0.5012965202331543,
          0.48425906896591187,
          0.4785376489162445,
          0.4785105586051941,
          0.5058252811431885,
          0.48337653279304504,
          0.4835813641548157,
          0.48896461725234985,
          0.4830928444862366,
          0.48346248269081116,
          0.4781675338745117,
          0.4653785228729248,
          0.4868116080760956,
          0.47665759921073914,
          0.4693427085876465,
          0.48145633935928345,
          0.5298944711685181,
          0.45942580699920654,
          0.4838981032371521,
          0.47981300950050354,
          0.5188224911689758,
          0.46779048442840576,
          0.49810662865638733,
          0.49386703968048096,
          0.5143960118293762,
          0.005135521292686462,
          0.9999977946281433,
          0.5122105479240417,
          0.5156905055046082,
          0.4925457537174225,
          0.47604286670684814,
          0.49590811133384705,
          0.48021289706230164,
          0.47576048970222473,
          0.4806405305862427,
          0.5070186853408813,
          0.6114433407783508,
          0.49508675932884216,
          0.46576598286628723,
          0.4748086929321289,
          0.48190227150917053,
          0.4725504219532013,
          0.4904320538043976,
          0.500606119632721,
          0.4741095006465912,
          0.47882330417633057,
          0.4425275921821594,
          0.49705344438552856,
          0.45529904961586,
          0.49663540720939636,
          0.4762611389160156,
          0.44396790862083435,
          0.47674623131752014,
          0.455160915851593,
          0.47122272849082947,
          0.4631493091583252,
          0.5124825835227966,
          0.49260708689689636,
          0.4852869510650635,
          0.4624444544315338,
          0.46676263213157654,
          0.47107475996017456,
          0.4791606366634369,
          0.45940130949020386,
          0.4764508306980133,
          0.5067552328109741,
          0.44573527574539185,
          0.4805983006954193,
          0.4880611002445221,
          0.5150599479675293,
          0.5011325478553772,
          0.4251379370689392,
          0.4797613322734833,
          0.49514240026474,
          0.48894578218460083,
          0.5039269328117371,
          0.484794020652771,
          0.4891118109226227,
          0.4911755919456482,
          0.5062490105628967,
          0.4794221818447113,
          0.46680307388305664,
          0.46255287528038025,
          0.48576536774635315,
          0.4821698069572449,
          0.4864113926887512,
          0.4960101544857025,
          0.44460514187812805,
          0.47960785031318665,
          0.48348119854927063,
          0.5221707224845886,
          0.4708627164363861,
          0.47527921199798584,
          0.48552048206329346,
          0.4712541401386261,
          0.5136261582374573,
          0.47485366463661194,
          0.5053935050964355,
          0.4729789197444916,
          0.45570677518844604,
          0.4797290563583374,
          0.5056574940681458,
          0.48677876591682434,
          0.46891167759895325,
          0.5223017334938049,
          0.47562170028686523,
          0.48995980620384216,
          0.5098294615745544,
          0.48923712968826294,
          0.47721606492996216,
          0.4970284402370453,
          0.5008535385131836,
          0.4795154631137848,
          0.47316792607307434,
          0.48325279355049133,
          0.36791881918907166,
          0.47098392248153687,
          0.46825140714645386,
          0.4713630676269531,
          0.4974295496940613,
          0.47870808839797974,
          0.4805658757686615,
          0.49250510334968567,
          0.4725900888442993,
          0.4775144159793854,
          0.49300915002822876,
          0.5122946500778198,
          0.4967649281024933,
          0.45276299118995667,
          0.45340245962142944,
          0.45682141184806824,
          0.4593190550804138,
          0.48574915528297424,
          0.492794007062912,
          0.4823644161224365,
          0.47325822710990906,
          0.49606719613075256,
          0.4412502348423004,
          0.4633816182613373,
          0.4738927185535431,
          0.4794192314147949,
          0.46609658002853394,
          0.49339190125465393,
          0.49163079261779785,
          0.48591160774230957,
          0.4713188707828522,
          0.48073458671569824,
          0.47408026456832886,
          0.4883173704147339,
          0.4758552014827728,
          0.49291306734085083,
          0.510175883769989,
          0.4978140592575073,
          0.48562508821487427,
          0.4847433567047119,
          0.4811500906944275,
          0.49848079681396484,
          0.48522627353668213,
          0.4823776185512543,
          0.497618168592453,
          0.46416202187538147,
          0.47153475880622864,
          0.48089349269866943,
          0.49381527304649353,
          0.4768129885196686,
          0.4728579819202423,
          0.5020965337753296,
          0.4952942132949829,
          0.47968947887420654,
          0.4801146984100342,
          0.47670289874076843,
          0.5069418549537659,
          0.45925381779670715,
          0.47200682759284973,
          0.46182316541671753,
          0.4786928594112396,
          0.4752303659915924,
          0.5037358403205872,
          0.48644155263900757,
          0.4775851368904114,
          0.5074971914291382,
          0.4794602394104004,
          0.45721954107284546,
          0.4529855251312256,
          0.5093238949775696,
          0.5139201879501343,
          0.45760101079940796,
          0.48195868730545044,
          0.49402791261672974,
          0.4958876371383667,
          0.48976171016693115,
          0.443344384431839,
          0.49021387100219727,
          0.5072221159934998,
          0.47836068272590637,
          0.4990599453449249,
          0.49179646372795105,
          0.4794148802757263,
          0.4874725937843323,
          0.47664883732795715,
          0.47583696246147156,
          0.4634624123573303,
          0.49841296672821045,
          0.49448302388191223,
          0.4831242561340332,
          0.49279797077178955,
          0.4806790053844452,
          0.4828207194805145,
          0.49802297353744507,
          0.5017995834350586,
          0.4861840605735779,
          0.49606895446777344,
          0.4720301032066345,
          0.465114951133728,
          0.5211612582206726,
          0.49807846546173096,
          0.4595029354095459,
          0.4867948591709137,
          0.5030864477157593,
          0.5028387904167175,
          0.4641726315021515,
          0.4859123229980469,
          0.4757758378982544,
          0.5062804222106934,
          0.49508213996887207,
          0.47026702761650085,
          0.47845378518104553,
          0.4706072509288788,
          0.47408127784729004,
          0.47034600377082825,
          0.48208582401275635,
          0.48026812076568604,
          0.48383569717407227,
          0.4819743037223816,
          0.4811490774154663,
          0.4594707489013672,
          0.5269952416419983,
          0.5401028394699097,
          0.4834288954734802,
          0.49555885791778564,
          0.49265071749687195,
          0.4802178144454956,
          0.4925386905670166,
          0.4742301106452942,
          0.5233983397483826,
          0.5081273317337036,
          0.4960184693336487,
          0.4802159070968628,
          0.4665139615535736,
          0.46503591537475586,
          0.46984031796455383,
          0.5018891096115112,
          0.4719540476799011,
          0.4754246473312378,
          0.46987998485565186,
          0.48783862590789795,
          0.49190419912338257,
          0.46755892038345337,
          0.4713260531425476,
          0.49133747816085815,
          0.4950345754623413,
          0.47018158435821533,
          0.4774181842803955,
          0.4756169021129608,
          0.4609222114086151,
          0.47835034132003784,
          0.49837854504585266,
          0.48763173818588257,
          0.4483668804168701,
          0.492705762386322,
          0.4987674653530121,
          0.47259923815727234,
          0.4683878421783447,
          0.5113999247550964,
          0.524440586566925,
          0.4735656976699829,
          0.47508031129837036,
          0.4908863306045532,
          0.49444714188575745,
          0.4897654354572296,
          0.47563549876213074,
          0.47540706396102905,
          0.47596412897109985,
          0.48112115263938904,
          0.5257270932197571,
          0.4980866312980652,
          0.4853071868419647,
          0.4735773205757141,
          0.5332886576652527,
          0.48722007870674133,
          0.47174227237701416,
          0.5292099118232727,
          0.4937962293624878,
          0.47829800844192505,
          0.48040270805358887,
          0.47253596782684326,
          0.5012269020080566,
          0.4995090067386627,
          0.480563223361969,
          0.4892512857913971,
          0.4869047999382019,
          0.4790689945220947,
          0.4752310812473297,
          0.48465535044670105,
          0.5149390697479248,
          0.4735156297683716,
          0.4930165112018585,
          0.49194785952568054,
          0.4765271544456482,
          0.46444058418273926,
          0.47005411982536316,
          0.46489474177360535,
          0.47101813554763794,
          0.4788401126861572,
          0.48906072974205017,
          0.4851174056529999,
          0.5009750723838806,
          0.49065840244293213,
          0.5055515766143799,
          0.5080428123474121,
          0.48821499943733215,
          0.4843693971633911,
          0.5042701959609985,
          0.49870648980140686,
          0.49696996808052063,
          0.5057163834571838,
          0.48534756898880005,
          0.5014716386795044,
          0.5034724473953247,
          0.5071493983268738,
          0.4753704071044922,
          0.5099589228630066,
          0.48615849018096924,
          0.5008175373077393,
          0.484178364276886,
          0.47618788480758667,
          0.4936823546886444,
          0.47821244597435,
          0.47561103105545044,
          0.49278759956359863,
          0.500493586063385,
          0.4575434625148773,
          0.46315184235572815,
          0.4832715392112732,
          0.4940289855003357,
          0.4997198283672333,
          0.4815463125705719,
          0.47211968898773193,
          0.5063283443450928,
          0.48987290263175964,
          0.46766993403434753,
          0.48089611530303955,
          0.4919452965259552,
          0.48988044261932373,
          0.4846210181713104,
          0.4994395077228546,
          0.4817708432674408,
          0.46986255049705505,
          0.4546128213405609,
          0.4948417842388153,
          0.47816935181617737,
          0.4797918498516083,
          0.4872446358203888,
          0.46547165513038635,
          0.5070660710334778,
          0.45270946621894836,
          0.4743732213973999,
          0.492171972990036,
          0.4983637034893036,
          0.47465255856513977,
          0.5054023861885071,
          0.5104182958602905,
          0.46773993968963623,
          0.49341100454330444,
          0.47076356410980225,
          0.45905765891075134,
          0.5110529661178589,
          0.49676260352134705,
          0.4865756630897522,
          0.46215903759002686,
          0.5083065032958984,
          0.509131133556366,
          0.511949896812439,
          0.49351614713668823,
          0.49918046593666077,
          0.45721495151519775,
          0.4766159951686859,
          0.5024855136871338,
          0.4822130799293518,
          0.5108853578567505,
          0.48314574360847473,
          0.4475075900554657,
          0.5063593983650208,
          0.47767582535743713,
          0.5015037655830383,
          0.48080122470855713,
          0.4520938992500305,
          0.49256354570388794,
          0.46107637882232666,
          0.4657701253890991,
          0.47555917501449585,
          0.46333202719688416,
          0.6016749143600464,
          0.48574769496917725,
          0.46608346700668335,
          0.4908081889152527,
          0.471794456243515,
          0.4880572557449341,
          0.5169349908828735,
          0.48760807514190674,
          0.4750187397003174,
          0.4960970878601074,
          0.48901835083961487,
          0.4695183336734772,
          0.5094985365867615,
          0.4823542535305023,
          0.48286452889442444,
          0.4786613881587982,
          0.4677548408508301,
          0.48884132504463196,
          0.4918046295642853,
          0.4836607575416565,
          0.4729474186897278,
          0.48719123005867004,
          0.5123831629753113,
          0.4962462782859802,
          0.4921987056732178,
          0.4639962315559387,
          0.4867643117904663,
          0.47139495611190796,
          0.49453163146972656,
          0.47620055079460144,
          0.46681198477745056,
          0.5550443530082703,
          0.4871275722980499,
          0.5177950859069824,
          0.4856571555137634,
          0.4924023747444153,
          0.4648823142051697,
          0.48832646012306213,
          0.46275249123573303,
          0.47572964429855347,
          0.4965139329433441,
          0.4697260558605194,
          0.48309335112571716,
          0.5035712122917175,
          0.49523448944091797,
          0.463019996881485,
          0.48277416825294495,
          0.5147697329521179,
          0.49573299288749695,
          0.48471927642822266,
          0.4438633322715759,
          0.48459964990615845,
          0.721729576587677,
          0.44594377279281616,
          0.47622787952423096,
          0.4877970814704895,
          0.49123620986938477,
          0.4919131100177765,
          0.4661445617675781,
          0.49048537015914917,
          0.5015162229537964,
          0.48440486192703247,
          0.4708273410797119,
          0.4840133488178253,
          0.4816216230392456,
          0.462997168302536,
          0.47967109084129333,
          0.48109087347984314,
          0.47887060046195984,
          0.47359710931777954,
          0.4724898040294647,
          0.4773170053958893,
          0.38509702682495117,
          0.5330044627189636,
          0.4923481345176697,
          0.47749096155166626,
          0.4932134449481964,
          0.46707257628440857,
          0.4955146014690399,
          0.4994905889034271,
          0.4872996509075165,
          0.4828638732433319,
          0.47190213203430176,
          0.4874086081981659,
          0.49912261962890625,
          0.4801551401615143,
          0.5243922472000122,
          0.48983514308929443,
          0.48758336901664734,
          0.4879828095436096,
          0.47855493426322937,
          0.4704844355583191,
          0.4866209924221039,
          0.4990667700767517,
          0.49548274278640747,
          0.4788575768470764,
          0.49225232005119324,
          0.4846881031990051,
          0.48431357741355896,
          0.49866604804992676,
          0.4684343934059143,
          0.4936944544315338,
          0.4671356678009033,
          0.4932510256767273,
          0.47653716802597046,
          0.4832843542098999,
          0.4748668074607849,
          0.4808853268623352,
          0.46988633275032043,
          0.4840559959411621,
          0.5044023990631104,
          0.47583335638046265,
          0.4687267541885376,
          0.4919337034225464,
          0.4848189353942871,
          0.48699742555618286,
          0.46151864528656006,
          0.4953882396221161,
          0.4699581563472748,
          0.49389520287513733,
          0.9999942779541016,
          0.5091589689254761,
          0.49223268032073975,
          0.43249279260635376,
          0.48780587315559387,
          0.47026944160461426,
          0.48894616961479187,
          0.47275781631469727,
          0.4897196292877197,
          0.4600629210472107,
          0.49997156858444214,
          0.49942436814308167,
          0.49640804529190063,
          0.4989367127418518,
          0.4797835052013397,
          0.49432751536369324,
          0.4855637848377228,
          0.4827602803707123,
          0.4991777539253235,
          0.45851537585258484,
          0.4864869713783264,
          0.4822123944759369,
          0.48119136691093445,
          0.4798245429992676,
          0.49309298396110535,
          0.48008042573928833,
          0.4645916521549225,
          0.4786357581615448,
          0.46351879835128784,
          0.48710009455680847,
          0.4858032464981079,
          0.4967239499092102,
          0.47374382615089417,
          0.49592435359954834,
          0.4700528085231781,
          0.47316524386405945,
          0.5418096780776978,
          0.48638075590133667,
          0.49798116087913513,
          0.4871179759502411,
          0.4938350021839142,
          0.46544790267944336,
          0.5178297758102417,
          0.4948045611381531,
          0.5018707513809204,
          0.47472983598709106,
          0.49585282802581787,
          0.4912445843219757,
          0.47296765446662903,
          0.49297893047332764,
          0.47948622703552246,
          0.4885734021663666,
          0.4728507697582245,
          0.48851674795150757,
          0.4875982999801636,
          0.4926661550998688,
          0.4543222486972809,
          0.4870269000530243,
          0.4770342707633972,
          0.4743706285953522,
          0.4756348729133606,
          0.5036881566047668,
          0.4924549162387848,
          0.4359482228755951,
          0.517745316028595,
          0.48623913526535034,
          0.46890342235565186,
          0.500346839427948,
          0.47402164340019226,
          0.4967527687549591,
          0.47269436717033386,
          0.48724669218063354,
          0.4908519685268402,
          0.4735274016857147,
          0.4778446555137634,
          0.5141101479530334,
          0.4789183735847473,
          0.48092207312583923,
          0.467569500207901,
          0.48113736510276794,
          0.42721739411354065,
          0.4840155243873596,
          0.47681331634521484,
          0.5083631873130798,
          0.46262699365615845,
          0.4962198734283447,
          0.5050982236862183,
          0.46507832407951355,
          0.4849485754966736,
          0.48387661576271057,
          0.46490058302879333,
          0.4915477931499481,
          0.49662095308303833,
          0.48261046409606934,
          0.5097205638885498,
          0.46724021434783936,
          0.5047206878662109,
          0.48224422335624695,
          0.47842565178871155,
          0.5003989338874817,
          0.4809665083885193,
          0.4656504988670349,
          0.4559550881385803,
          0.4921185374259949,
          0.498289555311203,
          0.49286705255508423,
          0.511268675327301,
          0.4649195671081543,
          0.4804423153400421,
          0.47704342007637024,
          0.4841572046279907,
          0.47010308504104614,
          0.4660749137401581,
          0.4800432622432709,
          0.46631067991256714,
          0.4868433475494385,
          0.49184486269950867,
          0.5208907723426819,
          0.4698527753353119,
          0.5020256042480469,
          0.4012388288974762,
          0.4756210148334503,
          0.5008120536804199,
          0.4852675199508667,
          0.49699437618255615,
          0.4922238290309906,
          0.4718688130378723,
          0.49429354071617126,
          0.4669448435306549,
          0.47357892990112305,
          0.4922923147678375,
          0.4861209988594055,
          0.48900559544563293,
          0.5293118953704834,
          0.4975050389766693,
          0.47162848711013794,
          0.49810174107551575,
          0.5036169290542603,
          0.5045626163482666,
          0.4718828797340393,
          0.5209617614746094,
          0.45974549651145935,
          0.44548726081848145,
          0.48595675826072693,
          0.48013627529144287,
          0.4723708927631378,
          0.4610830247402191,
          0.4692422151565552,
          0.4742601811885834,
          0.47627678513526917,
          0.49267539381980896,
          0.436409592628479,
          0.49500107765197754,
          0.4781050682067871,
          0.4723781943321228,
          0.49204713106155396,
          0.4960387647151947,
          0.4604693055152893,
          0.4799109697341919,
          0.5004884004592896,
          0.48185116052627563,
          0.4794333279132843,
          0.47919580340385437,
          0.46034911274909973,
          0.4992919862270355,
          0.5021327137947083,
          0.48406487703323364,
          0.47982093691825867,
          0.5190288424491882,
          0.48339688777923584,
          0.4965037405490875,
          0.45197227597236633,
          0.47932544350624084,
          0.4830286204814911,
          0.4727496802806854,
          0.47935596108436584,
          0.4569113552570343,
          0.504677951335907,
          0.4991791546344757,
          0.4761633276939392,
          0.47083625197410583,
          0.4822136163711548,
          0.4908389449119568,
          0.4464362859725952,
          0.5010024905204773,
          0.42827168107032776,
          0.48197734355926514,
          0.5402448177337646,
          0.5000339150428772,
          0.6266230940818787,
          0.4406726658344269,
          0.5052058100700378,
          0.4606519639492035,
          0.49414849281311035,
          0.4674984812736511,
          0.49425432085990906,
          0.5008590221405029,
          0.44589462876319885,
          0.46937593817710876,
          0.501095712184906,
          0.4719964265823364,
          0.4987435042858124,
          0.49149224162101746,
          0.4961529076099396,
          0.4857245981693268,
          0.4543301463127136,
          0.4884851574897766,
          0.4442637264728546,
          0.4857003092765808,
          0.522616982460022,
          0.5095802545547485,
          0.48288196325302124,
          0.4736640453338623,
          0.46551862359046936,
          0.46123698353767395,
          6.943312473595142e-05,
          0.49338245391845703,
          0.5544229745864868,
          0.4680970311164856,
          0.4939074218273163,
          0.49657055735588074,
          0.48875588178634644,
          0.4460899829864502,
          0.4963586628437042,
          0.4832507371902466,
          0.4783152937889099,
          0.4792540371417999,
          0.4813826382160187,
          0.45955246686935425,
          0.4775267243385315,
          0.4677208662033081,
          0.4842972159385681,
          0.5346496105194092,
          0.4812978506088257,
          0.45108315348625183,
          0.506476640701294,
          0.422275573015213,
          0.4776034355163574,
          0.9999587535858154,
          0.4486311376094818,
          0.46661561727523804,
          0.4848826825618744,
          0.49066057801246643,
          0.47445011138916016,
          0.4693725109100342,
          0.4869517982006073,
          0.5009325742721558,
          0.49710914492607117,
          0.5149183869361877,
          0.45057713985443115,
          0.4997579753398895,
          0.49683716893196106,
          0.47267255187034607,
          0.5086429715156555,
          0.49890416860580444,
          0.483689546585083,
          0.5158076882362366,
          0.48462507128715515,
          0.5117977857589722,
          0.47649165987968445,
          0.4747893512248993,
          0.4709828794002533,
          0.48023635149002075,
          0.4837549030780792,
          0.5081459283828735,
          0.4832307696342468,
          0.496818870306015,
          0.46676501631736755,
          0.48076745867729187,
          0.5015044808387756,
          0.49213430285453796,
          0.4918704330921173,
          0.45504868030548096,
          0.4594321548938751,
          0.4842073619365692,
          0.47695842385292053,
          0.4683891534805298,
          0.5119030475616455,
          0.46018585562705994,
          0.4968816041946411,
          0.4765402376651764,
          0.48963961005210876,
          0.48255059123039246,
          0.4922623634338379,
          0.4666427969932556,
          0.4257034361362457,
          0.4769956171512604,
          0.36161354184150696,
          0.4783327281475067,
          0.4161897897720337,
          0.46311721205711365,
          0.48559215664863586,
          0.4895315170288086,
          0.4677208662033081,
          0.45138630270957947,
          0.5077452659606934,
          0.48075583577156067,
          0.49118590354919434,
          0.4731839895248413,
          0.4816872477531433,
          0.4723847210407257,
          0.500214159488678,
          0.5036917924880981,
          0.4814145267009735,
          0.4839102327823639,
          0.5012821555137634,
          0.44316115975379944,
          0.46233585476875305,
          0.4785597622394562,
          0.44131210446357727,
          0.5213212966918945,
          0.48429542779922485,
          0.4805850386619568,
          0.4897201657295227,
          0.507470428943634,
          0.5032227635383606,
          0.47991615533828735,
          0.5065054297447205,
          0.46302148699760437,
          0.49985164403915405,
          0.4964125454425812,
          0.47701796889305115,
          0.49686160683631897,
          0.49216899275779724,
          0.4817964732646942,
          0.5668823719024658,
          0.48548978567123413,
          0.43026310205459595,
          0.48371124267578125,
          0.49922898411750793,
          0.4833458364009857,
          0.46668490767478943,
          0.47604501247406006,
          0.4812140464782715,
          0.4815128743648529,
          0.48200130462646484,
          0.4607812762260437,
          0.4848734438419342,
          0.5091649889945984,
          0.4952494204044342,
          0.4956044554710388,
          0.49254313111305237,
          0.48067009449005127,
          0.46325159072875977,
          0.4798870384693146,
          0.5068737268447876,
          0.44464173913002014,
          0.4791829288005829,
          0.48493248224258423,
          0.49360892176628113,
          0.5373669266700745,
          0.4757031798362732,
          0.4877367615699768,
          0.4924270808696747,
          0.4941260516643524,
          0.4713304042816162,
          0.48117098212242126,
          0.48970407247543335,
          0.4733855426311493,
          0.48506903648376465,
          0.48902493715286255,
          0.47822052240371704,
          0.5170361995697021,
          0.4876224994659424,
          0.429381787776947,
          0.47071006894111633,
          0.4629615843296051,
          0.4771210253238678,
          0.4789254665374756,
          0.47202855348587036,
          0.49598053097724915,
          0.4792080819606781,
          0.47568678855895996,
          0.4878649115562439,
          0.46213850378990173,
          0.48077407479286194,
          0.4740530550479889,
          0.4782025218009949,
          0.4525117874145508,
          0.4878438413143158,
          0.4751644730567932,
          0.5131164193153381,
          0.4901387691497803,
          0.5224816799163818,
          0.4772619903087616,
          0.49347275495529175,
          0.49399659037590027,
          0.48864424228668213,
          0.472851037979126,
          0.4700024127960205,
          0.5037054419517517,
          0.45295336842536926,
          0.5231131315231323,
          0.48982739448547363,
          0.46769529581069946,
          0.4154091477394104,
          0.48392075300216675,
          0.47682639956474304,
          0.4594148099422455,
          0.49587947130203247,
          0.479612797498703,
          0.48406386375427246,
          0.4672800600528717,
          0.48369479179382324,
          0.47852998971939087,
          0.49123045802116394,
          0.47072917222976685,
          0.47058212757110596,
          0.4846177399158478,
          0.4862576127052307,
          0.47018274664878845,
          0.4829946756362915,
          0.48524075746536255,
          0.46304991841316223,
          0.4772621989250183,
          0.47895997762680054,
          0.48822179436683655,
          0.5103216171264648,
          0.4732765257358551,
          0.49024927616119385,
          0.4887741804122925,
          0.4721038043498993,
          0.49657195806503296,
          0.4660646617412567,
          0.5095348358154297,
          0.4838468134403229,
          0.4952861964702606,
          0.5061253905296326,
          0.5209048986434937,
          0.4794570505619049,
          0.47729092836380005,
          0.4843027889728546,
          0.48229673504829407,
          0.4970179498195648,
          0.47342759370803833,
          0.44899237155914307,
          0.4640398919582367,
          0.48961809277534485,
          0.9699673056602478,
          0.4928243160247803,
          0.4626193940639496,
          0.5033506751060486,
          0.4744683802127838,
          0.5049694776535034,
          0.4915044605731964,
          0.45229464769363403,
          0.49040934443473816,
          0.529174268245697,
          0.45738252997398376,
          0.9999987483024597,
          0.5359945297241211,
          0.4692843556404114,
          0.49519288539886475,
          0.49218299984931946,
          0.44749024510383606,
          0.4809027910232544,
          0.4637254774570465,
          0.4595952033996582,
          0.5085399746894836,
          0.4869426190853119,
          0.4767586886882782,
          0.490161657333374,
          0.48264768719673157,
          0.5149146914482117,
          0.49958905577659607,
          0.5782001614570618,
          0.484025239944458,
          0.45505204796791077,
          0.4556487202644348,
          0.4801355302333832,
          0.4718778133392334,
          0.48575523495674133,
          0.48403483629226685,
          0.48815152049064636,
          0.5067659616470337,
          0.4813965857028961,
          0.5593498945236206,
          0.49946823716163635,
          0.5226496458053589,
          0.5026513338088989,
          0.47927170991897583,
          0.47129377722740173,
          0.470320463180542,
          0.5372424721717834,
          0.4914795160293579,
          0.4931948781013489,
          0.48934048414230347,
          0.5178767442703247,
          0.5296005606651306,
          0.467365026473999,
          0.4746673107147217,
          0.4825957715511322,
          0.5119138956069946,
          0.4881630539894104,
          0.4840743839740753,
          0.503607451915741,
          0.4695281982421875,
          0.48767024278640747,
          0.5498641729354858,
          0.475888729095459,
          0.46442413330078125,
          0.466947078704834,
          0.4791654646396637,
          0.498680979013443,
          0.46735262870788574,
          0.4872018098831177,
          0.47692111134529114,
          0.48953184485435486,
          0.4708942472934723,
          0.47901561856269836,
          0.5284488797187805,
          0.5024259686470032,
          0.48113036155700684,
          0.5298195481300354,
          0.4699994921684265,
          0.49681293964385986,
          0.4737226665019989,
          0.4787349998950958,
          0.4994131028652191,
          0.4698503315448761,
          0.49359890818595886,
          0.487232506275177,
          0.48510199785232544,
          0.4889060854911804,
          0.4645446240901947,
          0.47469988465309143,
          0.4542126953601837,
          0.48325586318969727,
          0.466087281703949,
          0.495496928691864,
          0.4934878349304199,
          0.49372467398643494,
          0.5094174146652222,
          0.5187650918960571,
          0.45970359444618225,
          0.4784744679927826,
          0.4804179072380066,
          0.4923534393310547,
          0.30743926763534546,
          0.46625810861587524,
          0.479002982378006,
          0.47758573293685913,
          0.4800146520137787,
          0.4834789037704468,
          0.47560814023017883,
          0.4859829843044281,
          0.497374027967453,
          0.48797449469566345,
          0.47971034049987793,
          0.46652621030807495,
          0.48981234431266785,
          0.465152770280838,
          0.4884408116340637,
          0.49242129921913147,
          0.5006951689720154,
          0.48822420835494995,
          0.4815828204154968,
          0.49974939227104187,
          0.4993307590484619,
          0.47877025604248047,
          0.4994257390499115,
          0.47275426983833313,
          0.45896339416503906,
          0.48276615142822266,
          0.4917853772640228,
          0.49082842469215393,
          0.4503987729549408,
          0.5164989233016968,
          0.47261372208595276,
          0.5070475339889526,
          0.4778364300727844,
          0.4988178014755249,
          0.49014633893966675,
          0.4876108169555664,
          0.4941459000110626,
          0.4740338623523712,
          0.5846864581108093,
          0.49706393480300903,
          0.4876140356063843,
          0.4774833023548126,
          0.4949721395969391,
          0.4743438959121704,
          0.4897477328777313,
          0.46006643772125244,
          0.49513962864875793,
          0.5122948288917542,
          0.4537559151649475,
          0.49556079506874084,
          0.4870225489139557,
          0.4893285036087036,
          0.5115801692008972,
          0.4796393811702728,
          0.4694846272468567,
          0.4751143157482147,
          0.4914311170578003,
          0.47872716188430786,
          8.400338629144244e-06,
          0.5010570287704468,
          0.4840351641178131,
          0.5509150624275208,
          0.4826587736606598,
          0.500467836856842,
          0.5128141045570374,
          0.5038466453552246,
          0.5103940963745117,
          0.47926050424575806,
          0.47803401947021484,
          0.5044296383857727,
          0.4610733985900879,
          0.4908173978328705,
          0.4811616837978363,
          0.49627357721328735,
          0.5004076361656189,
          0.4926016926765442,
          0.48761308193206787,
          0.5046711564064026,
          0.49174803495407104,
          0.53117436170578,
          0.46285802125930786,
          0.46704158186912537,
          0.46471497416496277,
          0.5011579394340515,
          0.49537256360054016,
          0.5074624419212341,
          0.4657139182090759,
          0.5424017310142517,
          0.4978821277618408,
          0.4716481864452362,
          0.5056057572364807,
          0.4495989680290222,
          0.4627265930175781,
          0.4857228994369507,
          0.4606020748615265,
          0.4715174436569214,
          0.48601779341697693,
          0.511121392250061,
          0.4964207410812378,
          0.4813779294490814,
          0.48506754636764526,
          0.46680471301078796,
          0.47546643018722534,
          0.4935503900051117,
          0.45801877975463867,
          0.4926719665527344,
          0.4808953106403351,
          0.4983058273792267,
          0.48976463079452515,
          0.4593797028064728,
          0.4942401349544525,
          0.48122334480285645,
          0.5008530020713806,
          0.4631606936454773,
          0.4683896601200104,
          0.5005195140838623,
          0.47250568866729736,
          0.47663241624832153,
          0.5175136923789978,
          0.4925954341888428,
          0.4860779345035553,
          0.4827965199947357,
          0.45392680168151855,
          0.47506192326545715,
          0.4604097604751587,
          0.4863530695438385,
          0.4863080680370331,
          0.4871978163719177,
          0.5319564342498779,
          0.4606575071811676,
          0.4958149492740631,
          0.5070241689682007,
          0.4842227101325989,
          0.498663991689682,
          0.46791550517082214,
          0.486218124628067,
          0.5143744945526123,
          0.47854650020599365,
          0.5234922766685486,
          0.4821940064430237,
          0.5010845065116882,
          0.500576376914978,
          0.4865989089012146,
          0.4904380738735199,
          0.4770148992538452,
          0.5038844347000122,
          0.5172247290611267,
          0.48495498299598694,
          0.48483628034591675,
          0.4770267903804779,
          0.4797597825527191,
          0.48189011216163635,
          0.5073891282081604,
          0.46431097388267517,
          0.445887953042984,
          0.4980461597442627,
          0.46357184648513794,
          0.4758182764053345,
          0.4542132019996643,
          0.471084862947464,
          0.5023674964904785,
          0.4889432191848755,
          0.00023267546202987432,
          0.47671666741371155,
          0.4569268524646759,
          0.488650918006897,
          0.45877620577812195,
          0.4859530031681061,
          0.49390652775764465,
          0.4948733448982239,
          0.4896342158317566,
          0.46189549565315247,
          0.4920184016227722,
          0.4751623272895813,
          0.4734090268611908,
          0.4951990842819214,
          0.5021789073944092,
          0.48693418502807617,
          0.4865463376045227,
          0.5097519159317017,
          0.4704209268093109,
          0.4961917996406555,
          0.49907177686691284,
          0.5131713151931763,
          0.480768084526062,
          0.486889511346817,
          0.45326298475265503,
          0.4851701259613037,
          0.44930124282836914,
          0.4738985002040863,
          0.48473265767097473,
          0.48197028040885925,
          0.49420401453971863,
          0.4805399179458618,
          0.4957764744758606,
          0.48064613342285156,
          0.4824248254299164,
          0.4447326958179474,
          0.4709876775741577,
          0.4860524535179138,
          0.48428070545196533,
          0.49815988540649414,
          0.4679276645183563,
          0.5045807957649231,
          0.4942662715911865,
          0.4812110960483551,
          0.46576637029647827,
          0.6632130742073059,
          0.503940761089325,
          0.5155450105667114,
          0.47207847237586975,
          0.4973248243331909,
          0.4979252517223358,
          0.5190972089767456,
          0.46630942821502686,
          0.4987506866455078,
          0.4597318768501282,
          0.5153988599777222,
          0.4791429042816162,
          0.4756013751029968,
          0.45467787981033325,
          0.47832465171813965,
          0.4811287522315979,
          0.465111643075943,
          0.468455046415329,
          0.4767746925354004,
          0.47573089599609375,
          0.5070134401321411,
          0.486990362405777,
          0.4728662967681885,
          0.47820213437080383,
          0.4754023551940918,
          0.4821456968784332,
          0.4645470380783081,
          0.5012168884277344,
          0.5141687989234924,
          0.49173080921173096,
          0.5008028745651245,
          0.4164991080760956,
          0.47929975390434265,
          0.48312363028526306,
          0.41749343276023865,
          0.4639418125152588,
          0.4676562547683716,
          0.4610831141471863,
          0.478509783744812,
          0.503086268901825,
          0.503311812877655,
          0.47139251232147217,
          0.4798981845378876,
          0.4631519913673401,
          0.4923660159111023,
          0.465759813785553,
          0.4864867031574249,
          0.47853487730026245,
          0.4817062318325043,
          0.4791313111782074,
          0.49279046058654785,
          0.5076999664306641,
          0.45765137672424316,
          0.49458131194114685,
          0.48403388261795044,
          0.4831272065639496,
          0.4849594533443451,
          0.4777895212173462,
          0.4646381437778473,
          0.4626515805721283,
          0.49867668747901917,
          0.48398151993751526,
          0.4850814640522003,
          0.47353726625442505,
          0.9999909400939941,
          0.4842928647994995,
          1.7259085325349588e-06,
          0.46867236495018005,
          0.4740334153175354,
          0.4874504804611206,
          0.46708738803863525,
          0.6431869864463806,
          0.4784336984157562,
          0.45924097299575806,
          0.4911347031593323,
          0.4437226355075836,
          0.4901067912578583,
          0.5016449093818665,
          0.47682836651802063,
          0.4905948042869568,
          0.49659690260887146,
          0.4696080684661865,
          0.5070614814758301,
          0.4749358594417572,
          0.4620518088340759,
          0.4876058101654053,
          0.48594287037849426,
          0.4664255380630493,
          0.4847799241542816,
          0.4703838527202606,
          0.4986954927444458,
          0.4663451313972473,
          0.4981198012828827,
          0.4966903626918793,
          0.44193708896636963,
          0.4746776223182678,
          0.4814682900905609,
          0.4668486416339874,
          0.49560797214508057,
          0.5324215888977051,
          0.46640583872795105,
          0.5085766911506653,
          0.4788450002670288,
          0.4884195625782013,
          0.477314293384552,
          0.48718252778053284,
          0.4655543267726898,
          0.48474252223968506,
          0.4786640405654907,
          0.49333974719047546,
          0.4904322028160095,
          0.47640785574913025,
          0.49477019906044006,
          0.5100462436676025,
          0.48520639538764954,
          0.4940376281738281,
          0.4989580810070038,
          0.4749559760093689,
          0.47414830327033997,
          0.47214221954345703,
          0.4686502516269684,
          0.4794875383377075,
          0.48023977875709534,
          0.4867996275424957,
          0.49464672803878784,
          0.4701290428638458,
          0.4999901056289673,
          0.47754910588264465,
          0.4812754690647125,
          0.5516448020935059,
          0.4897749722003937,
          0.501841127872467,
          0.4874284565448761,
          0.47345638275146484,
          0.48987147212028503,
          0.4784824252128601,
          0.496660441160202,
          0.48422297835350037,
          0.493012398481369,
          0.4940256178379059,
          0.49361395835876465,
          0.453556090593338,
          0.49404019117355347,
          0.47821876406669617,
          0.4954405725002289,
          0.47523748874664307,
          0.4601280689239502,
          0.4948694407939911,
          0.4931078553199768,
          0.452872097492218,
          0.470969557762146,
          0.4860571622848511,
          0.49495023488998413,
          0.49557608366012573,
          0.47133752703666687,
          0.4803718626499176,
          0.44597500562667847,
          0.4998118579387665,
          0.4991576373577118,
          0.48034825921058655,
          0.5121157765388489,
          0.48619264364242554,
          0.5044399499893188,
          0.4815381169319153,
          0.484973281621933,
          0.4818623661994934,
          0.5178344249725342,
          0.4841998517513275,
          0.48002585768699646,
          0.5036826729774475,
          0.48863983154296875,
          0.49714916944503784,
          0.5118688344955444,
          0.5077694058418274,
          0.43815749883651733,
          0.5389995574951172,
          0.5183058977127075,
          0.4878775477409363,
          0.4925227165222168,
          0.4883953928947449,
          0.5095657110214233,
          0.47641825675964355,
          0.4966410994529724,
          0.48177215456962585,
          0.4651673436164856,
          0.4955160915851593,
          0.48415112495422363,
          0.4606158435344696,
          0.49271509051322937,
          0.47334975004196167,
          0.48187533020973206,
          0.4448586702346802,
          0.47559288144111633,
          0.5080313086509705,
          0.46851128339767456,
          0.5048336982727051,
          0.4692712426185608,
          0.4825069010257721,
          0.506136953830719,
          0.49436235427856445,
          0.5194095373153687,
          0.490666002035141,
          0.5137240290641785,
          0.46655547618865967,
          0.488258421421051,
          0.4888341724872589,
          0.5588375926017761,
          0.49343132972717285,
          0.4651985168457031,
          0.5741216540336609,
          0.4972580075263977,
          0.4827617406845093,
          0.4821358621120453,
          0.4648371934890747,
          0.4919571578502655,
          0.475454717874527,
          0.4527725875377655,
          0.49738702178001404,
          0.4770577549934387,
          0.4807295501232147,
          0.4892292320728302,
          0.5054391622543335,
          0.5029680728912354,
          0.4815308451652527,
          0.46727365255355835,
          0.4811781644821167,
          0.48875439167022705,
          0.5104662775993347,
          0.47896575927734375,
          0.45675909519195557,
          0.506228506565094,
          0.48574337363243103,
          0.47511962056159973,
          0.45548558235168457,
          0.4724065065383911,
          0.4826715886592865,
          0.46582362055778503,
          0.47323518991470337,
          0.4987943768501282,
          0.46823111176490784,
          0.48364201188087463,
          0.46067363023757935,
          0.4784117043018341,
          0.4884362518787384,
          0.48079851269721985,
          0.48886120319366455,
          0.46164074540138245,
          0.4793277084827423,
          0.5026166439056396,
          0.5224917531013489,
          0.4804556369781494,
          0.4976075291633606,
          0.4661799669265747,
          0.47276052832603455,
          0.46390822529792786,
          0.5049134492874146,
          0.4487076699733734,
          0.4884479343891144,
          0.49784332513809204,
          0.5037945508956909,
          0.4736362397670746,
          0.47709912061691284,
          0.4582245349884033,
          0.49965032935142517,
          0.4965410530567169,
          0.5031670928001404,
          0.46508705615997314,
          0.4656437933444977,
          0.4853183627128601,
          0.4891616404056549,
          0.47364330291748047,
          0.8597108125686646,
          0.47212353348731995,
          0.4834554195404053,
          0.5001461505889893,
          0.4830149710178375,
          0.5479666590690613,
          0.0031615409534424543,
          0.4909476339817047,
          0.4992583394050598,
          0.49078187346458435,
          0.5116550326347351,
          0.4961549937725067,
          0.4571971297264099,
          0.48312243819236755,
          0.4755558371543884,
          0.48004695773124695,
          0.44967371225357056,
          0.47460323572158813,
          0.4860297739505768,
          0.47709375619888306,
          0.46017709374427795,
          0.48298120498657227,
          0.48292604088783264,
          0.4827694892883301,
          0.4532243013381958,
          0.5918851494789124,
          0.4818243682384491,
          0.48240983486175537,
          0.5227773785591125,
          7.337167062360095e-06,
          0.47424572706222534,
          0.4508567750453949,
          0.5123787522315979,
          0.4802268147468567
         ],
         "xaxis": "x",
         "yaxis": "y"
        }
       ],
       "layout": {
        "barmode": "relative",
        "legend": {
         "title": {
          "text": "variable"
         },
         "tracegroupgap": 0
        },
        "showlegend": false,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "title": {
         "text": "Pythia 1.3b checkpoint 30 vs Pythia 1.3b checkpoint 90"
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "ticktext": [
          "0",
          "0.25",
          "0.5",
          "0.75",
          "1.0"
         ],
         "tickvals": [
          0,
          0.25,
          0.5,
          0.75,
          1
         ],
         "title": {
          "text": "Relative decoder norm strength"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Number of Latents"
         }
        }
       }
      },
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "application/vnd.plotly.v1+json": {
       "config": {
        "plotlyServerURL": "https://plot.ly"
       },
       "data": [
        {
         "alignmentgroup": "True",
         "bingroup": "x",
         "hovertemplate": "variable=0<br>Cosine similarity of decoder vectors between models=%{x}<br>count=%{y}<extra></extra>",
         "legendgroup": "0",
         "marker": {
          "color": "#636efa",
          "pattern": {
           "shape": ""
          }
         },
         "name": "0",
         "nbinsx": 100,
         "offsetgroup": "0",
         "orientation": "v",
         "showlegend": true,
         "type": "histogram",
         "x": [
          0.8804374933242798,
          0.9045302271842957,
          0.9243128299713135,
          0.9136141538619995,
          0.9065384268760681,
          0.8944487571716309,
          0.9084400534629822,
          0.8779247999191284,
          0.9198806285858154,
          0.9139279723167419,
          0.9140370488166809,
          0.8988434672355652,
          0.9468966126441956,
          0.9323606491088867,
          0.9138879776000977,
          0.9225477576255798,
          0.8700077533721924,
          0.8957754969596863,
          0.9167594313621521,
          0.9234321117401123,
          0.90115886926651,
          0.9172141551971436,
          0.893372118473053,
          0.9234874248504639,
          0.8887549042701721,
          0.9233537912368774,
          0.9281665682792664,
          0.9014464616775513,
          0.9118452072143555,
          0.9238507151603699,
          0.9103907942771912,
          0.9260890483856201,
          0.928602397441864,
          0.9039350152015686,
          0.9138726592063904,
          0.9451808929443359,
          0.9217769503593445,
          0.9082467555999756,
          0.936942994594574,
          0.9120423197746277,
          0.9026680588722229,
          0.8504247665405273,
          0.9397832155227661,
          0.9291082620620728,
          0.8925419449806213,
          0.9105675220489502,
          0.8981126546859741,
          0.8852422833442688,
          0.9293832182884216,
          0.9163499474525452,
          0.8651395440101624,
          0.883607804775238,
          0.9378417134284973,
          0.926850438117981,
          0.9111697673797607,
          0.915230393409729,
          0.9001746773719788,
          0.8843889236450195,
          0.9521654844284058,
          0.927250862121582,
          0.9233384728431702,
          0.8992280960083008,
          0.9148436188697815,
          0.915772557258606,
          0.9037805199623108,
          0.9200003743171692,
          0.8913506269454956,
          0.9106326699256897,
          0.9436812400817871,
          0.8509161472320557,
          0.8994341492652893,
          0.9256547093391418,
          0.9011965394020081,
          0.8953392505645752,
          0.9190430641174316,
          0.9168694019317627,
          0.8996102809906006,
          0.7996374368667603,
          0.9208306074142456,
          0.8949967622756958,
          0.9304922819137573,
          0.918775737285614,
          0.9182837605476379,
          0.9291780591011047,
          0.8940836787223816,
          0.9146332144737244,
          0.9140596389770508,
          0.8560277223587036,
          0.9094326496124268,
          0.8914065361022949,
          0.9306421875953674,
          0.9115254282951355,
          0.8634622693061829,
          0.9221472144126892,
          0.9234121441841125,
          0.9005210995674133,
          0.8925435543060303,
          0.9231191873550415,
          0.8789094090461731,
          0.9148433804512024,
          0.8841709494590759,
          0.9151700735092163,
          0.9456311464309692,
          0.9131341576576233,
          0.9160788059234619,
          0.9186345934867859,
          0.9038844704627991,
          0.8997878432273865,
          0.8874775171279907,
          0.9487842321395874,
          0.908746600151062,
          0.9110788106918335,
          0.8927076458930969,
          0.9189229607582092,
          0.7949886918067932,
          0.9171413779258728,
          0.9170580506324768,
          0.9097158312797546,
          0.8681685924530029,
          0.9346598386764526,
          0.9368196725845337,
          0.9057446718215942,
          0.8815659284591675,
          0.9342705607414246,
          0.8933815360069275,
          0.9454453587532043,
          0.8814557194709778,
          0.9295302629470825,
          0.9129102826118469,
          0.938442587852478,
          0.9043078422546387,
          0.9404241442680359,
          0.9233461022377014,
          0.9368083477020264,
          0.8046109676361084,
          0.8983295559883118,
          0.8846803903579712,
          0.9165620803833008,
          0.907672107219696,
          0.9204033613204956,
          0.9028373956680298,
          0.9071815609931946,
          0.9279075860977173,
          0.8936079740524292,
          0.8638132214546204,
          0.9218297600746155,
          0.9017321467399597,
          0.9181376695632935,
          0.9047459959983826,
          0.8921917676925659,
          0.9243253469467163,
          0.9274454116821289,
          0.89528888463974,
          0.8835806846618652,
          0.8653451800346375,
          0.9258636832237244,
          0.9221198558807373,
          0.9503306150436401,
          0.8755946755409241,
          0.9269077777862549,
          0.9098353385925293,
          0.9056705832481384,
          0.9177287817001343,
          0.9045016169548035,
          0.8856844305992126,
          0.9328944087028503,
          0.9211296439170837,
          0.9399620294570923,
          0.9186571836471558,
          0.9232110977172852,
          0.9120124578475952,
          0.9019237160682678,
          0.9056259393692017,
          0.8771395087242126,
          0.9302495121955872,
          0.9194232225418091,
          0.9489209055900574,
          0.9065452814102173,
          0.8573087453842163,
          0.917701005935669,
          0.9386063814163208,
          0.8737433552742004,
          0.9140528440475464,
          0.8513565063476562,
          0.8885162472724915,
          0.8390195369720459,
          0.9148766398429871,
          0.8800861835479736,
          0.8337743878364563,
          0.9158326983451843,
          0.9446869492530823,
          0.9285537004470825,
          0.9063506722450256,
          0.9107828140258789,
          0.8803433179855347,
          0.9303761124610901,
          0.8936536908149719,
          0.909884512424469,
          0.9157258868217468,
          0.9286745190620422,
          0.8749828338623047,
          0.888544499874115,
          0.9055363535881042,
          0.8674024939537048,
          0.9289953708648682,
          0.9126951694488525,
          0.9135161638259888,
          0.9018048644065857,
          0.89093416929245,
          0.9326019287109375,
          0.8985774517059326,
          0.9156929850578308,
          0.9128950834274292,
          0.9258865118026733,
          0.8789949417114258,
          0.9082290530204773,
          0.8402166962623596,
          0.9121223092079163,
          0.9223940968513489,
          0.9207560420036316,
          0.923975944519043,
          0.9077129364013672,
          0.869163990020752,
          0.9087438583374023,
          0.9099171161651611,
          0.918236494064331,
          0.930557370185852,
          0.8734970688819885,
          0.8963555693626404,
          0.9274832606315613,
          0.9133639335632324,
          0.9218212366104126,
          0.9274266958236694,
          0.9082017540931702,
          0.8570603132247925,
          0.9279718995094299,
          0.937289297580719,
          0.9020915031433105,
          0.8970692753791809,
          0.9374074339866638,
          0.9117323756217957,
          0.9255497455596924,
          0.8535932302474976,
          0.891631543636322,
          0.9300523400306702,
          0.9160123467445374,
          0.92140793800354,
          0.9084684252738953,
          0.9249805808067322,
          0.8300163745880127,
          0.8543248176574707,
          0.9203181862831116,
          0.8941266536712646,
          0.9001039862632751,
          0.9129928946495056,
          0.8236638307571411,
          0.9221527576446533,
          0.8952153921127319,
          0.916084349155426,
          0.9433993101119995,
          0.9003199338912964,
          0.9071842432022095,
          0.9036280512809753,
          0.913160502910614,
          0.8935784697532654,
          0.907238245010376,
          0.9191953539848328,
          0.9152113795280457,
          0.9233946204185486,
          0.9251725077629089,
          0.7717694640159607,
          0.9179364442825317,
          0.9161388278007507,
          0.877855658531189,
          0.9107549786567688,
          0.9273335933685303,
          0.907927930355072,
          0.8948887586593628,
          0.9176227450370789,
          0.931196928024292,
          0.9317888617515564,
          0.9408968091011047,
          0.917791485786438,
          0.9146982431411743,
          0.9403602480888367,
          0.8892256617546082,
          0.8636699914932251,
          0.9023683667182922,
          0.9144447445869446,
          0.9237272143363953,
          0.9192863702774048,
          0.9019684791564941,
          0.884009599685669,
          0.9030467867851257,
          0.9065287709236145,
          0.8991800546646118,
          0.9367680549621582,
          0.9226012229919434,
          0.9325750470161438,
          0.9088981747627258,
          0.9319390058517456,
          0.9027556777000427,
          0.9274492263793945,
          0.9470046162605286,
          0.9138925075531006,
          0.8661244511604309,
          0.9241980314254761,
          0.9121057391166687,
          0.922176718711853,
          0.892913818359375,
          0.9273027777671814,
          0.9147820472717285,
          0.9318066239356995,
          0.9220813512802124,
          0.9247909188270569,
          0.9280971884727478,
          0.903704047203064,
          0.8658826351165771,
          0.9149995446205139,
          0.910551130771637,
          0.8928266763687134,
          0.8890470862388611,
          0.9286825060844421,
          0.9016740918159485,
          0.8828842043876648,
          0.9476093053817749,
          0.8406070470809937,
          0.8929993510246277,
          0.9121356010437012,
          0.9496618509292603,
          0.9152628183364868,
          0.905632495880127,
          0.9148041605949402,
          0.9186813831329346,
          0.9098613858222961,
          0.9216442108154297,
          0.9258155822753906,
          0.9100148677825928,
          0.9195863008499146,
          0.8790261745452881,
          0.9364786744117737,
          0.8959394097328186,
          0.7890983819961548,
          0.8795744776725769,
          0.9052655696868896,
          0.8894155621528625,
          0.8914898633956909,
          0.9418618083000183,
          0.8927952647209167,
          0.9166884422302246,
          0.9018369913101196,
          0.9408758282661438,
          0.9007574915885925,
          0.9281958341598511,
          0.9075876474380493,
          0.9370726943016052,
          0.9056686758995056,
          0.8809901475906372,
          0.846034824848175,
          0.9045764803886414,
          0.9379994869232178,
          0.9152694344520569,
          0.9149878025054932,
          0.9326282739639282,
          0.9225469827651978,
          0.9320878386497498,
          0.9203211069107056,
          0.9305368065834045,
          0.9120259881019592,
          0.8772782683372498,
          0.9247270822525024,
          0.9180973172187805,
          0.8676856160163879,
          0.9117408990859985,
          0.8872009515762329,
          0.8690112233161926,
          0.9174712896347046,
          0.8829071521759033,
          0.9149519205093384,
          0.9215053915977478,
          0.91152423620224,
          0.9013122320175171,
          0.8765220642089844,
          0.9199201464653015,
          0.9382511973381042,
          0.9292519688606262,
          0.8491147756576538,
          0.9256429672241211,
          0.9185247421264648,
          0.8985342979431152,
          0.9207770824432373,
          0.9131154417991638,
          0.92271488904953,
          0.905971109867096,
          0.9255712032318115,
          0.8888804912567139,
          0.9069082736968994,
          0.8570252060890198,
          0.7116094827651978,
          0.8744955062866211,
          0.9198514819145203,
          0.9198319315910339,
          0.934918999671936,
          0.9179447889328003,
          0.9089944958686829,
          0.9014797210693359,
          0.9222487807273865,
          0.9152716398239136,
          0.9105603098869324,
          0.9345731139183044,
          0.9209779500961304,
          0.9224219918251038,
          0.8749752640724182,
          0.920370876789093,
          0.9476199150085449,
          0.8885846138000488,
          0.93262779712677,
          0.912984311580658,
          0.8742465972900391,
          0.9149859547615051,
          0.9198525547981262,
          0.9232311248779297,
          0.9390648007392883,
          0.9274585247039795,
          0.9267558455467224,
          0.8845407366752625,
          0.8976045846939087,
          0.900234580039978,
          0.9351125359535217,
          0.9305132627487183,
          0.8502322435379028,
          0.9291969537734985,
          0.9240343570709229,
          0.9402878284454346,
          0.9179500937461853,
          0.9242387413978577,
          0.899450421333313,
          0.9192181825637817,
          0.9056330323219299,
          0.9094136953353882,
          0.9157384037971497,
          0.8974924683570862,
          0.9180446863174438,
          0.9302268624305725,
          0.9324543476104736,
          0.924008309841156,
          0.8910993337631226,
          0.9310529232025146,
          0.9030280709266663,
          0.8988643288612366,
          0.9275820851325989,
          0.9311712980270386,
          0.9293874502182007,
          0.9002457857131958,
          0.8890085816383362,
          0.8856663703918457,
          0.8911560773849487,
          0.8663585186004639,
          0.9298516511917114,
          0.9368894696235657,
          0.8854767680168152,
          0.9013597369194031,
          0.9171662926673889,
          0.8918623924255371,
          0.921448290348053,
          0.9072717428207397,
          0.9137637615203857,
          0.9421312808990479,
          0.9211235046386719,
          0.8402645587921143,
          0.9090560078620911,
          0.869016706943512,
          0.9222026467323303,
          0.934378981590271,
          0.9115522503852844,
          0.9432313442230225,
          0.8753224015235901,
          0.9260261058807373,
          0.9269295334815979,
          0.9015373587608337,
          0.9248673319816589,
          0.9150524735450745,
          0.9413312077522278,
          0.8667342662811279,
          0.8778048753738403,
          0.9140699505805969,
          0.8896409869194031,
          0.8678244352340698,
          0.9516602158546448,
          0.8982523679733276,
          0.9364370107650757,
          0.8898103833198547,
          0.9198019504547119,
          0.9081499576568604,
          0.920753538608551,
          0.9213541746139526,
          0.8838005065917969,
          0.907939612865448,
          0.8779996037483215,
          0.9011231064796448,
          0.9190911054611206,
          0.8644592761993408,
          0.939484715461731,
          0.8793120980262756,
          0.8983668088912964,
          0.9188510179519653,
          0.9204536080360413,
          0.9063174724578857,
          0.9308696389198303,
          0.910464882850647,
          0.9515657424926758,
          0.8833734393119812,
          0.922475278377533,
          0.90111243724823,
          0.9055496454238892,
          0.9271544814109802,
          0.8780844211578369,
          0.9177926778793335,
          0.8793097734451294,
          0.9213765859603882,
          0.8639952540397644,
          0.8702453970909119,
          0.9243015050888062,
          0.9187957048416138,
          0.8911765217781067,
          0.9186190962791443,
          0.9021158814430237,
          0.933698296546936,
          0.8776775002479553,
          0.867123007774353,
          0.914878249168396,
          0.9154314398765564,
          0.9237096905708313,
          0.8785528540611267,
          0.8967761993408203,
          0.8909425735473633,
          0.9215663075447083,
          0.8875025510787964,
          0.9255281090736389,
          0.9184049367904663,
          0.9319345951080322,
          0.8891057372093201,
          0.8989043831825256,
          0.926284670829773,
          0.9316797256469727,
          0.9225450158119202,
          0.9071333408355713,
          0.9236626029014587,
          0.9046406149864197,
          0.9091002941131592,
          0.9420825839042664,
          0.9235353469848633,
          0.9434900879859924,
          0.8920229077339172,
          0.8610846400260925,
          0.8761530518531799,
          0.9214873313903809,
          0.9069564342498779,
          0.9175766706466675,
          0.8983068466186523,
          0.8690736293792725,
          0.9269483685493469,
          0.9058468341827393,
          0.9152328372001648,
          0.8771892189979553,
          0.9308537840843201,
          0.9230555891990662,
          0.9101251363754272,
          0.8827184438705444,
          0.9190932512283325,
          0.8942346572875977,
          0.9254299402236938,
          0.914707601070404,
          0.9223149418830872,
          0.916252851486206,
          0.9312267303466797,
          0.9417036175727844,
          0.9360238313674927,
          0.911630392074585,
          0.951652467250824,
          0.9021002650260925,
          0.9403685927391052,
          0.9021381139755249,
          0.9144799709320068,
          0.8987978100776672,
          0.9068320989608765,
          0.9344806671142578,
          0.8664135932922363,
          0.9003176689147949,
          0.890425443649292,
          0.9265860319137573,
          0.9152520895004272,
          0.9019292593002319,
          0.9224550724029541,
          0.9242097735404968,
          0.9372490048408508,
          0.9324385523796082,
          0.9170473217964172,
          0.8959470391273499,
          0.9273785948753357,
          0.9116431474685669,
          0.9113867282867432,
          0.9213188886642456,
          0.895090639591217,
          0.8972532153129578,
          0.9143930077552795,
          0.9091215133666992,
          0.8902747631072998,
          0.9284785389900208,
          0.9350592494010925,
          0.8644473552703857,
          0.9461410045623779,
          0.9198499917984009,
          0.8952351808547974,
          0.9103723168373108,
          0.8873345851898193,
          0.923101007938385,
          0.923442542552948,
          0.8989468812942505,
          0.9281306862831116,
          0.9230322241783142,
          0.8352014422416687,
          0.8710557818412781,
          0.9508090615272522,
          0.9118895530700684,
          0.9155469536781311,
          0.8755037784576416,
          0.9178254008293152,
          0.923725426197052,
          0.9072301983833313,
          0.9257773756980896,
          0.8889604806900024,
          0.8678746819496155,
          0.9135340452194214,
          0.9305899739265442,
          0.9072145223617554,
          0.9115746021270752,
          0.9029006958007812,
          0.8535678386688232,
          0.8941634297370911,
          0.9229543805122375,
          0.9242267608642578,
          0.9291542768478394,
          0.9353458285331726,
          0.9096187353134155,
          0.898914635181427,
          0.9452517032623291,
          0.9351485967636108,
          0.891501784324646,
          0.927501380443573,
          0.9066249132156372,
          0.8318329453468323,
          0.9215912222862244,
          0.9066184759140015,
          0.9223235249519348,
          0.9412081241607666,
          0.937663197517395,
          0.9139994978904724,
          0.8986494541168213,
          0.8883959650993347,
          0.89572674036026,
          0.9026669263839722,
          0.9274627566337585,
          0.9228475689888,
          0.9235469698905945,
          0.8949567079544067,
          0.9251047372817993,
          0.9009353518486023,
          0.9459743499755859,
          0.9315248727798462,
          0.9151396155357361,
          0.9416712522506714,
          0.9196945428848267,
          0.9059364795684814,
          0.8909290432929993,
          0.9302356243133545,
          0.925873875617981,
          0.9149861931800842,
          0.8974280953407288,
          0.9204295873641968,
          0.9344583749771118,
          0.9078630208969116,
          0.9443715810775757,
          0.8917931318283081,
          0.8669090270996094,
          0.928836464881897,
          0.9143258929252625,
          0.8903710842132568,
          0.9357874393463135,
          0.891181230545044,
          0.9240272641181946,
          0.928347647190094,
          0.932465672492981,
          0.9009433388710022,
          0.913541316986084,
          0.8934574127197266,
          0.9361234903335571,
          0.8763104677200317,
          0.9142035841941833,
          0.933497965335846,
          0.90152508020401,
          0.9102332592010498,
          0.9109615683555603,
          0.9296086430549622,
          0.8701621294021606,
          0.9226552844047546,
          0.897373616695404,
          0.9214452505111694,
          0.9389488101005554,
          0.8951927423477173,
          0.9143596887588501,
          0.9190576672554016,
          0.9436129331588745,
          0.9146639704704285,
          0.9187185168266296,
          0.9017150402069092,
          0.9266879558563232,
          0.914374589920044,
          0.8961099982261658,
          0.9124908447265625,
          0.9233332872390747,
          0.9021669030189514,
          0.9258246421813965,
          0.8650572896003723,
          0.8436073064804077,
          0.8967234492301941,
          0.9007423520088196,
          0.90372234582901,
          0.8517472743988037,
          0.9213946461677551,
          0.9393390417098999,
          0.9218102097511292,
          0.9124323725700378,
          0.9117113351821899,
          0.9026619791984558,
          0.8966816663742065,
          0.9086636304855347,
          0.9036468863487244,
          0.9097917079925537,
          0.9108290672302246,
          0.9262425899505615,
          0.8638970851898193,
          0.9309857487678528,
          0.9135022163391113,
          0.9242265820503235,
          0.8750474452972412,
          0.937946617603302,
          0.9193857312202454,
          0.9232932329177856,
          0.9082973599433899,
          0.9302110075950623,
          0.9320956468582153,
          0.900476336479187,
          0.9191351532936096,
          0.9269595742225647,
          0.9311386942863464,
          0.9365666508674622,
          0.9174283742904663,
          0.8989697098731995,
          0.893244206905365,
          0.9150264859199524,
          0.903196394443512,
          0.9357814788818359,
          0.9185316562652588,
          0.9199883937835693,
          0.7928999066352844,
          0.9173592925071716,
          0.9401831030845642,
          0.9076793193817139,
          0.9082757830619812,
          0.9058942794799805,
          0.9024853706359863,
          0.8781968951225281,
          0.9127939939498901,
          0.9356046319007874,
          0.9192560911178589,
          0.9352931976318359,
          0.9218007922172546,
          0.9212023615837097,
          0.8819250464439392,
          0.8063619136810303,
          0.8827119469642639,
          0.9245651364326477,
          0.9089972376823425,
          0.9264931082725525,
          0.9269550442695618,
          0.9297360777854919,
          0.877560555934906,
          0.9193760752677917,
          0.9414687156677246,
          0.9018278121948242,
          0.9146749973297119,
          0.9338796138763428,
          0.9280674457550049,
          0.8849164843559265,
          0.9357246160507202,
          0.8855440616607666,
          0.9017127752304077,
          0.8740274310112,
          0.9167082905769348,
          0.9191308617591858,
          0.8821017742156982,
          0.9231926202774048,
          0.9053685665130615,
          0.902004063129425,
          0.8881784677505493,
          0.9466920495033264,
          0.9116654992103577,
          0.930220365524292,
          0.9333265423774719,
          0.9433179497718811,
          0.9212005734443665,
          0.9221919775009155,
          0.902984082698822,
          0.9215005040168762,
          0.8487929105758667,
          0.8994031548500061,
          0.9352589845657349,
          0.8941140174865723,
          0.9143484830856323,
          0.9142011404037476,
          0.9487048387527466,
          0.9177235960960388,
          0.9221215844154358,
          0.9212108850479126,
          0.9091103076934814,
          0.8524875640869141,
          0.8930931091308594,
          0.8737719058990479,
          0.9147979021072388,
          0.9267233610153198,
          0.9219606518745422,
          0.9083881378173828,
          0.8703656792640686,
          0.9192519187927246,
          0.9270171523094177,
          0.9083868861198425,
          0.8630964159965515,
          0.9127822518348694,
          0.8968184590339661,
          0.9216786026954651,
          0.9198826551437378,
          0.8833885788917542,
          0.9178473949432373,
          0.9212205410003662,
          0.9228266477584839,
          0.8614571690559387,
          0.9389729499816895,
          0.9096053838729858,
          0.9268071055412292,
          0.8966816067695618,
          0.9314929246902466,
          0.9271038770675659,
          0.9222432374954224,
          0.9153929948806763,
          0.8937448263168335,
          0.9254403114318848,
          0.8611003160476685,
          0.8778046369552612,
          0.9392706751823425,
          0.9193891286849976,
          0.9225932359695435,
          0.8941942453384399,
          0.9044532179832458,
          0.9338221549987793,
          0.9444755911827087,
          0.9394384026527405,
          0.913834273815155,
          0.9120599627494812,
          0.9061989784240723,
          0.8530880808830261,
          0.8825573921203613,
          0.9081871509552002,
          0.9100592136383057,
          0.8741484880447388,
          0.9299205541610718,
          0.890397310256958,
          0.8558743000030518,
          0.9123510122299194,
          0.9169068336486816,
          0.9240350127220154,
          0.8547337651252747,
          0.9180517792701721,
          0.8810814023017883,
          0.8671221733093262,
          0.9278891682624817,
          0.8832083940505981,
          0.8503558039665222,
          0.8711672425270081,
          0.8851578831672668,
          0.9048817157745361,
          0.89043790102005,
          0.9348457455635071,
          0.9412283301353455,
          0.9147939682006836,
          0.9087481498718262,
          0.8992496728897095,
          0.8274486064910889,
          0.9091174006462097,
          0.9260678887367249,
          0.9317358136177063,
          0.8966437578201294,
          0.9156106114387512,
          0.924659788608551,
          0.9021992683410645,
          0.8681460618972778,
          0.9049478769302368,
          0.9376306533813477,
          0.9326417446136475,
          0.9053246974945068,
          0.9156985282897949,
          0.9298387169837952,
          0.9155492782592773,
          0.851401686668396,
          0.9309332966804504,
          0.8813134431838989,
          0.9162895679473877,
          0.9273955821990967,
          0.8991304636001587,
          0.9297831654548645,
          0.9017869830131531,
          0.9048826694488525,
          0.9137632250785828,
          0.9321200251579285,
          0.9149727821350098,
          0.9048625230789185,
          0.9160150289535522,
          0.9181565046310425,
          0.9126144051551819,
          0.8839367032051086,
          0.9177528023719788,
          0.9539639353752136,
          0.923780620098114,
          0.925969123840332,
          0.9309075474739075,
          0.9166030883789062,
          0.9321023225784302,
          0.8925805687904358,
          0.9130690693855286,
          0.8600279092788696,
          0.9176563024520874,
          0.9385870099067688,
          0.856295108795166,
          0.9260417222976685,
          0.9206121563911438,
          0.8306055068969727,
          0.9231424927711487,
          0.9215999841690063,
          0.9033306241035461,
          0.8875004053115845,
          0.9366486668586731,
          0.8937464356422424,
          0.9122235178947449,
          0.9166523814201355,
          0.9259684681892395,
          0.9344825744628906,
          0.8556777834892273,
          0.9058789610862732,
          0.9143438339233398,
          0.9109845757484436,
          0.9064498543739319,
          0.9166703224182129,
          0.9299548864364624,
          0.9194825291633606,
          0.9144087433815002,
          0.911925733089447,
          0.921646773815155,
          0.9260528683662415,
          0.8959826827049255,
          0.9283036589622498,
          0.9236276149749756,
          0.8325855731964111,
          0.887080192565918,
          0.8764709234237671,
          0.8850294351577759,
          0.934363067150116,
          0.9072603583335876,
          0.8810060024261475,
          0.9022349715232849,
          0.9256336688995361,
          0.9106512069702148,
          0.8962171673774719,
          0.9302906394004822,
          0.9147138595581055,
          0.9267889261245728,
          0.9065197110176086,
          0.9239413738250732,
          0.9105919003486633,
          0.9341522455215454,
          0.841425359249115,
          0.9184451699256897,
          0.9087277054786682,
          0.9137870669364929,
          0.9305223226547241,
          0.9254551529884338,
          0.8970215320587158,
          0.936311662197113,
          0.7728119492530823,
          0.8644477725028992,
          0.9109935760498047,
          0.8802666068077087,
          0.9201703071594238,
          0.9052091240882874,
          0.909088671207428,
          0.9304559230804443,
          0.8950759172439575,
          0.8961225748062134,
          0.907498836517334,
          0.89081209897995,
          0.91847163438797,
          0.9001504182815552,
          0.9136705994606018,
          0.9126518368721008,
          0.917630136013031,
          0.9014915227890015,
          0.9216259717941284,
          0.9227889776229858,
          0.9218562245368958,
          0.9188969731330872,
          0.9169754385948181,
          0.88840252161026,
          0.8657286763191223,
          0.9235687255859375,
          0.921948254108429,
          0.9148945808410645,
          0.925512969493866,
          0.9165241718292236,
          0.7948593497276306,
          0.9179143309593201,
          0.9242763519287109,
          0.9268019199371338,
          0.9227580428123474,
          0.9193288683891296,
          0.9270011186599731,
          0.8982647061347961,
          0.9062061309814453,
          0.9382101893424988,
          0.8499533534049988,
          0.9171788096427917,
          0.919998288154602,
          0.9156358242034912,
          0.8856438994407654,
          0.7680718898773193,
          0.9224982857704163,
          0.8841495513916016,
          0.9347508549690247,
          0.8198785185813904,
          0.9359396696090698,
          0.8535688519477844,
          0.9066880345344543,
          0.9066113233566284,
          0.9327256679534912,
          0.9215502738952637,
          0.9222755432128906,
          0.934855043888092,
          0.8933171033859253,
          0.8753356337547302,
          0.8821414709091187,
          0.9297545552253723,
          0.9029030799865723,
          0.9286285042762756,
          0.9162082672119141,
          0.9223376512527466,
          0.9093292355537415,
          0.9121592044830322,
          0.9262099266052246,
          0.8854047656059265,
          0.9102466106414795,
          0.9002820253372192,
          0.9275551438331604,
          0.8964678049087524,
          0.9329127073287964,
          0.9207277894020081,
          0.9194672703742981,
          0.8599423170089722,
          0.8595423102378845,
          0.8780008554458618,
          0.8484423756599426,
          0.9160423874855042,
          0.8956053853034973,
          0.9337497353553772,
          0.9265661239624023,
          0.9297232031822205,
          0.896553635597229,
          0.8542603254318237,
          0.8932126760482788,
          0.9206913709640503,
          0.9375215768814087,
          0.9352315664291382,
          0.9310650825500488,
          0.8714101314544678,
          0.9240124821662903,
          0.9215371012687683,
          0.9027055501937866,
          0.9337863326072693,
          0.9059519171714783,
          0.9281426668167114,
          0.9174473881721497,
          0.9148542881011963,
          0.933660626411438,
          0.9209794998168945,
          0.84516841173172,
          0.951881468296051,
          0.867577850818634,
          0.8989353179931641,
          0.9172697067260742,
          0.9122060537338257,
          0.9153797030448914,
          0.9110685586929321,
          0.8999859690666199,
          0.9335683584213257,
          0.9316086173057556,
          0.8849310874938965,
          0.9126936793327332,
          0.9133456349372864,
          0.9214819669723511,
          0.9286195039749146,
          0.9008523225784302,
          0.8784703612327576,
          0.9112934470176697,
          0.871658980846405,
          0.8988427519798279,
          0.8875794410705566,
          0.9215085506439209,
          0.9110571146011353,
          0.9251897931098938,
          0.8910878300666809,
          0.9327956438064575,
          0.8137686848640442,
          0.9224611520767212,
          0.9194085001945496,
          0.9080604910850525,
          0.9251211285591125,
          0.9125560522079468,
          0.9298601746559143,
          0.9172325730323792,
          0.8749793171882629,
          0.9268777370452881,
          0.877215564250946,
          0.9209623336791992,
          0.9098197221755981,
          0.9065178036689758,
          0.9244449734687805,
          0.9308792352676392,
          0.9347915053367615,
          0.9258256554603577,
          0.9353880882263184,
          0.9329306483268738,
          0.8888542652130127,
          0.9329894185066223,
          0.9165582060813904,
          0.9306875467300415,
          0.9094586968421936,
          0.9081066250801086,
          0.9207457900047302,
          0.9021777510643005,
          0.9277046918869019,
          0.8785451650619507,
          0.9092849493026733,
          0.918028712272644,
          0.9092755317687988,
          0.9172703623771667,
          0.9181275367736816,
          0.8347249627113342,
          0.9040693044662476,
          0.926770031452179,
          0.9300679564476013,
          0.927238404750824,
          0.8987806439399719,
          0.941190779209137,
          0.9106991291046143,
          0.9172618389129639,
          0.9081283807754517,
          0.94475257396698,
          0.9283750057220459,
          0.917072594165802,
          0.7544955611228943,
          0.9180983901023865,
          0.8579464554786682,
          0.864210844039917,
          0.9245587587356567,
          0.9206063747406006,
          0.9264664053916931,
          0.8325796723365784,
          0.9243442416191101,
          0.9178063869476318,
          0.9106086492538452,
          0.8645768761634827,
          0.9285014271736145,
          0.8753560185432434,
          0.9052937626838684,
          0.8642974495887756,
          0.9301006197929382,
          0.9089638590812683,
          0.8913481831550598,
          0.8915186524391174,
          0.9288880228996277,
          0.9227105975151062,
          0.8771776556968689,
          0.9425735473632812,
          0.9245020747184753,
          0.8951320052146912,
          0.9077946543693542,
          0.8896975517272949,
          0.9119601845741272,
          0.918405294418335,
          0.8839300870895386,
          0.8994130492210388,
          0.9163041114807129,
          0.8579252362251282,
          0.9253143072128296,
          0.9356409907341003,
          0.9323010444641113,
          0.9283664226531982,
          0.9206699132919312,
          0.9049835801124573,
          0.8991518020629883,
          0.8530137538909912,
          0.9337416291236877,
          0.9216136932373047,
          0.9468721151351929,
          0.934323251247406,
          0.9222966432571411,
          0.9295116066932678,
          0.9144765138626099,
          0.9164338707923889,
          0.9240722060203552,
          0.9121778011322021,
          0.9279971122741699,
          0.8338720798492432,
          0.8939852118492126,
          0.8951079845428467,
          0.9294570088386536,
          0.862975537776947,
          0.9075407385826111,
          0.9176716804504395,
          0.9160867929458618,
          0.9306866526603699,
          0.9007797837257385,
          0.8916663527488708,
          0.8965436220169067,
          0.9123964905738831,
          0.9058793187141418,
          0.8615974187850952,
          0.9276353120803833,
          0.9095231890678406,
          0.9134442210197449,
          0.9294703006744385,
          0.9234817028045654,
          0.8653712868690491,
          0.9193077683448792,
          0.8997771739959717,
          0.86390620470047,
          0.8782637715339661,
          0.9224067330360413,
          0.9014782905578613,
          0.8854061365127563,
          0.929915189743042,
          0.8806654214859009,
          0.8713647723197937,
          0.9333361387252808,
          0.9285708665847778,
          0.902731716632843,
          0.9216727614402771,
          0.9159152507781982,
          0.9466332197189331,
          0.8716913461685181,
          0.9261468052864075,
          0.9192609786987305,
          0.8933660984039307,
          0.9145694971084595,
          0.9082257151603699,
          0.9066784381866455,
          0.9086880683898926,
          0.915794849395752,
          0.9146966338157654,
          0.9080842137336731,
          0.9333760142326355,
          0.934983491897583,
          0.9152987599372864,
          0.9052248597145081,
          0.9260164499282837,
          0.9038780331611633,
          0.8789305686950684,
          0.9169496893882751,
          0.9120110869407654,
          0.935135006904602,
          0.9054502844810486,
          0.9245673418045044,
          0.9143171906471252,
          0.834781289100647,
          0.9081725478172302,
          0.9311954975128174,
          0.9424976110458374,
          0.9318799376487732,
          0.8924779295921326,
          0.9330748319625854,
          0.8903765678405762,
          0.859725832939148,
          0.9232520461082458,
          0.9280939698219299,
          0.9164658784866333,
          0.9232927560806274,
          0.899523913860321,
          0.9315109848976135,
          0.9269864559173584,
          0.8777222037315369,
          0.904879629611969,
          0.907328724861145,
          0.8879598379135132,
          0.9334415793418884,
          0.9389248490333557,
          0.9179864525794983,
          0.9154715538024902,
          0.904549241065979,
          0.9069051146507263,
          0.9314866662025452,
          0.9249400496482849,
          0.9186112284660339,
          0.8995478749275208,
          0.9063448905944824,
          0.9137783646583557,
          0.92670738697052,
          0.9196462035179138,
          0.9102467894554138,
          0.9068188667297363,
          0.8971102833747864,
          0.937455415725708,
          0.9372949600219727,
          0.8892440795898438,
          0.9175507426261902,
          0.9186383485794067,
          0.907055139541626,
          0.9036270976066589,
          0.924809455871582,
          0.8908069729804993,
          0.9109674692153931,
          0.8989225625991821,
          0.923961877822876,
          0.8873586058616638,
          0.9206106066703796,
          0.8900455832481384,
          0.9306389093399048,
          0.9080865383148193,
          0.9087355732917786,
          0.8939314484596252,
          0.9118881225585938,
          0.9117384552955627,
          0.9385020136833191,
          0.9190184473991394,
          0.8638105392456055,
          0.8946207761764526,
          0.8890621662139893,
          0.9306797385215759,
          0.8773744106292725,
          0.8816848993301392,
          0.9057511687278748,
          0.9111810326576233,
          0.9183182716369629,
          0.9322695136070251,
          0.8860680460929871,
          0.9036588072776794,
          0.9035133123397827,
          0.9009817242622375,
          0.9358669519424438,
          0.9244419932365417,
          0.8683419227600098,
          0.932241678237915,
          0.9369761943817139,
          0.9072870016098022,
          0.9323076009750366,
          0.9041770100593567,
          0.8602195382118225,
          0.9152542352676392,
          0.9244152903556824,
          0.9237453937530518,
          0.925330400466919,
          0.8873305916786194,
          0.9464302659034729,
          0.9064122438430786,
          0.9017146229743958,
          0.9048714637756348,
          0.9188870787620544,
          0.9235310554504395,
          0.9133365750312805,
          0.892555296421051,
          0.8983479738235474,
          0.9333887100219727,
          0.9248272776603699,
          0.8884154558181763,
          0.8934363722801208,
          0.9262571930885315,
          0.9315161108970642,
          0.9028029441833496,
          0.8786126971244812,
          0.9400181770324707,
          0.9388270974159241,
          0.8582624197006226,
          0.9376986026763916,
          0.9299671649932861,
          0.9287425875663757,
          0.9177585244178772,
          0.8990951776504517,
          0.9199264049530029,
          0.9213998913764954,
          0.8878887891769409,
          0.9259101748466492,
          0.9238340854644775,
          0.8680336475372314,
          0.9228877425193787,
          0.9465053081512451,
          0.9280110001564026,
          0.9118545651435852,
          0.9395313858985901,
          0.8636879920959473,
          0.9129738211631775,
          0.9129615426063538,
          0.8755785226821899,
          0.8626564741134644,
          0.9265947937965393,
          0.9264749884605408,
          0.8474751114845276,
          0.9065138101577759,
          0.9306485652923584,
          0.9154820442199707,
          0.8680300712585449,
          0.9483122825622559,
          0.87996506690979,
          0.9299163222312927,
          0.8992770910263062,
          0.8772541284561157,
          0.9236647486686707,
          0.9166862964630127,
          0.918447732925415,
          0.9224960207939148,
          0.9274424910545349,
          0.9052711129188538,
          0.9106913208961487,
          0.9030013084411621,
          0.9251977205276489,
          0.9249494671821594,
          0.904629647731781,
          0.9024845957756042,
          0.9319145083427429,
          0.9379478096961975,
          0.9259899258613586,
          0.9531896114349365,
          0.8894158005714417,
          0.9384812712669373,
          0.9254165291786194,
          0.8925507664680481,
          0.9047274589538574,
          0.9188508987426758,
          0.8714914321899414,
          0.9310981035232544,
          0.9059941172599792,
          0.9194300174713135,
          0.9282295107841492,
          0.8834661841392517,
          0.934524655342102,
          0.8909087777137756,
          0.9077982902526855,
          0.8982594609260559,
          0.9421345591545105,
          0.865249514579773,
          0.9187130331993103,
          0.9201797842979431,
          0.8693086504936218,
          0.8598546981811523,
          0.9225760698318481,
          0.903986930847168,
          0.9136431813240051,
          0.9018877744674683,
          0.9205008149147034,
          0.9272267818450928,
          0.9038869738578796,
          0.9463686347007751,
          0.9407841563224792,
          0.9461641907691956,
          0.8271229863166809,
          0.9055460095405579,
          0.9164794683456421,
          0.9307374954223633,
          0.9295215010643005,
          0.8725911378860474,
          0.9461807012557983,
          0.9136789441108704,
          0.9208589196205139,
          0.9126692414283752,
          0.9332988262176514,
          0.87098228931427,
          0.947433590888977,
          0.9295489192008972,
          0.9354066848754883,
          0.9248866438865662,
          0.9289406538009644,
          0.9140579700469971,
          0.9254240393638611,
          0.9175681471824646,
          0.8712475299835205,
          0.9100658893585205,
          0.9292336106300354,
          0.9082143306732178,
          0.9223580956459045,
          0.9301544427871704,
          0.9196756482124329,
          0.8845428228378296,
          0.8590617775917053,
          0.9328638911247253,
          0.9217438697814941,
          0.8886563777923584,
          0.9217745661735535,
          0.8928208351135254,
          0.8845318555831909,
          0.9272430539131165,
          0.9233115315437317,
          0.8917592763900757,
          0.9041552543640137,
          0.9216313362121582,
          0.9120571613311768,
          0.9017150402069092,
          0.9164391160011292,
          0.9331257939338684,
          0.9059740900993347,
          0.9378150105476379,
          0.9315179586410522,
          0.8462314009666443,
          0.8660909533500671,
          0.9271178841590881,
          0.8786190152168274,
          0.9257253408432007,
          0.9006911516189575,
          0.8764904737472534,
          0.8904720544815063,
          0.9087182879447937,
          0.9061893820762634,
          0.9424066543579102,
          0.839098334312439,
          0.9399861693382263,
          0.9142807126045227,
          0.9306560158729553,
          0.8958520889282227,
          0.9505951404571533,
          0.8930069804191589,
          0.9363216757774353,
          0.9401922821998596,
          0.9075819849967957,
          0.923973798751831,
          0.8893004655838013,
          0.8967642188072205,
          0.9255517721176147,
          0.9184528589248657,
          0.9349831938743591,
          0.9260352253913879,
          0.9182612299919128,
          0.9141345024108887,
          0.9269126057624817,
          0.9484792947769165,
          0.9132977724075317,
          0.9129246473312378,
          0.9114825129508972,
          0.88132643699646,
          0.8792629837989807,
          0.8805921673774719,
          0.9279657602310181,
          0.9247632622718811,
          0.8608707189559937,
          0.8771852850914001,
          0.902593195438385,
          0.9058718681335449,
          0.9320732355117798,
          0.9022692441940308,
          0.85841965675354,
          0.9157171249389648,
          0.9167771339416504,
          0.9213347434997559,
          0.9087495803833008,
          0.8249120712280273,
          0.8874406814575195,
          0.8943171501159668,
          0.9246602058410645,
          0.8667131662368774,
          0.9277355074882507,
          0.9340939521789551,
          0.9160102605819702,
          0.9421126246452332,
          0.9188470244407654,
          0.9209703207015991,
          0.882639467716217,
          0.9287281632423401,
          0.9218549728393555,
          0.9067115783691406,
          0.8797279596328735,
          0.8750714659690857,
          0.9335808753967285,
          0.9207345247268677,
          0.9313075542449951,
          0.890421450138092,
          0.9162667393684387,
          0.9032809138298035,
          0.912329375743866,
          0.9005957245826721,
          0.9301639199256897,
          0.9293879270553589,
          0.87468022108078,
          0.9339801073074341,
          0.8983032703399658,
          0.9239667057991028,
          0.9109935760498047,
          0.8668990731239319,
          0.931706964969635,
          0.8811919093132019,
          0.8470585942268372,
          0.943275511264801,
          0.9100279211997986,
          0.9015727043151855,
          0.9145004749298096,
          0.9162508249282837,
          0.9356533288955688,
          0.9119608402252197,
          0.9078505039215088,
          0.9087885022163391,
          0.8844714164733887,
          0.928931713104248,
          0.9171732068061829,
          0.939638078212738,
          0.9295321702957153,
          0.9056951999664307,
          0.9269585609436035,
          0.8438736796379089,
          0.9249412417411804,
          0.8961994051933289,
          0.8928752541542053,
          0.9256196022033691,
          0.9412419199943542,
          0.9183913469314575,
          0.9244700074195862,
          0.9194344282150269,
          0.9010284543037415,
          0.9083116054534912,
          0.9281896948814392,
          0.856934130191803,
          0.9033597111701965,
          0.9135914444923401,
          0.8944704532623291,
          0.8890612721443176,
          0.8932424187660217,
          0.8808018565177917,
          0.881683886051178,
          0.9155545234680176,
          0.9241470098495483,
          0.9109616875648499,
          0.8581216335296631,
          0.8680630326271057,
          0.9405348896980286,
          0.8891540765762329,
          0.8296048045158386,
          0.8711010217666626,
          0.9095519185066223,
          0.8683531880378723,
          0.9250245094299316,
          0.8482785224914551,
          0.8993355631828308,
          0.8938440084457397,
          0.9299445748329163,
          0.9064337015151978,
          0.9474519491195679,
          0.872805118560791,
          0.8968763947486877,
          0.9019900560379028,
          0.9283272624015808,
          0.9286618828773499,
          0.9058932662010193,
          0.9282336831092834,
          0.8890299201011658,
          0.8645553588867188,
          0.9173092246055603,
          0.8646887540817261,
          0.9236704111099243,
          0.8683668375015259,
          0.9220666885375977,
          0.9122827649116516,
          0.8891528844833374,
          0.9298813343048096,
          0.9172136783599854,
          0.90851891040802,
          0.8929474949836731,
          0.9240139126777649,
          0.9226810932159424,
          0.8769634366035461,
          0.9223008155822754,
          0.8932205438613892,
          0.8912220597267151,
          0.907974362373352,
          0.912460446357727,
          0.9153286814689636,
          0.9182671308517456,
          0.9075044989585876,
          0.8670192360877991,
          0.9325646162033081,
          0.9138188362121582,
          0.9033036231994629,
          0.9356352686882019,
          0.9108715653419495,
          0.8942432999610901,
          0.9270429015159607,
          0.9288888573646545,
          0.9099096655845642,
          0.9170079231262207,
          0.9221741557121277,
          0.9244512915611267,
          0.9044415354728699,
          0.8498051166534424,
          0.826474130153656,
          0.9063365459442139,
          0.9003680348396301,
          0.9363523125648499,
          0.9032799005508423,
          0.9187605381011963,
          0.903684139251709,
          0.9230218529701233,
          0.9341477155685425,
          0.9403806328773499,
          0.9067814350128174,
          0.8989126086235046,
          0.9060810208320618,
          0.8849114179611206,
          0.9019975066184998,
          0.8437402844429016,
          0.9354328513145447,
          0.9176393151283264,
          0.901821494102478,
          0.8979768753051758,
          0.9121257662773132,
          0.8717733025550842,
          0.9380888342857361,
          0.9204487204551697,
          0.8164962530136108,
          0.8902838826179504,
          0.894040584564209,
          0.9312995076179504,
          0.9034290313720703,
          0.9280663728713989,
          0.8442105054855347,
          0.9322359561920166,
          0.9359384775161743,
          0.9171204566955566,
          0.9183804392814636,
          0.9240900278091431,
          0.8982242345809937,
          0.9301227331161499,
          0.9150947332382202,
          0.9014091491699219,
          0.8740431070327759,
          0.9137236475944519,
          0.92502361536026,
          0.917918860912323,
          0.8972828388214111,
          0.9428719282150269,
          0.8673164248466492,
          0.9410073757171631,
          0.9003496766090393,
          0.8480427265167236,
          0.9217853546142578,
          0.920576810836792,
          0.8897130489349365,
          0.9020453691482544,
          0.9015757441520691,
          0.9245355129241943,
          0.9069356322288513,
          0.8744233250617981,
          0.8979237675666809,
          0.8943694829940796,
          0.8792079091072083,
          0.9072476625442505,
          0.9017351269721985,
          0.911399781703949,
          0.9025004506111145,
          0.905293881893158,
          0.9343995451927185,
          0.8914620280265808,
          0.8851013779640198,
          0.9310058355331421,
          0.9065836668014526,
          0.9083707928657532,
          0.9046825170516968,
          0.909477174282074,
          0.8849638104438782,
          0.9219526052474976,
          0.9411224126815796,
          0.9288769960403442,
          0.9191712141036987,
          0.8776015043258667,
          0.9435667991638184,
          0.881945788860321,
          0.9225916266441345,
          0.9405707716941833,
          0.8523964285850525,
          0.9053587317466736,
          0.9092787504196167,
          0.9181995391845703,
          0.8620992302894592,
          0.9358238577842712,
          0.9129533171653748,
          0.9189436435699463,
          0.9259154796600342,
          0.9086599349975586,
          0.9069839119911194,
          0.9042133688926697,
          0.8757495284080505,
          0.8582714200019836,
          0.9049676656723022,
          0.9324535131454468,
          0.9443065524101257,
          0.9264698624610901,
          0.8982723951339722,
          0.8847505450248718,
          0.9234796166419983,
          0.9253248572349548,
          0.9469353556632996,
          0.9377867579460144,
          0.9302884340286255,
          0.9368916153907776,
          0.9254689812660217,
          0.9007978439331055,
          0.8750520348548889,
          0.9150296449661255,
          0.9436300992965698,
          0.9389199614524841,
          0.9130106568336487,
          0.9390878677368164,
          0.9196169376373291,
          0.8654777407646179,
          0.8772653341293335,
          0.9096279740333557,
          0.9023525714874268,
          0.9344708919525146,
          0.8814449310302734,
          0.9120944142341614,
          0.9164870977401733,
          0.9055607318878174,
          0.8894845247268677,
          0.8968027830123901,
          0.8949141502380371,
          0.8842343091964722,
          0.9183647036552429,
          0.924872875213623,
          0.9226749539375305,
          0.8823298811912537,
          0.9072321653366089,
          0.9235601425170898,
          0.9008907675743103,
          0.9161938428878784,
          0.8529309034347534,
          0.9259659051895142,
          0.888667106628418,
          0.9261148571968079,
          0.9236608743667603,
          0.8394502401351929,
          0.8798167705535889,
          0.9135477542877197,
          0.830254077911377,
          0.9246047139167786,
          0.9099224209785461,
          0.9002997875213623,
          0.8971582055091858,
          0.8635459542274475,
          0.9174193739891052,
          0.9048923254013062,
          0.8561302423477173,
          0.9380100965499878,
          0.9182746410369873,
          0.8943265676498413,
          0.8452004790306091,
          0.9258499145507812,
          0.9088414907455444,
          0.9093614816665649,
          0.9457257986068726,
          0.8609826564788818,
          0.9237433075904846,
          0.8821720480918884,
          0.9294452667236328,
          0.9078198075294495,
          0.8978766202926636,
          0.8977154493331909,
          0.9073951244354248,
          0.8870251178741455,
          0.9278883934020996,
          0.9255074858665466,
          0.8984532356262207,
          0.9247066974639893,
          0.8702557682991028,
          0.8908188939094543,
          0.8993871808052063,
          0.9014121294021606,
          0.9227904677391052,
          0.9224686026573181,
          0.9226544499397278,
          0.9027289748191833,
          0.9365923404693604,
          0.9237266778945923,
          0.928912341594696,
          0.8989927172660828,
          0.9247459769248962,
          0.9261099696159363,
          0.916348397731781,
          0.9313376545906067,
          0.9464396238327026,
          0.8977133631706238,
          0.9134780764579773,
          0.9008212089538574,
          0.8821104168891907,
          0.9346599578857422,
          0.9182819724082947,
          0.9081960320472717,
          0.9243209362030029,
          0.9075648188591003,
          0.921536386013031,
          0.9269129633903503,
          0.9269383549690247,
          0.9116955399513245,
          0.9272524118423462,
          0.9166195392608643,
          0.9421705603599548,
          0.9214321970939636,
          0.9344581365585327,
          0.9172596335411072,
          0.919172465801239,
          0.9162933230400085,
          0.8855569362640381,
          0.907694935798645,
          0.8782743215560913,
          0.9206687808036804,
          0.8779869079589844,
          0.8987172842025757,
          0.9375460147857666,
          0.9194810390472412,
          0.9180657863616943,
          0.9216231107711792,
          0.8581624031066895,
          0.9271954298019409,
          0.8829482197761536,
          0.880065381526947,
          0.9345800280570984,
          0.9254974126815796,
          0.8980291485786438,
          0.9443624019622803,
          0.870762288570404,
          0.8791253566741943,
          0.9338095784187317,
          0.9128665924072266,
          0.9251508712768555,
          0.9068162441253662,
          0.9145044684410095,
          0.86525559425354,
          0.9172016978263855,
          0.9398707151412964,
          0.9031213521957397,
          0.916390061378479,
          0.8865841031074524,
          0.8910225629806519,
          0.9225383400917053,
          0.9177113771438599,
          0.9381349682807922,
          0.9250162839889526,
          0.9228333234786987,
          0.9181802868843079,
          0.9001747965812683,
          0.9215101599693298,
          0.9272279739379883,
          0.9099959135055542,
          0.8964324593544006,
          0.9221398830413818,
          0.9071014523506165,
          0.8700112104415894,
          0.8893360495567322,
          0.9282235503196716,
          0.9337927103042603,
          0.8705410957336426,
          0.8608748316764832,
          0.9299092888832092,
          0.918158769607544,
          0.9047996997833252,
          0.9134271740913391,
          0.9080515503883362,
          0.9068142175674438,
          0.8679998517036438,
          0.9263637065887451,
          0.9154370427131653,
          0.9209982752799988,
          0.8621223568916321,
          0.9285931587219238,
          0.938694953918457,
          0.9301714897155762,
          0.9016034603118896,
          0.9093992710113525,
          0.9257878065109253,
          0.9389064311981201,
          0.9109283685684204,
          0.9112008213996887,
          0.8853927254676819,
          0.8554589152336121,
          0.9398881793022156,
          0.8838239908218384,
          0.9033012986183167,
          0.9105470776557922,
          0.939579963684082,
          0.9373894929885864,
          0.9168040752410889,
          0.9182949662208557,
          0.9065487384796143,
          0.91471266746521,
          0.9330663084983826,
          0.8971976041793823,
          0.927907407283783,
          0.9125488996505737,
          0.9427409172058105,
          0.9019795656204224,
          0.930439293384552,
          0.9157271981239319,
          0.9066699743270874,
          0.9246455430984497,
          0.9153286814689636,
          0.9220704436302185,
          0.907511830329895,
          0.8838891386985779,
          0.9224772453308105,
          0.9249472618103027,
          0.8720487356185913,
          0.9343417286872864,
          0.8828609585762024,
          0.9183807373046875,
          0.8851135969161987,
          0.9133856296539307,
          0.9198897480964661,
          0.9256131649017334,
          0.9398480653762817,
          0.8812363147735596,
          0.8933479189872742,
          0.9425825476646423,
          0.9073514342308044,
          0.9000064730644226,
          0.9046227931976318,
          0.907313883304596,
          0.8763653635978699,
          0.8808048963546753,
          0.9243514537811279,
          0.9379240870475769,
          0.9000791311264038,
          0.8952147364616394,
          0.9145874381065369,
          0.9270544648170471,
          0.9128934741020203,
          0.9031170010566711,
          0.9028638601303101,
          0.9147987961769104,
          0.9325212836265564,
          0.8955511450767517,
          0.9203450679779053,
          0.9227032661437988,
          0.9201646447181702,
          0.901459276676178,
          0.9150860905647278,
          0.928632915019989,
          0.8871932029724121,
          0.9311025738716125,
          0.9102935791015625,
          0.8736165165901184,
          0.8445028066635132,
          0.8976067900657654,
          0.9410287737846375,
          0.9158288240432739,
          0.9059447050094604,
          0.9305480718612671,
          0.9047990441322327,
          0.9048661589622498,
          0.8498939871788025,
          0.8955556750297546,
          0.9280112981796265,
          0.903472900390625,
          0.9297334551811218,
          0.9230372905731201,
          0.9075008034706116,
          0.9071145057678223,
          0.92085200548172,
          0.888640284538269,
          0.9211925268173218,
          0.9256963729858398,
          0.9334797859191895,
          0.9277409911155701,
          0.9270710349082947,
          0.9212678074836731,
          0.914701521396637,
          0.9172828793525696,
          0.894407331943512,
          0.8863269090652466,
          0.8872889280319214,
          0.9055267572402954,
          0.9220737218856812,
          0.9167753458023071,
          0.8954135775566101,
          0.906005859375,
          0.9165133237838745,
          0.9306598901748657,
          0.9049535393714905,
          0.9278162717819214,
          0.8931816220283508,
          0.9130541086196899,
          0.8505440950393677,
          0.9373788833618164,
          0.9099313020706177,
          0.9054051041603088,
          0.9277896881103516,
          0.8477109670639038,
          0.8693474531173706,
          0.8652336001396179,
          0.9147220253944397,
          0.9188830852508545,
          0.9082923531532288,
          0.904362142086029,
          0.8969328999519348,
          0.9375894069671631,
          0.9000294208526611,
          0.8986653685569763,
          0.9185521602630615,
          0.8663276433944702,
          0.9151881337165833,
          0.9096485376358032,
          0.9133906960487366,
          0.9294016361236572,
          0.9348579049110413,
          0.8511784076690674,
          0.9461156129837036,
          0.9444286823272705,
          0.9137505888938904,
          0.9041013717651367,
          0.9373621344566345,
          0.9197880029678345,
          0.9295027852058411,
          0.8971115350723267,
          0.890241801738739,
          0.9162540435791016,
          0.9032253623008728,
          0.9042624831199646,
          0.8703610897064209,
          0.9172970652580261,
          0.9041135907173157,
          0.9257222414016724,
          0.9242103099822998,
          0.9174258708953857,
          0.800003707408905,
          0.9026903510093689,
          0.9259945154190063,
          0.889302134513855,
          0.9371420741081238,
          0.931512176990509,
          0.8911939263343811,
          0.9240201115608215,
          0.918512761592865,
          0.9315080046653748,
          0.9241854548454285,
          0.9100115895271301,
          0.8658117055892944,
          0.9333896040916443,
          0.9100260734558105,
          0.9067862033843994,
          0.9118402004241943,
          0.9151601791381836,
          0.9371863603591919,
          0.9277179837226868,
          0.7878598570823669,
          0.9005146026611328,
          0.9290065169334412,
          0.8843339085578918,
          0.8869721293449402,
          0.8325737118721008,
          0.9219012260437012,
          0.8600174188613892,
          0.8783338069915771,
          0.9211339354515076,
          0.9081509113311768,
          0.9011985659599304,
          0.9168790578842163,
          0.9171475172042847,
          0.8992420434951782,
          0.9236525893211365,
          0.8661484122276306,
          0.9320911169052124,
          0.884434700012207,
          0.8846957683563232,
          0.904884397983551,
          0.9095602631568909,
          0.9040800929069519,
          0.9375121593475342,
          0.943109393119812,
          0.8940752744674683,
          0.9016394019126892,
          0.9389992356300354,
          0.9187584519386292,
          0.8885957598686218,
          0.9219465851783752,
          0.9020584225654602,
          0.9116576313972473,
          0.9247158169746399,
          0.9199748039245605,
          0.9039368033409119,
          0.9131067395210266,
          0.9183927774429321,
          0.9171537160873413,
          0.8569276928901672,
          0.9092037081718445,
          0.9045780897140503,
          0.8981248140335083,
          0.9049793481826782,
          0.9023947715759277,
          0.8562002778053284,
          0.8747803568840027,
          0.878640353679657,
          0.9065514206886292,
          0.9287886619567871,
          0.9206705093383789,
          0.9128778576850891,
          0.8538440465927124,
          0.8639508485794067,
          0.9294200539588928,
          0.9409316778182983,
          0.914038896560669,
          0.8794026970863342,
          0.9282174110412598,
          0.90108323097229,
          0.9246107339859009,
          0.8797441720962524,
          0.9408002495765686,
          0.869697630405426,
          0.9254749417304993,
          0.9314179420471191,
          0.8683986067771912,
          0.8826233148574829,
          0.9307470321655273,
          0.9265015721321106,
          0.9046740531921387,
          0.9117833971977234,
          0.8968901038169861,
          0.8590729832649231,
          0.9023027420043945,
          0.9067846536636353,
          0.9132612943649292,
          0.9252626299858093,
          0.9271747469902039,
          0.9151999950408936,
          0.9240555167198181,
          0.9155653119087219,
          0.8812984228134155,
          0.8772984147071838,
          0.9246078729629517,
          0.9320289492607117,
          0.8904975652694702,
          0.8992759585380554,
          0.916674017906189,
          0.9402444958686829,
          0.8713876008987427,
          0.9184895157814026,
          0.9135150909423828,
          0.8959667086601257,
          0.8991456031799316,
          0.9196010231971741,
          0.9409544467926025,
          0.8952306509017944,
          0.9051134586334229,
          0.9252715110778809,
          0.9354172348976135,
          0.9287990927696228,
          0.862215518951416,
          0.9216437935829163,
          0.8844072222709656,
          0.8638861775398254,
          0.8640782237052917,
          0.888116180896759,
          0.9067216515541077,
          0.8726285099983215,
          0.9101364612579346,
          0.864516019821167,
          0.9097663760185242,
          0.9270917773246765,
          0.8715708255767822,
          0.925555408000946,
          0.9362558722496033,
          0.9073095917701721,
          0.8994967341423035,
          0.917790412902832,
          0.9287480115890503,
          0.8770958185195923,
          0.8966368436813354,
          0.9157108068466187,
          0.9318393468856812,
          0.9410629272460938,
          0.9011065363883972,
          0.918920636177063,
          0.9069758057594299,
          0.9183277487754822,
          0.9248383641242981,
          0.9181777834892273,
          0.8943584561347961,
          0.894176721572876,
          0.9526500701904297,
          0.9312892556190491,
          0.9180154800415039,
          0.9166082739830017,
          0.8698723912239075,
          0.8848591446876526,
          0.9034518599510193,
          0.8935736417770386,
          0.897049069404602,
          0.9337968230247498,
          0.9046449065208435,
          0.9390095472335815,
          0.8961642384529114,
          0.9471779465675354,
          0.9208170175552368,
          0.9058272838592529,
          0.9270546436309814,
          0.9335430860519409,
          0.9035192728042603,
          0.9178988933563232,
          0.9149828553199768,
          0.8805705904960632,
          0.925204336643219,
          0.9279781579971313,
          0.865378201007843,
          0.8808114528656006,
          0.9212285280227661,
          0.9042354822158813,
          0.9135267734527588,
          0.8949916958808899,
          0.9280765056610107,
          0.8863255977630615,
          0.929357647895813,
          0.9053917527198792,
          0.913102388381958,
          0.9129753708839417,
          0.9109035134315491,
          0.9096651077270508,
          0.9147452116012573,
          0.955488383769989,
          0.9162095189094543,
          0.8871541619300842,
          0.9214285016059875,
          0.9251766204833984,
          0.938294529914856,
          0.9115492701530457,
          0.9203206896781921,
          0.9153045415878296,
          0.9082372188568115,
          0.924632728099823,
          0.9179178476333618,
          0.9253502488136292,
          0.9251825213432312,
          0.9251111745834351,
          0.8977712988853455,
          0.8962655067443848,
          0.8421953320503235,
          0.8234238028526306,
          0.9333639144897461,
          0.8939903974533081,
          0.9108041524887085,
          0.9119076132774353,
          0.8951879143714905,
          0.8857433795928955,
          0.9401249289512634,
          0.9482166171073914,
          0.9176526069641113,
          0.9263723492622375,
          0.921095073223114,
          0.9027869701385498,
          0.9259579181671143,
          0.9500852227210999,
          0.9311666488647461,
          0.931957483291626,
          0.915149986743927,
          0.9171940088272095,
          0.9137261509895325,
          0.9357562065124512,
          0.878082811832428,
          0.9358260035514832,
          0.8732321262359619,
          0.900065541267395,
          0.8999729752540588,
          0.9432622790336609,
          0.8272807002067566,
          0.9111520648002625,
          0.9190273284912109,
          0.9203702211380005,
          0.9062798023223877,
          0.9399380087852478,
          0.9337567687034607,
          0.9282622933387756,
          0.8800088167190552,
          0.9322988986968994,
          0.9277609586715698,
          0.8589040040969849,
          0.9143145084381104,
          0.9154348969459534,
          0.916752815246582,
          0.9307832717895508,
          0.9162539839744568,
          0.9123667478561401,
          0.9317981004714966,
          0.9151125550270081,
          0.9334765672683716,
          0.9114447236061096,
          0.9052302241325378,
          0.9174971580505371,
          0.9368934035301208,
          0.8865077495574951,
          0.9104365706443787,
          0.9136438965797424,
          0.9308995604515076,
          0.9304562211036682,
          0.9082434773445129,
          0.8871042728424072,
          0.8760055899620056,
          0.8570581078529358,
          0.9007357358932495,
          0.89278644323349,
          0.9042559266090393,
          0.9135193824768066,
          0.9322901368141174,
          0.8772794604301453,
          0.9243719577789307,
          0.9221750497817993,
          0.8880140781402588,
          0.8900400400161743,
          0.9164731502532959,
          0.9236615896224976,
          0.9372119307518005,
          0.8921270370483398,
          0.943889319896698,
          0.9351624846458435,
          0.9240341186523438,
          0.9272611141204834,
          0.877149760723114,
          0.927895724773407,
          0.911777138710022,
          0.8816788792610168,
          0.9222968816757202,
          0.9382954239845276,
          0.9449551105499268,
          0.9479788541793823,
          0.912403404712677,
          0.9232508540153503,
          0.9389695525169373,
          0.8735724091529846,
          0.9199506044387817,
          0.9241881966590881,
          0.9032275080680847,
          0.9149781465530396,
          0.923477053642273,
          0.8805415630340576,
          0.9306772351264954,
          0.8572846055030823,
          0.896272599697113,
          0.9245457649230957,
          0.9084354639053345,
          0.9118599891662598,
          0.9247511029243469,
          0.8970761299133301,
          0.926403284072876,
          0.9380211234092712,
          0.8727191686630249,
          0.9186784625053406,
          0.9054855108261108,
          0.9227543473243713,
          0.9175360202789307,
          0.8711568117141724,
          0.9373661279678345,
          0.9164037704467773,
          0.9081586003303528,
          0.9176977872848511,
          0.9159662127494812,
          0.9169643521308899,
          0.8667847514152527,
          0.8832486867904663,
          0.8799060583114624,
          0.932223916053772,
          0.9350335001945496,
          0.879332959651947,
          0.9318211674690247,
          0.8982924222946167,
          0.8988480567932129,
          0.9394537806510925,
          0.8806109428405762,
          0.9236847162246704,
          0.8830782771110535,
          0.9100170135498047,
          0.8879134654998779,
          0.9179132580757141,
          0.9200055003166199,
          0.9241418838500977,
          0.8507025241851807,
          0.9326189756393433,
          0.9055535793304443,
          0.880980372428894,
          0.924218475818634,
          0.9235963821411133,
          0.922389030456543,
          0.9167492985725403,
          0.9105820059776306,
          0.9191389679908752,
          0.9098363518714905,
          0.8801557421684265,
          0.9315129518508911,
          0.8549687266349792,
          0.8501396775245667,
          0.8916990160942078,
          0.9227705001831055,
          0.919511616230011,
          0.9177899360656738,
          0.9192476868629456,
          0.8757734298706055,
          0.9197302460670471,
          0.8768306374549866,
          0.8730122447013855,
          0.9326663613319397,
          0.8895978331565857,
          0.9157170057296753,
          0.925583004951477,
          0.9185969829559326,
          0.9061360955238342,
          0.9092423319816589,
          0.8867082595825195,
          0.6263759136199951,
          0.9299817085266113,
          0.9191924929618835,
          0.871164858341217,
          0.9239507913589478,
          0.867546796798706,
          0.9285629391670227,
          0.8351767063140869,
          0.9131009578704834,
          0.9199693202972412,
          0.8165690302848816,
          0.9234034419059753,
          0.9033074975013733,
          0.8294935822486877,
          0.916106641292572,
          0.9473221898078918,
          0.8953471779823303,
          0.9306942224502563,
          0.888620913028717,
          0.8960884213447571,
          0.8793492913246155,
          0.9114841222763062,
          0.9360035061836243,
          0.9006730914115906,
          0.9070661067962646,
          0.9300212264060974,
          0.9419956207275391,
          0.9279045462608337,
          0.9392037987709045,
          0.8768526315689087,
          0.9235941171646118,
          0.9186953902244568,
          0.9332369565963745,
          0.8777529001235962,
          0.8931501507759094,
          0.8220614790916443,
          0.9205626249313354,
          0.9168421626091003,
          0.944318950176239,
          0.9042820334434509,
          0.9356091618537903,
          0.9062900543212891,
          0.9264230132102966,
          0.9121019244194031,
          0.883690595626831,
          0.9350026249885559,
          0.8768813014030457,
          0.8890053033828735,
          0.9191144704818726,
          0.9175006747245789,
          0.9071778655052185,
          0.89235919713974,
          0.9091451168060303,
          0.9050535559654236,
          0.8957806825637817,
          0.9360839128494263,
          0.8725684881210327,
          0.9268935322761536,
          0.9256857633590698,
          0.9102839827537537,
          0.9161403179168701,
          0.8968092799186707,
          0.9081331491470337,
          0.9335129857063293,
          0.8617609143257141,
          0.9372694492340088,
          0.9059334397315979,
          0.923717737197876,
          0.9189320802688599,
          0.9033751487731934,
          0.9287583827972412,
          0.9102175235748291,
          0.9262073040008545,
          0.9249812960624695,
          0.9118010401725769,
          0.8867796659469604,
          0.9379693269729614,
          0.9201660752296448,
          0.9307824373245239,
          0.9337922930717468,
          0.9008240103721619,
          0.9290838837623596,
          0.9217857122421265,
          0.882142186164856,
          0.9255653619766235,
          0.928289532661438,
          0.8918401598930359,
          0.9358803629875183,
          0.90364670753479,
          0.907453715801239,
          0.8121057152748108,
          0.825937032699585,
          0.8331237435340881,
          0.9327442646026611,
          0.8880981802940369,
          0.8781183958053589,
          0.9159248471260071,
          0.8940666317939758,
          0.9119679927825928,
          0.9256305694580078,
          0.9353392720222473,
          0.8812722563743591,
          0.9189556837081909,
          0.9392388463020325,
          0.9277365803718567,
          0.9104142189025879,
          0.9165199995040894,
          0.9241915941238403,
          0.9307989478111267,
          0.9195464849472046,
          0.9150975942611694,
          0.9173554182052612,
          0.905482292175293,
          0.889275312423706,
          0.8868537545204163,
          0.8828684091567993,
          0.9422085881233215,
          0.8125056624412537,
          0.9139217138290405,
          0.9229246377944946,
          0.9081854224205017,
          0.9085915684700012,
          0.9380815625190735,
          0.9276983737945557,
          0.9271172881126404,
          0.9339494109153748,
          0.8662981986999512,
          0.9010096788406372,
          0.914797842502594,
          0.9232304096221924,
          0.8924769163131714,
          0.9101386666297913,
          0.9254679083824158,
          0.9166778922080994,
          0.9197283387184143,
          0.89007169008255,
          0.9107428193092346,
          0.9121778607368469,
          0.9164247512817383,
          0.9460300207138062,
          0.9168708324432373,
          0.9153860211372375,
          0.8876429796218872,
          0.9411141872406006,
          0.9342272877693176,
          0.9123873710632324,
          0.9182655811309814,
          0.9099499583244324,
          0.8769526481628418,
          0.9006694555282593,
          0.9385899305343628,
          0.9054974913597107,
          0.9190683960914612,
          0.9324501156806946,
          0.9148269295692444,
          0.9331966042518616,
          0.9120798707008362,
          0.8618865609169006,
          0.914118230342865,
          0.9167362451553345,
          0.9006626009941101,
          0.9130566716194153,
          0.8901385068893433,
          0.8962399363517761,
          0.9332494139671326,
          0.9232792258262634,
          0.8895806074142456,
          0.9279412031173706,
          0.9171027541160583,
          0.9030522704124451,
          0.9122035503387451,
          0.891646146774292,
          0.8757860660552979,
          0.8832106590270996,
          0.9125950336456299,
          0.8803294897079468,
          0.8904090523719788,
          0.9219772815704346,
          0.8931092023849487,
          0.890251874923706,
          0.908405065536499,
          0.9278208017349243,
          0.9187570214271545,
          0.8920208215713501,
          0.8802111744880676,
          0.9390794634819031,
          0.8989642262458801,
          0.8665168881416321,
          0.8991568684577942,
          0.9485110640525818,
          0.9043540954589844,
          0.8997345566749573,
          0.9075316190719604,
          0.9060083031654358,
          0.8904314637184143,
          0.9170685410499573,
          0.9216716885566711,
          0.8827224373817444,
          0.9292504191398621,
          0.9298417568206787,
          0.8955601453781128,
          0.8684543371200562,
          0.8866115212440491,
          0.9070248007774353,
          0.8867737054824829,
          0.9260137677192688,
          0.8641655445098877,
          0.9199180006980896,
          0.9134365320205688,
          0.9316057562828064,
          0.8950750231742859,
          0.8654062747955322,
          0.9179526567459106,
          0.908481240272522,
          0.9235846996307373,
          0.8654904961585999,
          0.9302289485931396,
          0.9203513264656067,
          0.8928633332252502,
          0.9389145970344543,
          0.8857389688491821,
          0.9217584729194641,
          0.9335511326789856,
          0.9071035385131836,
          0.8759161233901978,
          0.9010983109474182,
          0.8867925405502319,
          0.9238436222076416,
          0.9051061868667603,
          0.9082712531089783,
          0.9044472575187683,
          0.9160569906234741,
          0.919787585735321,
          0.9107423424720764,
          0.9177164435386658,
          0.8876675367355347,
          0.9167116284370422,
          0.9275822639465332,
          0.8921725153923035,
          0.8759652376174927,
          0.8856309056282043,
          0.884705126285553,
          0.9257386922836304,
          0.9003474712371826,
          0.9313361048698425,
          0.9292116761207581,
          0.9186016917228699,
          0.9232386946678162,
          0.8846112489700317,
          0.8942989706993103,
          0.925520122051239,
          0.8776742815971375,
          0.9127078056335449,
          0.9182189106941223,
          0.9119768738746643,
          0.8063121438026428,
          0.8612195253372192,
          0.8830824494361877,
          0.9262295961380005,
          0.9129402041435242,
          0.9042370915412903,
          0.8708577156066895,
          0.932618260383606,
          0.9116208553314209,
          0.9181326031684875,
          0.8763015866279602,
          0.924109160900116,
          0.9182955622673035,
          0.8905206322669983,
          0.9394055008888245,
          0.8699341416358948,
          0.9157649278640747,
          0.9303357005119324,
          0.9146410822868347,
          0.9291360974311829,
          0.868865966796875,
          0.8739809393882751,
          0.8808370232582092,
          0.9103144407272339,
          0.8722556233406067,
          0.8438315391540527,
          0.9048064351081848,
          0.8733454346656799,
          0.8670861124992371,
          0.9219693541526794,
          0.8759279847145081,
          0.9182518124580383,
          0.9150745272636414,
          0.9177694320678711,
          0.8947295546531677,
          0.9025070667266846,
          0.9408454298973083,
          0.9073042273521423,
          0.8848485946655273,
          0.9105720520019531,
          0.9295091032981873,
          0.9031992554664612,
          0.9323045015335083,
          0.8509740829467773,
          0.9378818869590759,
          0.9080999493598938,
          0.93060702085495,
          0.8850279450416565,
          0.7953927516937256,
          0.9102737903594971,
          0.9182377457618713,
          0.9346619844436646,
          0.8874595761299133,
          0.9362879991531372,
          0.8967875242233276,
          0.935568630695343,
          0.8958843946456909,
          0.9303461313247681,
          0.883021891117096,
          0.9257147312164307,
          0.9015368819236755,
          0.8481731414794922,
          0.8829030394554138,
          0.8623772263526917,
          0.8949910402297974,
          0.9056521058082581,
          0.9299103021621704,
          0.89527428150177,
          0.930685818195343,
          0.9027549028396606,
          0.9174426198005676,
          0.8899059891700745,
          0.9256415367126465,
          0.8894069790840149,
          0.8141987323760986,
          0.9183124899864197,
          0.9219322204589844,
          0.8739202618598938,
          0.8941178321838379,
          0.9149656295776367,
          0.9166883826255798,
          0.8937202095985413,
          0.8988446593284607,
          0.874563455581665,
          0.8960691690444946,
          0.876221239566803,
          0.9145557880401611,
          0.9373804926872253,
          0.9189565777778625,
          0.8927528262138367,
          0.9074438810348511,
          0.9234544634819031,
          0.9012371897697449,
          0.9018537998199463,
          0.9204806089401245,
          0.9358897805213928,
          0.893739640712738,
          0.9300880432128906,
          0.8622426390647888,
          0.9211835861206055,
          0.9258989691734314,
          0.9084004163742065,
          0.9019823670387268,
          0.8977763056755066,
          0.9225094318389893,
          0.8912972211837769,
          0.9084245562553406,
          0.9358899593353271,
          0.9322441816329956,
          0.9060882329940796,
          0.9063467383384705,
          0.7715601921081543,
          0.9210352301597595,
          0.9282557964324951,
          0.9004353880882263,
          0.9263731837272644,
          0.9360881447792053,
          0.8914567828178406,
          0.9305777549743652,
          0.9332118630409241,
          0.9224916100502014,
          0.9220482707023621,
          0.877598226070404,
          0.8705853223800659,
          0.9397081732749939,
          0.9319572448730469,
          0.8990995287895203,
          0.92976313829422,
          0.9263639450073242,
          0.9252992868423462,
          0.9077584743499756,
          0.8948079943656921,
          0.8938158750534058,
          0.8682348728179932,
          0.8494715690612793,
          0.9103839993476868,
          0.9401381611824036,
          0.889286994934082,
          0.8941951990127563,
          0.9016590714454651,
          0.9197517037391663,
          0.8874265551567078,
          0.9017166495323181,
          0.9366041421890259,
          0.8822039365768433,
          0.8691798448562622,
          0.9106758832931519,
          0.9280314445495605,
          0.8973810076713562,
          0.9468314051628113,
          0.8946813941001892,
          0.8958320617675781,
          0.9155353903770447,
          0.8911720514297485,
          0.8105000853538513,
          0.891873836517334,
          0.9242485761642456,
          0.9240332245826721,
          0.8624253273010254,
          0.9056022763252258,
          0.9134247899055481,
          0.8507342338562012,
          0.8869727849960327,
          0.9225224256515503,
          0.851545512676239,
          0.9260046482086182,
          0.9440553784370422,
          0.86922687292099,
          0.9175209999084473,
          0.9120556712150574,
          0.8912063241004944,
          0.9100780487060547,
          0.9128553867340088,
          0.902434766292572,
          0.890265703201294,
          0.9017940163612366,
          0.9246115684509277,
          0.9252563118934631,
          0.9183864593505859,
          0.9105655550956726,
          0.9252486824989319,
          0.9291382431983948,
          0.7981575727462769,
          0.8685346245765686,
          0.8920101523399353,
          0.9290286898612976,
          0.8819188475608826,
          0.9071474671363831,
          0.9305223226547241,
          0.909424901008606,
          0.8972148299217224,
          0.8984043598175049,
          0.9268069863319397,
          0.898423433303833,
          0.9115437269210815,
          0.9202598929405212,
          0.8781805038452148,
          0.9342566728591919,
          0.8756060004234314,
          0.9014521241188049,
          0.8959981203079224,
          0.8901915550231934,
          0.8811122179031372,
          0.9332351684570312,
          0.9030070900917053,
          0.835904061794281,
          0.9123201966285706,
          0.9014196395874023,
          0.9258951544761658,
          0.9364954829216003,
          0.9159939885139465,
          0.8966925144195557,
          0.8659297823905945,
          0.9436323642730713,
          0.9197326898574829,
          0.9201234579086304,
          0.838465690612793,
          0.9095701575279236,
          0.9180172085762024,
          0.9333516955375671,
          0.8879425525665283,
          0.9394264817237854,
          0.925450325012207,
          0.8772065043449402,
          0.8756510019302368,
          0.9001688361167908,
          0.9376148581504822,
          0.9142655730247498,
          0.8984097242355347,
          0.948265790939331,
          0.9266993999481201,
          0.9191876649856567,
          0.923444390296936,
          0.9159924983978271,
          0.8901849389076233,
          0.8705244660377502,
          0.9369847178459167,
          0.9190159440040588,
          0.8923290967941284,
          0.9164785146713257,
          0.8538467288017273,
          0.9410809278488159,
          0.8823935389518738,
          0.9383051991462708,
          0.8772470355033875,
          0.9489681124687195,
          0.9074003100395203,
          0.9126909971237183,
          0.9381266236305237,
          0.8986301422119141,
          0.9311802983283997,
          0.9211155772209167,
          0.8916149735450745,
          0.9400527477264404,
          0.9287910461425781,
          0.9346796870231628,
          0.8872970938682556,
          0.9210541844367981,
          0.9281622171401978,
          0.9323349595069885,
          0.86625736951828,
          0.9035289883613586,
          0.9156143665313721,
          0.9186954498291016,
          0.9519191980361938,
          0.8751675486564636,
          0.9292717576026917,
          0.9108585119247437,
          0.9102354645729065,
          0.9053718447685242,
          0.9212788343429565,
          0.9155673980712891,
          0.889484167098999,
          0.8845683336257935,
          0.8695463538169861,
          0.8956741094589233,
          0.9223254323005676,
          0.9075586199760437,
          0.8996986150741577,
          0.8519627451896667,
          0.9088276624679565,
          0.8411297798156738,
          0.8727853894233704,
          0.8999457955360413,
          0.9167863726615906,
          0.9217968583106995,
          0.9269958138465881,
          0.8994851112365723,
          0.9193990230560303,
          0.9229550361633301,
          0.9048558473587036,
          0.859292209148407,
          0.9320772290229797,
          0.878272294998169,
          0.8927648663520813,
          0.9437081217765808,
          0.8886071443557739,
          0.9153745174407959,
          0.8797181248664856,
          0.9267789721488953,
          0.9119920134544373,
          0.9208400845527649,
          0.8916268348693848,
          0.9214470982551575,
          0.9208056926727295,
          0.9214338064193726,
          0.9121221303939819,
          0.905677855014801,
          0.8990364074707031,
          0.9206212759017944,
          0.9145257472991943,
          0.9056445360183716,
          0.8997347950935364,
          0.8999050259590149,
          0.9146244525909424,
          0.9163384437561035,
          0.9175693988800049,
          0.9339280128479004,
          0.8818149566650391,
          0.934677004814148,
          0.920264482498169,
          0.9143834710121155,
          0.9014855027198792,
          0.9300462603569031,
          0.8806344270706177,
          0.9110994935035706,
          0.935870349407196,
          0.9133803844451904,
          0.8690577149391174,
          0.8678678870201111,
          0.9173956513404846,
          0.9177410006523132,
          0.9130387306213379,
          0.9006129503250122,
          0.9162525534629822,
          0.8864558935165405,
          0.9297444820404053,
          0.8680598735809326,
          0.9081336259841919,
          0.887704074382782,
          0.9067826271057129,
          0.9131367206573486,
          0.8722449541091919,
          0.8881306648254395,
          0.883436918258667,
          0.9162150025367737,
          0.8758657574653625,
          0.9284001588821411,
          0.8683158755302429,
          0.8163391351699829,
          0.9112203121185303,
          0.8461796045303345,
          0.8745254874229431,
          0.9099907279014587,
          0.897574245929718,
          0.9165946245193481,
          0.923647403717041,
          0.8563730716705322,
          0.9267563819885254,
          0.8891760110855103,
          0.9174048900604248,
          0.9030864834785461,
          0.896840512752533,
          0.8851296305656433,
          0.9205194115638733,
          0.9203101992607117,
          0.9353371858596802,
          0.8868563175201416,
          0.9317722916603088,
          0.8744688630104065,
          0.9269692897796631,
          0.9238943457603455,
          0.929611086845398,
          0.8711459040641785,
          0.87630295753479,
          0.9184774160385132,
          0.9269996881484985,
          0.9373207688331604,
          0.9088640213012695,
          0.9101278185844421,
          0.9075155258178711,
          0.9136716723442078,
          0.8576505780220032,
          0.8715906143188477,
          0.9104646444320679,
          0.899356484413147,
          0.9216054677963257,
          0.8927891850471497,
          0.8771821856498718,
          0.915076494216919,
          0.9393308758735657,
          0.9323618412017822,
          0.879540741443634,
          0.9132959842681885,
          0.8656967878341675,
          0.8976424336433411,
          0.8677316308021545,
          0.8555024266242981,
          0.901539146900177,
          0.9164128303527832,
          0.9410240054130554,
          0.8582693934440613,
          0.8693826794624329,
          0.9140104055404663,
          0.9190451502799988,
          0.9318208694458008,
          0.8466627597808838,
          0.8856519460678101,
          0.8903301954269409,
          0.9159607291221619,
          0.9100534319877625,
          0.9114492535591125,
          0.9363669753074646,
          0.9259741902351379,
          0.9400060176849365,
          0.931832492351532,
          0.8329544067382812,
          0.8759728074073792,
          0.8077182173728943,
          0.8589693307876587,
          0.8953662514686584,
          0.8743269443511963,
          0.9075097441673279,
          0.8938555121421814,
          0.9445968270301819,
          0.9190973043441772,
          0.8648570775985718,
          0.926312267780304,
          0.8991342186927795,
          0.9134880304336548,
          0.898529589176178,
          0.9471172094345093,
          0.8729202151298523,
          0.9256910085678101,
          0.9162347912788391,
          0.9240536093711853,
          0.8364701867103577,
          0.938793420791626,
          0.8666576147079468,
          0.894341766834259,
          0.9140021800994873,
          0.9141747951507568,
          0.9189221858978271,
          0.9211812019348145,
          0.9410370588302612,
          0.8595600128173828,
          0.8897320032119751,
          0.9254847168922424,
          0.9088239669799805,
          0.9136523604393005,
          0.9315376877784729,
          0.8699580430984497,
          0.8968656659126282,
          0.9144676327705383,
          0.8907381296157837,
          0.9142986536026001,
          0.9261274933815002,
          0.9366083145141602,
          0.8821839690208435,
          0.8847197890281677,
          0.9104393720626831,
          0.906665563583374,
          0.9218732714653015,
          0.8840115666389465,
          0.9165635108947754,
          0.875434160232544,
          0.8948449492454529,
          0.8920783996582031,
          0.926308274269104,
          0.9361520409584045,
          0.8756704330444336,
          0.9110121726989746,
          0.912808895111084,
          0.9227245450019836,
          0.9404930472373962,
          0.9224100112915039,
          0.925984263420105,
          0.898316502571106,
          0.9353610277175903,
          0.904837965965271,
          0.8604006171226501,
          0.9332188367843628,
          0.8965182304382324,
          0.8687523603439331,
          0.8785566091537476,
          0.8901340365409851,
          0.9324016571044922,
          0.9146713614463806,
          0.9309337735176086,
          0.9257581233978271,
          0.8613362312316895,
          0.895463764667511,
          0.9209627509117126,
          0.8926364779472351,
          0.9314161539077759,
          0.8698831796646118,
          0.8813501000404358,
          0.9248409867286682,
          0.8844552636146545,
          0.9221164584159851,
          0.9221850633621216,
          0.8837073445320129,
          0.8796641230583191,
          0.9228078126907349,
          0.8729734420776367,
          0.934535026550293,
          0.9187547564506531,
          0.9401324987411499,
          0.9340643286705017,
          0.9174066185951233,
          0.8606176376342773,
          0.9361435174942017,
          0.9201920628547668,
          0.8863407373428345,
          0.7505109310150146,
          0.90705406665802,
          0.9239624738693237,
          0.9094279408454895,
          0.9267202615737915,
          0.9164279103279114,
          0.9044389128684998,
          0.9218539595603943,
          0.9221406579017639,
          0.9425376057624817,
          0.9063379764556885,
          0.9259274005889893,
          0.8985291123390198,
          0.902031660079956,
          0.8912979364395142,
          0.914168119430542,
          0.9115383625030518,
          0.90373694896698,
          0.9125748872756958,
          0.9329259395599365,
          0.9134547114372253,
          0.878258228302002,
          0.9234219193458557,
          0.8842739462852478,
          0.9023934006690979,
          0.9085139036178589,
          0.893902599811554,
          0.907281219959259,
          0.920181393623352,
          0.9248175024986267,
          0.8942277431488037,
          0.9241496324539185,
          0.9189276099205017,
          0.89625084400177,
          0.9350677728652954,
          0.9123566150665283,
          0.9107268452644348,
          0.8912956714630127,
          0.820156455039978,
          0.9132345914840698,
          0.8727076053619385,
          0.8553387522697449,
          0.8991497755050659,
          0.8975647687911987,
          0.9292716979980469,
          0.9209448099136353,
          0.8876245021820068,
          0.9336380362510681,
          0.9307008385658264,
          0.9036749601364136,
          0.9102968573570251,
          0.9403412938117981,
          0.9149573445320129,
          0.9058852791786194,
          0.9153150916099548,
          0.8972783088684082,
          0.9198163151741028,
          0.9295079112052917,
          0.9181918501853943,
          0.8741459250450134,
          0.9296799302101135,
          0.8837655782699585,
          0.8833439350128174,
          0.8024559020996094,
          0.9257060885429382,
          0.8743006587028503,
          0.8488286733627319,
          0.9167228937149048,
          0.8596557378768921,
          0.9121510982513428,
          0.9449906349182129,
          0.9429214596748352,
          0.9089484214782715,
          0.9276254773139954,
          0.9417281746864319,
          0.9184654951095581,
          0.9122446179389954,
          0.9327096939086914,
          0.9218755960464478,
          0.9443322420120239,
          0.9046328067779541,
          0.9196105003356934,
          0.9105358719825745,
          0.8682511448860168,
          0.9321157932281494,
          0.8914863467216492,
          0.8805112242698669,
          0.8980048298835754,
          0.9185828566551208,
          0.9038046598434448,
          0.9059196710586548,
          0.8931716084480286,
          0.9114233255386353,
          0.9037162661552429,
          0.8300396203994751,
          0.935646116733551,
          0.8559973239898682,
          0.9005165100097656,
          0.9397897720336914,
          0.8850201368331909,
          0.9185998439788818,
          0.8837646245956421,
          0.9437180757522583,
          0.8781647086143494,
          0.8872214555740356,
          0.8686508536338806,
          0.882793664932251,
          0.9194029569625854,
          0.9391595125198364,
          0.9221274256706238,
          0.9050354361534119,
          0.9239471554756165,
          0.9075031280517578,
          0.9280838370323181,
          0.9563178420066833,
          0.9236744046211243,
          0.884986400604248,
          0.9335607290267944,
          0.8685463666915894,
          0.9070239067077637,
          0.939591646194458,
          0.90025395154953,
          0.9124618768692017,
          0.8961600661277771,
          0.9059658050537109,
          0.9032884240150452,
          0.9152670502662659,
          0.7966378927230835,
          0.9291856288909912,
          0.9219636917114258,
          0.9178243279457092,
          0.9277717471122742,
          0.9323462247848511,
          0.8912663459777832,
          0.8566263914108276,
          0.9099591970443726,
          0.9015132188796997,
          0.8768292665481567,
          0.9266664981842041,
          0.8987284302711487,
          0.8565958738327026,
          0.8778379559516907,
          0.8654268383979797,
          0.8909468650817871,
          0.915908932685852,
          0.8970528841018677,
          0.8982743620872498,
          0.8898827433586121,
          0.918251633644104,
          0.9409306049346924,
          0.9360765814781189,
          0.8959047794342041,
          0.8439807891845703,
          0.8936583399772644,
          0.9142208099365234,
          0.9019037485122681,
          0.9093146920204163,
          0.9061720967292786,
          0.890119731426239,
          0.8845534324645996,
          0.9284972548484802,
          0.8742206692695618,
          0.9156826734542847,
          0.9177225828170776,
          0.8837106823921204,
          0.9192752242088318,
          0.9029178619384766,
          0.9404955506324768,
          0.9395110011100769,
          0.9216040372848511,
          0.9103075861930847,
          0.918485701084137,
          0.9257885217666626,
          0.8933681845664978,
          0.8846654891967773,
          0.8916628360748291,
          0.8761308193206787,
          0.9101547002792358,
          0.9397400617599487,
          0.9377509355545044,
          0.9227644801139832,
          0.8924713134765625,
          0.9322028756141663,
          0.8522320985794067,
          0.9378628134727478,
          0.865706741809845,
          0.8497962355613708,
          0.8836314678192139,
          0.9018561840057373,
          0.8963175415992737,
          0.9159486293792725,
          0.8919698596000671,
          0.9285861253738403,
          0.8854292631149292,
          0.8571565747261047,
          0.9184797406196594,
          0.9203023314476013,
          0.925280749797821,
          0.8467181324958801,
          0.9133598208427429,
          0.942196786403656,
          0.9162004590034485,
          0.8900987505912781,
          0.9010259509086609,
          0.8755419254302979,
          0.9177057147026062,
          0.8887078166007996,
          0.915102481842041,
          0.9127458333969116,
          0.8572941422462463,
          0.9367455244064331,
          0.8985171914100647,
          0.9213913679122925,
          0.8657149076461792,
          0.9022216200828552,
          0.8875515460968018,
          0.9263975024223328,
          0.9367239475250244,
          0.8943883180618286,
          0.9040066599845886,
          0.9309130907058716,
          0.8822609186172485,
          0.9153838753700256,
          0.925182580947876,
          0.8431718945503235,
          0.925623893737793,
          0.9373218417167664,
          0.918084442615509,
          0.9027411937713623,
          0.8940990567207336,
          0.9224110245704651,
          0.8975269198417664,
          0.9307920336723328,
          0.9192045331001282,
          0.9246360659599304,
          0.9287070631980896,
          0.897813618183136,
          0.9316946268081665,
          0.9263112545013428,
          0.8782317042350769,
          0.8430959582328796,
          0.9372942447662354,
          0.909591794013977,
          0.8789743781089783,
          0.906769871711731,
          0.9269688725471497,
          0.9290187358856201,
          0.8922683596611023,
          0.9098964929580688,
          0.7300401926040649,
          0.9434967637062073,
          0.9373313188552856,
          0.9077271223068237,
          0.9199992418289185,
          0.8797864317893982,
          0.9150684475898743,
          0.9195435047149658,
          0.8642083406448364,
          0.8989498615264893,
          0.9190370440483093,
          0.9106857776641846,
          0.9278976321220398,
          0.9237720370292664,
          0.9173835515975952,
          0.9251816272735596,
          0.9076305627822876,
          0.926227867603302,
          0.9233600497245789,
          0.8592067956924438,
          0.842694878578186,
          0.8959077000617981,
          0.8886978626251221,
          0.9279749393463135,
          0.9226977825164795,
          0.9345898628234863,
          0.9157137870788574,
          0.9354553818702698,
          0.9115437865257263,
          0.9196179509162903,
          0.9144652485847473,
          0.8990986943244934,
          0.9458214044570923,
          0.9291945099830627,
          0.9080047011375427,
          0.9060342907905579,
          0.9298298954963684,
          0.8752593398094177,
          0.8982086777687073,
          0.8381525874137878,
          0.9245225191116333,
          0.9092882871627808,
          0.8886356353759766,
          0.8853423595428467,
          0.9174625277519226,
          0.9269610643386841,
          0.8734068870544434,
          0.8907169699668884,
          0.9278891086578369,
          0.9136812090873718,
          0.8796933889389038,
          0.9390571117401123,
          0.9040703177452087,
          0.9072736501693726,
          0.9350829124450684,
          0.9069920182228088,
          0.9005053043365479,
          0.9108410477638245,
          0.8748583793640137,
          0.9259254336357117,
          0.8804580569267273,
          0.9315364956855774,
          0.9321221709251404,
          0.8943490386009216,
          0.8900885581970215,
          0.8497815132141113,
          0.9084690809249878,
          0.8878111839294434,
          0.907987117767334,
          0.9209029674530029,
          0.9144238829612732,
          0.8973222970962524,
          0.931032121181488,
          0.8765963315963745,
          0.8794323205947876,
          0.9104737043380737,
          0.8637687563896179,
          0.9098942279815674,
          0.83573979139328,
          0.9163404703140259,
          0.8803898096084595,
          0.8810827732086182,
          0.8903518915176392,
          0.931094765663147,
          0.9306545257568359,
          0.9267513155937195,
          0.8944313526153564,
          0.9263037443161011,
          0.9019964337348938,
          0.9219325184822083,
          0.9293822050094604,
          0.8833521604537964,
          0.8954706192016602,
          0.8946260213851929,
          0.906326413154602,
          0.947323203086853,
          0.8947083950042725,
          0.9001733660697937,
          0.9096232652664185,
          0.9046438336372375,
          0.9283565878868103,
          0.9136006832122803,
          0.8782907128334045,
          0.9245176911354065,
          0.8795093297958374,
          0.8719388246536255,
          0.895328164100647,
          0.9506564140319824,
          0.9055113196372986,
          0.8598676919937134,
          0.924741804599762,
          0.9328358769416809,
          0.9095306992530823,
          0.8944221138954163,
          0.8956077098846436,
          0.9171081781387329,
          0.9044323563575745,
          0.848914623260498,
          0.94400554895401,
          0.907330334186554,
          0.9040504693984985,
          0.9165648818016052,
          0.8881592154502869,
          0.9079030156135559,
          0.9257600903511047,
          0.8968345522880554,
          0.9062365293502808,
          0.8821297287940979,
          0.9342836141586304,
          0.8987212181091309,
          0.9280233383178711,
          0.9216510653495789,
          0.9430352449417114,
          0.9210847020149231,
          0.9358870387077332,
          0.9322943687438965,
          0.8976212739944458,
          0.8893130421638489,
          0.9191120266914368,
          0.9204279184341431,
          0.9071007966995239,
          0.8858845233917236,
          0.9109346866607666,
          0.8963868021965027,
          0.9146925806999207,
          0.9289764165878296,
          0.9079315662384033,
          0.8752537965774536,
          0.9048041701316833,
          0.9018145799636841,
          0.9124659895896912,
          0.887983500957489,
          0.9233283400535583,
          0.9242346286773682,
          0.8881343603134155,
          0.9176466464996338,
          0.9389597177505493,
          0.9355927109718323,
          0.9274811744689941,
          0.9328027963638306,
          0.934589147567749,
          0.9282310009002686,
          0.8881407976150513,
          0.9382111430168152,
          0.9200605154037476,
          0.9081078767776489,
          0.9391026496887207,
          0.9215407967567444,
          0.9421786665916443,
          0.9496805667877197,
          0.9007828235626221,
          0.9310538172721863,
          0.9281424880027771,
          0.8993019461631775,
          0.9043447375297546,
          0.903393566608429,
          0.8919270038604736,
          0.860781729221344,
          0.95316082239151,
          0.9468048214912415,
          0.850961446762085,
          0.917353630065918,
          0.9065390229225159,
          0.9263520836830139,
          0.9276123046875,
          0.9199569225311279,
          0.8515992164611816,
          0.9030799865722656,
          0.9102272391319275,
          0.9128071069717407,
          0.9296077489852905,
          0.9162699580192566,
          0.8902225494384766,
          0.9243470430374146,
          0.9021649956703186,
          0.9176995754241943,
          0.931713879108429,
          0.9020347595214844,
          0.9250606298446655,
          0.9323021173477173,
          0.92107093334198,
          0.9108656644821167,
          0.9384092688560486,
          0.925098717212677,
          0.9265520572662354,
          0.8632439970970154,
          0.8909592032432556,
          0.922452449798584,
          0.9192031025886536,
          0.9150428771972656,
          0.8947270512580872,
          0.8918938636779785,
          0.9160655736923218,
          0.9356720447540283,
          0.9268016219139099,
          0.9065960645675659,
          0.937597930431366,
          0.9048811793327332,
          0.8964045643806458,
          0.8856630921363831,
          0.9084969162940979,
          0.8503371477127075,
          0.9187182784080505,
          0.9307516813278198,
          0.9135012030601501,
          0.872821033000946,
          0.8919644355773926,
          0.9269330501556396,
          0.898468017578125,
          0.9428632855415344,
          0.9315357208251953,
          0.9249937534332275,
          0.8944929838180542,
          0.8907099366188049,
          0.8998077511787415,
          0.9226239323616028,
          0.8554437160491943,
          0.9156816601753235,
          0.9137399196624756,
          0.9328722953796387,
          0.9002436995506287,
          0.937546968460083,
          0.9222359657287598,
          0.9420719146728516,
          0.9275916814804077,
          0.8935723304748535,
          0.9036136865615845,
          0.9234814643859863,
          0.9247356653213501,
          0.9225305914878845,
          0.9149923324584961,
          0.9272379875183105,
          0.911984384059906,
          0.900594174861908,
          0.931922197341919,
          0.8981858491897583,
          0.9095996022224426,
          0.9506481885910034,
          0.9348415732383728,
          0.9265831112861633,
          0.9067306518554688,
          0.9219112396240234,
          0.9288823008537292,
          0.8983649611473083,
          0.9441031813621521,
          0.8998491764068604,
          0.9253805875778198,
          0.8934647440910339,
          0.9175447225570679,
          0.9085639715194702,
          0.9407021403312683,
          0.9215341210365295,
          0.897595226764679,
          0.9381179809570312,
          0.7915682792663574,
          0.9295127391815186,
          0.9059791564941406,
          0.9260534644126892,
          0.8116356730461121,
          0.919730007648468,
          0.9096384644508362,
          0.8791729211807251,
          0.9069178700447083,
          0.8942388892173767,
          0.9306761026382446,
          0.9340347051620483,
          0.9263515472412109,
          0.9431434273719788,
          0.9319230914115906,
          0.9323135614395142,
          0.9310517311096191,
          0.8744897246360779,
          0.8821064233779907,
          0.885409414768219,
          0.9172168374061584,
          0.9359999895095825,
          0.9221532344818115,
          0.929386556148529,
          0.9274876713752747,
          0.9117334485054016,
          0.8957291841506958,
          0.9065327048301697,
          0.9277327060699463,
          0.8822466731071472,
          0.9124441742897034,
          0.9108896851539612,
          0.8892867565155029,
          0.9250069260597229,
          0.9146308898925781,
          0.9193942546844482,
          0.9138805270195007,
          0.9339842796325684,
          0.898239016532898,
          0.9192900061607361,
          0.9073951244354248,
          0.8953767418861389,
          0.8919158577919006,
          0.8942797780036926,
          0.911249577999115,
          0.9150242805480957,
          0.9151293635368347,
          0.8918114304542542,
          0.9270684123039246,
          0.9473766088485718,
          0.9359638690948486,
          0.8963134288787842,
          0.8963367938995361,
          0.9046609997749329,
          0.9350093007087708,
          0.910872757434845,
          0.8966076374053955,
          0.9353910088539124,
          0.7721894979476929,
          0.9234212636947632,
          0.9182664155960083,
          0.8732871413230896,
          0.91022789478302,
          0.8724431991577148,
          0.9132703542709351,
          0.9196537137031555,
          0.881751537322998,
          0.9291503429412842,
          0.8432349562644958,
          0.9105355739593506,
          0.9285913705825806,
          0.9146754741668701,
          0.9039631485939026,
          0.9108745455741882,
          0.9198618531227112,
          0.8827731013298035,
          0.9364800453186035,
          0.9103785753250122,
          0.8800475597381592,
          0.8967484831809998,
          0.8596154451370239,
          0.8873477578163147,
          0.9215246438980103,
          0.921205461025238,
          0.9066266417503357,
          0.9454061985015869,
          0.9192184209823608,
          0.9333831667900085,
          0.9133592844009399,
          0.9319660067558289,
          0.900999903678894,
          0.8931176662445068,
          0.911533772945404,
          0.9376698732376099,
          0.9203823208808899,
          0.932003915309906,
          0.9165154099464417,
          0.9226694703102112,
          0.8668707013130188,
          0.9152398705482483,
          0.9241721034049988,
          0.896328330039978,
          0.9114659428596497,
          0.9331862926483154,
          0.8545018434524536,
          0.8664647936820984,
          0.9268741011619568,
          0.8672052621841431,
          0.9159060120582581,
          0.8698592185974121,
          0.8940141201019287,
          0.9275403022766113,
          0.912088930606842,
          0.9366860389709473,
          0.9208188652992249,
          0.9087966680526733,
          0.9226283431053162,
          0.8840897679328918,
          0.9235848188400269,
          0.897642970085144,
          0.9476405382156372,
          0.9152673482894897,
          0.9384613633155823,
          0.9052807688713074,
          0.9158798456192017,
          0.9273946285247803,
          0.9352132678031921,
          0.8650755882263184,
          0.9214029312133789,
          0.9181311130523682,
          0.9351919293403625,
          0.9219517111778259,
          0.9520649313926697,
          0.8973334431648254,
          0.9019286632537842,
          0.811560332775116,
          0.9085763096809387,
          0.9130203723907471,
          0.8164340853691101,
          0.8909425139427185,
          0.9281884431838989,
          0.9036648273468018,
          0.8755225539207458,
          0.9148229956626892,
          0.9165078401565552,
          0.922262966632843,
          0.9367237091064453,
          0.9158808588981628,
          0.8876335620880127,
          0.915457546710968,
          0.8945278525352478,
          0.9330491423606873,
          0.8891739845275879,
          0.9223813414573669,
          0.9325318336486816,
          0.9322348237037659,
          0.834412157535553,
          0.9266676902770996,
          0.931632399559021,
          0.9161204695701599,
          0.9036659002304077,
          0.9228169322013855,
          0.8538075685501099,
          0.9253543615341187,
          0.9143291115760803,
          0.9367583990097046,
          0.8708558678627014,
          0.8531535863876343,
          0.92046719789505,
          0.9220342636108398,
          0.9278429746627808,
          0.9109593629837036,
          0.9298203587532043,
          0.9343791007995605,
          0.9135328531265259,
          0.9256281852722168,
          0.9010297656059265,
          0.929118275642395,
          0.8309992551803589,
          0.9143085479736328,
          0.8760667443275452,
          0.9259206652641296,
          0.8945336937904358,
          0.932190477848053,
          0.903458833694458,
          0.9419082999229431,
          0.912219226360321,
          0.9182936549186707,
          0.9141058325767517,
          0.9027366042137146,
          0.9047548174858093,
          0.874739944934845,
          0.9226230978965759,
          0.901618480682373,
          0.8112666606903076,
          0.8860775232315063,
          0.9294242858886719,
          0.9139828085899353,
          0.9094757437705994,
          0.9352777600288391,
          0.9332619905471802,
          0.9145182371139526,
          0.9232938289642334,
          0.8754348754882812,
          0.8532257676124573,
          0.9142828583717346,
          0.9256744384765625,
          0.8965902328491211,
          0.9009729027748108,
          0.9439998865127563,
          0.9162911176681519,
          0.8528231978416443,
          0.9145509600639343,
          0.9122349619865417,
          0.9029449224472046,
          0.9415912628173828,
          0.9284611344337463,
          0.9424810409545898,
          0.9393731951713562,
          0.8855748176574707,
          0.9353960752487183,
          0.8976640701293945,
          0.8381655216217041,
          0.675158679485321,
          0.9231820106506348,
          0.8927567601203918,
          0.8916944861412048,
          0.9164716005325317,
          0.9383882284164429,
          0.8956156969070435,
          0.8688119053840637
         ],
         "xaxis": "x",
         "yaxis": "y"
        }
       ],
       "layout": {
        "barmode": "relative",
        "legend": {
         "title": {
          "text": "variable"
         },
         "tracegroupgap": 0
        },
        "margin": {
         "t": 60
        },
        "showlegend": false,
        "template": {
         "data": {
          "bar": [
           {
            "error_x": {
             "color": "#2a3f5f"
            },
            "error_y": {
             "color": "#2a3f5f"
            },
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "bar"
           }
          ],
          "barpolar": [
           {
            "marker": {
             "line": {
              "color": "#E5ECF6",
              "width": 0.5
             },
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "barpolar"
           }
          ],
          "carpet": [
           {
            "aaxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "baxis": {
             "endlinecolor": "#2a3f5f",
             "gridcolor": "white",
             "linecolor": "white",
             "minorgridcolor": "white",
             "startlinecolor": "#2a3f5f"
            },
            "type": "carpet"
           }
          ],
          "choropleth": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "choropleth"
           }
          ],
          "contour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "contour"
           }
          ],
          "contourcarpet": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "contourcarpet"
           }
          ],
          "heatmap": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmap"
           }
          ],
          "heatmapgl": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "heatmapgl"
           }
          ],
          "histogram": [
           {
            "marker": {
             "pattern": {
              "fillmode": "overlay",
              "size": 10,
              "solidity": 0.2
             }
            },
            "type": "histogram"
           }
          ],
          "histogram2d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2d"
           }
          ],
          "histogram2dcontour": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "histogram2dcontour"
           }
          ],
          "mesh3d": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "type": "mesh3d"
           }
          ],
          "parcoords": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "parcoords"
           }
          ],
          "pie": [
           {
            "automargin": true,
            "type": "pie"
           }
          ],
          "scatter": [
           {
            "fillpattern": {
             "fillmode": "overlay",
             "size": 10,
             "solidity": 0.2
            },
            "type": "scatter"
           }
          ],
          "scatter3d": [
           {
            "line": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatter3d"
           }
          ],
          "scattercarpet": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattercarpet"
           }
          ],
          "scattergeo": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergeo"
           }
          ],
          "scattergl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattergl"
           }
          ],
          "scattermapbox": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scattermapbox"
           }
          ],
          "scatterpolar": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolar"
           }
          ],
          "scatterpolargl": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterpolargl"
           }
          ],
          "scatterternary": [
           {
            "marker": {
             "colorbar": {
              "outlinewidth": 0,
              "ticks": ""
             }
            },
            "type": "scatterternary"
           }
          ],
          "surface": [
           {
            "colorbar": {
             "outlinewidth": 0,
             "ticks": ""
            },
            "colorscale": [
             [
              0,
              "#0d0887"
             ],
             [
              0.1111111111111111,
              "#46039f"
             ],
             [
              0.2222222222222222,
              "#7201a8"
             ],
             [
              0.3333333333333333,
              "#9c179e"
             ],
             [
              0.4444444444444444,
              "#bd3786"
             ],
             [
              0.5555555555555556,
              "#d8576b"
             ],
             [
              0.6666666666666666,
              "#ed7953"
             ],
             [
              0.7777777777777778,
              "#fb9f3a"
             ],
             [
              0.8888888888888888,
              "#fdca26"
             ],
             [
              1,
              "#f0f921"
             ]
            ],
            "type": "surface"
           }
          ],
          "table": [
           {
            "cells": {
             "fill": {
              "color": "#EBF0F8"
             },
             "line": {
              "color": "white"
             }
            },
            "header": {
             "fill": {
              "color": "#C8D4E3"
             },
             "line": {
              "color": "white"
             }
            },
            "type": "table"
           }
          ]
         },
         "layout": {
          "annotationdefaults": {
           "arrowcolor": "#2a3f5f",
           "arrowhead": 0,
           "arrowwidth": 1
          },
          "autotypenumbers": "strict",
          "coloraxis": {
           "colorbar": {
            "outlinewidth": 0,
            "ticks": ""
           }
          },
          "colorscale": {
           "diverging": [
            [
             0,
             "#8e0152"
            ],
            [
             0.1,
             "#c51b7d"
            ],
            [
             0.2,
             "#de77ae"
            ],
            [
             0.3,
             "#f1b6da"
            ],
            [
             0.4,
             "#fde0ef"
            ],
            [
             0.5,
             "#f7f7f7"
            ],
            [
             0.6,
             "#e6f5d0"
            ],
            [
             0.7,
             "#b8e186"
            ],
            [
             0.8,
             "#7fbc41"
            ],
            [
             0.9,
             "#4d9221"
            ],
            [
             1,
             "#276419"
            ]
           ],
           "sequential": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ],
           "sequentialminus": [
            [
             0,
             "#0d0887"
            ],
            [
             0.1111111111111111,
             "#46039f"
            ],
            [
             0.2222222222222222,
             "#7201a8"
            ],
            [
             0.3333333333333333,
             "#9c179e"
            ],
            [
             0.4444444444444444,
             "#bd3786"
            ],
            [
             0.5555555555555556,
             "#d8576b"
            ],
            [
             0.6666666666666666,
             "#ed7953"
            ],
            [
             0.7777777777777778,
             "#fb9f3a"
            ],
            [
             0.8888888888888888,
             "#fdca26"
            ],
            [
             1,
             "#f0f921"
            ]
           ]
          },
          "colorway": [
           "#636efa",
           "#EF553B",
           "#00cc96",
           "#ab63fa",
           "#FFA15A",
           "#19d3f3",
           "#FF6692",
           "#B6E880",
           "#FF97FF",
           "#FECB52"
          ],
          "font": {
           "color": "#2a3f5f"
          },
          "geo": {
           "bgcolor": "white",
           "lakecolor": "white",
           "landcolor": "#E5ECF6",
           "showlakes": true,
           "showland": true,
           "subunitcolor": "white"
          },
          "hoverlabel": {
           "align": "left"
          },
          "hovermode": "closest",
          "mapbox": {
           "style": "light"
          },
          "paper_bgcolor": "white",
          "plot_bgcolor": "#E5ECF6",
          "polar": {
           "angularaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "radialaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "scene": {
           "xaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "yaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           },
           "zaxis": {
            "backgroundcolor": "#E5ECF6",
            "gridcolor": "white",
            "gridwidth": 2,
            "linecolor": "white",
            "showbackground": true,
            "ticks": "",
            "zerolinecolor": "white"
           }
          },
          "shapedefaults": {
           "line": {
            "color": "#2a3f5f"
           }
          },
          "ternary": {
           "aaxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "baxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           },
           "bgcolor": "#E5ECF6",
           "caxis": {
            "gridcolor": "white",
            "linecolor": "white",
            "ticks": ""
           }
          },
          "title": {
           "x": 0.05
          },
          "xaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          },
          "yaxis": {
           "automargin": true,
           "gridcolor": "white",
           "linecolor": "white",
           "ticks": "",
           "title": {
            "standoff": 15
           },
           "zerolinecolor": "white",
           "zerolinewidth": 2
          }
         }
        },
        "xaxis": {
         "anchor": "y",
         "domain": [
          0,
          1
         ],
         "range": [
          -1,
          1
         ],
         "title": {
          "text": "Cosine similarity of decoder vectors between models"
         }
        },
        "yaxis": {
         "anchor": "x",
         "domain": [
          0,
          1
         ],
         "title": {
          "text": "Number of Latents (log scale)"
         },
         "type": "log"
        }
       }
      },
      "image/png": "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"
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "# %%\n",
    "\n",
    "fig = px.histogram(\n",
    "    relative_norms.detach().cpu().numpy(), \n",
    "    title=\"Pythia 1.3b checkpoint 30 vs Pythia 1.3b checkpoint 90\",\n",
    "    labels={\"value\": \"Relative decoder norm strength\"},\n",
    "    nbins=200,\n",
    ")\n",
    "\n",
    "fig.update_layout(showlegend=False)\n",
    "fig.update_yaxes(title_text=\"Number of Latents\")\n",
    "\n",
    "# Update x-axis ticks\n",
    "fig.update_xaxes(\n",
    "    tickvals=[0, 0.25, 0.5, 0.75, 1.0],\n",
    "    ticktext=['0', '0.25', '0.5', '0.75', '1.0']\n",
    ")\n",
    "\n",
    "# Display in notebook\n",
    "fig.show()\n",
    "\n",
    "# %%\n",
    "shared_latent_mask = (relative_norms < 0.7) & (relative_norms > 0.3)\n",
    "shared_latent_mask.shape\n",
    "# %%\n",
    "# Cosine similarity of recoder vectors between models\n",
    "\n",
    "cosine_sims = (cross_coder.W_dec[:, 0, :] * cross_coder.W_dec[:, 1, :]).sum(dim=-1) / (cross_coder.W_dec[:, 0, :].norm(dim=-1) * cross_coder.W_dec[:, 1, :].norm(dim=-1))\n",
    "cosine_sims.shape\n",
    "# %%\n",
    "\n",
    "fig = px.histogram(\n",
    "    cosine_sims[shared_latent_mask].to(torch.float32).detach().cpu().numpy(), \n",
    "    log_y=True,  # Sets the y-axis to log scale\n",
    "    range_x=[-1, 1],  # Sets the x-axis range from -1 to 1\n",
    "    nbins=100,  # Adjust this value to change the number of bins\n",
    "    labels={\"value\": \"Cosine similarity of decoder vectors between models\"}\n",
    ")\n",
    "\n",
    "fig.update_layout(showlegend=False)\n",
    "fig.update_yaxes(title_text=\"Number of Latents (log scale)\")\n",
    "\n",
    "# Display in notebook\n",
    "fig.show()\n",
    "\n",
    "# %%"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e36ccb9a-edcc-49b5-9983-72a7b7f4f1a3",
   "metadata": {},
   "source": [
    "# Analyse the unique latents"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d1c71bb5-74bf-4b62-83d6-a67e592f5c4a",
   "metadata": {},
   "source": [
    "## Maximum activating examples\n",
    "Get tokens that maximally activate latent_idx\n",
    "- Run a bunch of tokens, collect activations and probably cache these\n",
    "- Run activations through encode in batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "133a883f-4324-4d75-80a9-c5b6efb0f552",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_max_activating_tokens(cross_coder, model_A, model_B, tokens, latent_idx, top_k=10):\n",
    "    \"\"\"\n",
    "    tokens: input tokens to analyze [batch, seq_len]\n",
    "    latent_idx: which latent dimension to analyze\n",
    "    \"\"\"\n",
    "    with torch.no_grad():\n",
    "        # Get activations from both models\n",
    "        _, cache_A = model_A.run_with_cache(tokens, names_filter=\"blocks.18.hook_resid_pre\")\n",
    "        _, cache_B = model_B.run_with_cache(tokens, names_filter=\"blocks.18.hook_resid_pre\")\n",
    "        \n",
    "        # Stack activations [2, batch, seq_len, d_model]\n",
    "        acts = torch.stack([\n",
    "            cache_A[\"blocks.18.hook_resid_pre\"],   \n",
    "            cache_B[\"blocks.18.hook_resid_pre\"]\n",
    "        ], dim=0)\n",
    "\n",
    "        # print(acts.shape)\n",
    "        \n",
    "        # Reshape to [batch*seq_len, 2, d_model]\n",
    "        acts = einops.rearrange(acts, \n",
    "            \"n_models batch seq_len d_model -> (batch seq_len) n_models d_model\")\n",
    "        \n",
    "        # Get encoded activations\n",
    "        encoded = cross_coder.encode(acts)  # [(batch*seq_len), d_hidden]\n",
    "        \n",
    "        # Get activations for specific latent\n",
    "        latent_acts = encoded[:, latent_idx]\n",
    "        \n",
    "        # Find top activating positions\n",
    "        top_values, top_indices = latent_acts.topk(top_k)\n",
    "        \n",
    "        # Map top_indices back to batch and sequence indices\n",
    "        batch_size, seq_len = tokens.shape\n",
    "        token_indices = top_indices % (batch_size * seq_len)\n",
    "        batch_indices = token_indices // seq_len\n",
    "        seq_indices = token_indices % seq_len\n",
    "        \n",
    "        return batch_indices, seq_indices, top_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ff9f6f1-d6bb-4522-81b3-1a71813b426d",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda:0'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "ab103133-a75b-4f67-b7e6-38758679e0fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "# import gc\n",
    "\n",
    "# gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "dd3fa27a-67a5-4590-933d-bc618811e858",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Pythia models on HF were updated on 4/3/23! add '-v0' to model name to access the old models.\n",
      "The `GPTNeoXSdpaAttention` class is deprecated in favor of simply modifying the `config._attn_implementation`attribute of the `GPTNeoXAttention` class! It will be removed in v4.48\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model pythia-1.3b into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda:0'\n",
    "\n",
    "N_1 = 30\n",
    "pythia1 = HookedTransformer.from_pretrained(\"pythia-1.3b\", checkpoint_index=N_1, device = device)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "834ac711-6395-447a-b2b6-4545f246f5f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ModuleList(\n",
       "  (0-23): 24 x TransformerBlock(\n",
       "    (ln1): LayerNormPre(\n",
       "      (hook_scale): HookPoint()\n",
       "      (hook_normalized): HookPoint()\n",
       "    )\n",
       "    (ln2): LayerNormPre(\n",
       "      (hook_scale): HookPoint()\n",
       "      (hook_normalized): HookPoint()\n",
       "    )\n",
       "    (attn): Attention(\n",
       "      (hook_k): HookPoint()\n",
       "      (hook_q): HookPoint()\n",
       "      (hook_v): HookPoint()\n",
       "      (hook_z): HookPoint()\n",
       "      (hook_attn_scores): HookPoint()\n",
       "      (hook_pattern): HookPoint()\n",
       "      (hook_result): HookPoint()\n",
       "      (hook_rot_k): HookPoint()\n",
       "      (hook_rot_q): HookPoint()\n",
       "    )\n",
       "    (mlp): MLP(\n",
       "      (hook_pre): HookPoint()\n",
       "      (hook_post): HookPoint()\n",
       "    )\n",
       "    (hook_attn_in): HookPoint()\n",
       "    (hook_q_input): HookPoint()\n",
       "    (hook_k_input): HookPoint()\n",
       "    (hook_v_input): HookPoint()\n",
       "    (hook_mlp_in): HookPoint()\n",
       "    (hook_attn_out): HookPoint()\n",
       "    (hook_mlp_out): HookPoint()\n",
       "    (hook_resid_pre): HookPoint()\n",
       "    (hook_resid_post): HookPoint()\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pythia1.blocks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3dafb4a6-0cbe-42f2-96fc-9149e25077e9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Pythia models on HF were updated on 4/3/23! add '-v0' to model name to access the old models.\n",
      "huggingface/tokenizers: The current process just got forked, after parallelism has already been used. Disabling parallelism to avoid deadlocks...\n",
      "To disable this warning, you can either:\n",
      "\t- Avoid using `tokenizers` before the fork if possible\n",
      "\t- Explicitly set the environment variable TOKENIZERS_PARALLELISM=(true | false)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loaded pretrained model pythia-1.3b into HookedTransformer\n"
     ]
    }
   ],
   "source": [
    "N_2 = 90\n",
    "pythia2 = HookedTransformer.from_pretrained(\"pythia-1.3b\", checkpoint_index=N_2, device = device) # commented out due to too much memory"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0046cd17-dfc9-4c2b-815a-9350152e07a8",
   "metadata": {},
   "source": [
    "### loading in latents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "07734685-c3e7-410e-9912-99c25cef01e1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading data from disk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/crosscoders/crosscoder-model-diff-replication/utils.py:184: FutureWarning:\n",
      "\n",
      "You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from utils import load_pile_deduped_pythia_random_sampled\n",
    "test_tokens = load_pile_deduped_pythia_random_sampled()[:10240]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "83b75e1b-b83f-4a50-bfc0-c1cfae5e6664",
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_token_in_context(tokens, batch_idx, seq_idx, window_size=10, model=pythia2):\n",
    "    \"\"\"\n",
    "    Print a window of tokens around a specific token, showing maximum available context\n",
    "    \"\"\"\n",
    "    # Get start and end indices, bounded by sequence length\n",
    "    start = max(0, seq_idx - window_size)\n",
    "    end = min(tokens.shape[1], seq_idx + window_size + 1)\n",
    "    \n",
    "    # Get the context window and target token\n",
    "    context = tokens[batch_idx, start:end]\n",
    "    target_token = tokens[batch_idx, seq_idx]\n",
    "    \n",
    "    # Get the strings\n",
    "    text = model.to_string(context)\n",
    "    token_str = model.to_string(target_token)\n",
    "    \n",
    "    # Replace whitespace with visible characters for display\n",
    "    token_display = token_str.replace(' ', '␣').replace('\\n', '⏎').replace('\\t', '⇥')\n",
    "\n",
    "    # Print with color\n",
    "    colors = {\n",
    "        'red': '\\033[91m',\n",
    "        'blue': '\\033[94m',\n",
    "        'ENDC': '\\033[0m'\n",
    "    }\n",
    "    \n",
    "    # For debugging\n",
    "    print(f\"{colors['blue']}Token: '{token_display}'{colors['ENDC']}\")\n",
    "    \n",
    "    # Split into individual tokens and find the target token position\n",
    "    context_tokens = [model.to_string(t) for t in context]\n",
    "    relative_pos = seq_idx - start\n",
    "    \n",
    "    # Calculate string positions\n",
    "    start_pos = sum(len(t) for t in context_tokens[:relative_pos])\n",
    "    token_len = len(context_tokens[relative_pos])\n",
    "    \n",
    "    print(text[:start_pos] + \n",
    "          colors['red'] + text[start_pos:start_pos+token_len] + colors['ENDC'] + \n",
    "          text[start_pos+token_len:])\n",
    "\n",
    "def analyse_max_act_tok_batched(latent_idx, batch_size=32, topk=10):\n",
    "    print(\"-\" * 50)\n",
    "    print(\"LatentIDX:\", latent_idx.item())\n",
    "    \n",
    "    # Lists to store results from each batch\n",
    "    all_batch_indices = []\n",
    "    all_seq_indices = []\n",
    "    all_values = []\n",
    "    \n",
    "    # Process in batches\n",
    "    for i in tqdm(range(0, len(test_tokens), batch_size)):\n",
    "        batch_tokens = test_tokens[i:i+batch_size].to(device)\n",
    "        \n",
    "        # Get top k for this batch\n",
    "        batch_indices, seq_indices, values = get_max_activating_tokens(\n",
    "            cross_coder, pythia1, pythia2, batch_tokens, latent_idx, top_k=topk\n",
    "        )\n",
    "        \n",
    "        # Adjust batch indices to global indices\n",
    "        batch_indices = batch_indices + i\n",
    "        \n",
    "        # Store results\n",
    "        all_batch_indices.extend(batch_indices.cpu())\n",
    "        all_seq_indices.extend(seq_indices.cpu())\n",
    "        all_values.extend(values.cpu())\n",
    "    \n",
    "    # Convert to tensors\n",
    "    all_batch_indices = torch.tensor(all_batch_indices)\n",
    "    all_seq_indices = torch.tensor(all_seq_indices)\n",
    "    all_values = torch.tensor(all_values)\n",
    "    \n",
    "    # Get overall top 10\n",
    "    top_k = 10\n",
    "    top_indices = torch.topk(all_values, min(top_k, len(all_values)))\n",
    "    final_batch_indices = all_batch_indices[top_indices.indices]\n",
    "    final_seq_indices = all_seq_indices[top_indices.indices]\n",
    "    \n",
    "    print(\"\\nTop activating contexts:\")\n",
    "    print(\"-\" * 50)\n",
    "    for i, (batch_idx, seq_idx) in enumerate(zip(final_batch_indices, final_seq_indices)):\n",
    "        print(f\"\\n{i+1}. Value: {top_indices.values[i]:.3f}\")\n",
    "        print_token_in_context(test_tokens, batch_idx, seq_idx, window_size=10, model=pythia2)\n",
    "    \n",
    "    # Clean up memory\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    return final_batch_indices, final_seq_indices, top_indices.values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "11a35550-3543-4310-b17a-6566a247108c",
   "metadata": {},
   "source": [
    "## Let's take a look at latents mostly unique to Pythia 1.3b checkpoint 90..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "c299693b-476c-4daf-8549-1eb84ca99338",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2135"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.empty_cache()\n",
    "import gc\n",
    "gc.collect()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bceed015-801b-4610-9828-ba22afbd8e01",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "LatentIDX: 224\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "00%|████████████████████████████████████████████████████████████████████████| 40/40 [03:47<00:00,  5.68s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top activating contexts:\n",
      "--------------------------------------------------\n",
      "\n",
      "1. Value: 63.713\n",
      "\u001b[94mToken: '⏎⏎⏎⏎⏎'\u001b[0m\n",
      "\u001b[91m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[0m                                      -8-\n",
      "\f",
      "J-\n",
      "\n",
      "2. Value: 63.278\n",
      "\u001b[94mToken: ''\u001b[0m\n",
      "ç\u001b[91m\u001b[0m¨ç¡¬ä»¶æ¯\n",
      "\n",
      "3. Value: 59.157\n",
      "\u001b[94mToken: '⏎⏎⏎'\u001b[0m\n",
      "\u001b[91m\n",
      "\n",
      "\n",
      "\u001b[0m       In the light most favorable to the State,\n",
      "\n",
      "4. Value: 51.577\n",
      "\u001b[94mToken: '```'\u001b[0m\n",
      "\u001b[91m```\u001b[0m\n",
      "> ./gradlew assemble\n",
      "\n",
      "BUILD SU\n",
      "\n",
      "5. Value: 50.356\n",
      "\u001b[94mToken: '--'\u001b[0m\n",
      "\u001b[91m--\u001b[0mno matter what happens.\"\n",
      "\n",
      "He'd reached\n",
      "\n",
      "6. Value: 50.356\n",
      "\u001b[94mToken: '--'\u001b[0m\n",
      "\u001b[91m--\u001b[0m367) μg/g at entry vs 142 (\n",
      "\n",
      "7. Value: 49.416\n",
      "\u001b[94mToken: '�'\u001b[0m\n",
      "�\u001b[91m京\u001b[0m风味小吃中�\n",
      "\n",
      "8. Value: 47.008\n",
      "\u001b[94mToken: '‘'\u001b[0m\n",
      "\u001b[91m‘\u001b[0ms “Redneck Crazy,”\n",
      "some radio\n",
      "\n",
      "9. Value: 46.916\n",
      "\u001b[94mToken: '␣very'\u001b[0m\n",
      "\u001b[91m very\u001b[0m fact that a Homo sapien named \"Pet\n",
      "\n",
      "10. Value: 46.916\n",
      "\u001b[94mToken: '␣very'\u001b[0m\n",
      "\u001b[91m very\u001b[0m seriously, studying hard and insisting that she would prefer\n",
      "--------------------------------------------------\n",
      "LatentIDX: 372\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "00%|████████████████████████████████████████████████████████████████████████| 40/40 [03:48<00:00,  5.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top activating contexts:\n",
      "--------------------------------------------------\n",
      "\n",
      "1. Value: 71.878\n",
      "\u001b[94mToken: '13'\u001b[0m\n",
      "                        \u001b[91m13\u001b[0m\n",
      "\n",
      "\n",
      "appraisal report itself for defects under the\n",
      "\n",
      "2. Value: 68.508\n",
      "\u001b[94mToken: '�'\u001b[0m\n",
      "�\u001b[91m京\u001b[0m风味小吃中�\n",
      "\n",
      "3. Value: 65.039\n",
      "\u001b[94mToken: '␣cant'\u001b[0m\n",
      " i said i just\u001b[91m cant\u001b[0m see a reason why Brazil will not win this ,\n",
      "\n",
      "4. Value: 63.120\n",
      "\u001b[94mToken: '17'\u001b[0m\n",
      "15\u001b[91m17\u001b[0m, Q. Nos. 12-17) The\n",
      "\n",
      "5. Value: 60.689\n",
      "\u001b[94mToken: '␣\"'\u001b[0m\n",
      "... \"\u001b[91m \"\u001b[0mYou tell me.\" \"Elias says she\n",
      "\n",
      "6. Value: 60.158\n",
      "\u001b[94mToken: '␣web'\u001b[0m\n",
      "Reader\u001b[91m web\u001b[0mInput2 = new BufferedReader( \n",
      "    \n",
      "\n",
      "7. Value: 58.573\n",
      "\u001b[94mToken: 'NA'\u001b[0m\n",
      "\u001b[91mNA\u001b[0mNUnion64                     = { kFloat64NA\n",
      "\n",
      "8. Value: 58.345\n",
      "\u001b[94mToken: 'RR'\u001b[0m\n",
      "\u001b[91mRR\u001b[0mCConnectionRelease) message at step 270. As\n",
      "\n",
      "9. Value: 58.345\n",
      "\u001b[94mToken: 'RR'\u001b[0m\n",
      "\u001b[91mRR\u001b[0mC) is Manitoba’s largest institute of\n",
      "\n",
      "10. Value: 56.738\n",
      "\u001b[94mToken: '␣Magazine'\u001b[0m\n",
      " Markets\u001b[91m Magazine\u001b[0m Micro MediaKit\n",
      "\n",
      "Bloomberg Markets Magazine\n",
      "--------------------------------------------------\n",
      "LatentIDX: 550\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "00%|████████████████████████████████████████████████████████████████████████| 40/40 [03:48<00:00,  5.71s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top activating contexts:\n",
      "--------------------------------------------------\n",
      "\n",
      "1. Value: 29.438\n",
      "\u001b[94mToken: '!['\u001b[0m\n",
      "--------------------------------------- ---------------------------------------\n",
      "\n",
      "  ---------------------------------------- ----------------------------------------\n",
      "   \u001b[91m![\u001b[0mimage](pyr_ip_v2.\n",
      "\n",
      "2. Value: 28.083\n",
      "\u001b[94mToken: '␣\\['\u001b[0m\n",
      " does leak significant information between the flows. In Section\u001b[91m \\[\u001b[0m\n",
      "\n",
      "3. Value: 26.954\n",
      "\u001b[94mToken: '.'\u001b[0m\n",
      "mette l'accesso al dominio example\u001b[91m.\u001b[0morg e a tutti i suoi sottod\n",
      "\n",
      "4. Value: 26.200\n",
      "\u001b[94mToken: '\\['\u001b[0m\n",
      ". \\[sec2\\]. In Sect. \u001b[91m\\[\u001b[0msec3\\], we show a phase diagram of\n",
      "\n",
      "5. Value: 25.712\n",
      "\u001b[94mToken: '␣\\['\u001b[0m\n",
      " in this paper does not make this feasible. Section\u001b[91m \\[\u001b[0msec:formalization\\] describes the Ag\n",
      "\n",
      "6. Value: 24.638\n",
      "\u001b[94mToken: '␣(\\['\u001b[0m\n",
      "{eq:var2}$$\n",
      "\n",
      "Using equation\u001b[91m (\\[\u001b[0meq\n",
      "\n",
      "7. Value: 24.569\n",
      "\u001b[94mToken: '.'\u001b[0m\n",
      "\"/>\n",
      "\n",
      "    <!-- urn:absolute:example\u001b[91m.\u001b[0mcom/#Keyboard -->\n",
      "\n",
      "    <owl:\n",
      "\n",
      "8. Value: 23.931\n",
      "\u001b[94mToken: '␣receive'\u001b[0m\n",
      "International\n",
      "\n",
      "Spend $200 or more to\u001b[91m receive\u001b[0m free shipping to anywhere else in the world.\n",
      "\n",
      "\n",
      "9. Value: 22.981\n",
      "\u001b[94mToken: '**'\u001b[0m\n",
      "retch**\n",
      "\n",
      "(directions)\n",
      "\n",
      "\u001b[91m**\u001b[0m3**\n",
      "\n",
      "###\n",
      "\n",
      "10. Value: 22.488\n",
      "\u001b[94mToken: '.'\u001b[0m\n",
      "Cannot initiate the connection to in.archive.ubuntu\u001b[91m.\u001b[0mcom:80 (2001:67c:13\n",
      "--------------------------------------------------\n",
      "LatentIDX: 803\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "00%|████████████████████████████████████████████████████████████████████████| 40/40 [03:48<00:00,  5.72s/it]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Top activating contexts:\n",
      "--------------------------------------------------\n",
      "\n",
      "1. Value: 73.377\n",
      "\u001b[94mToken: '⏎⏎⏎⏎⏎'\u001b[0m\n",
      "\u001b[91m\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\u001b[0m                                      -8-\n",
      "\f",
      "J-\n",
      "\n",
      "2. Value: 73.282\n",
      "\u001b[94mToken: '�'\u001b[0m\n",
      "�\u001b[91m京\u001b[0m风味小吃中�\n",
      "\n",
      "3. Value: 71.190\n",
      "\u001b[94mToken: ''\u001b[0m\n",
      "ç\u001b[91m\u001b[0m¨ç¡¬ä»¶æ¯\n",
      "\n",
      "4. Value: 69.067\n",
      "\u001b[94mToken: '⏎⏎⏎'\u001b[0m\n",
      "\u001b[91m\n",
      "\n",
      "\n",
      "\u001b[0m       In the light most favorable to the State,\n",
      "\n",
      "5. Value: 68.977\n",
      "\u001b[94mToken: '--'\u001b[0m\n",
      "\u001b[91m--\u001b[0mno matter what happens.\"\n",
      "\n",
      "He'd reached\n",
      "\n",
      "6. Value: 68.977\n",
      "\u001b[94mToken: '--'\u001b[0m\n",
      "\u001b[91m--\u001b[0m367) μg/g at entry vs 142 (\n",
      "\n",
      "7. Value: 67.939\n",
      "\u001b[94mToken: '```'\u001b[0m\n",
      "\u001b[91m```\u001b[0m\n",
      "> ./gradlew assemble\n",
      "\n",
      "BUILD SU\n",
      "\n",
      "8. Value: 59.487\n",
      "\u001b[94mToken: '13'\u001b[0m\n",
      "                        \u001b[91m13\u001b[0m\n",
      "\n",
      "\n",
      "appraisal report itself for defects under the\n",
      "\n",
      "9. Value: 58.237\n",
      "\u001b[94mToken: '‘'\u001b[0m\n",
      "\u001b[91m‘\u001b[0ms “Redneck Crazy,”\n",
      "some radio\n",
      "\n",
      "10. Value: 56.667\n",
      "\u001b[94mToken: '␣i'\u001b[0m\n",
      " i said\u001b[91m i\u001b[0m just cant see a reason why Brazil will not win\n",
      "--------------------------------------------------\n",
      "LatentIDX: 1208\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      " 5%|███▋                                                                     | 2/40 [00:14<04:34,  7.21s/it]"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[15], line 4\u001b[0m\n\u001b[1;32m      2\u001b[0m indices_0 \u001b[38;5;241m=\u001b[39m mask\u001b[38;5;241m.\u001b[39mnonzero()\u001b[38;5;241m.\u001b[39msqueeze()\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m latent_idx \u001b[38;5;129;01min\u001b[39;00m indices_0:\n\u001b[0;32m----> 4\u001b[0m     \u001b[43manalyse_max_act_tok_batched\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlatent_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m256\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[13], line 56\u001b[0m, in \u001b[0;36manalyse_max_act_tok_batched\u001b[0;34m(latent_idx, batch_size, topk)\u001b[0m\n\u001b[1;32m     53\u001b[0m batch_tokens \u001b[38;5;241m=\u001b[39m test_tokens[i:i\u001b[38;5;241m+\u001b[39mbatch_size]\u001b[38;5;241m.\u001b[39mto(device)\n\u001b[1;32m     55\u001b[0m \u001b[38;5;66;03m# Get top k for this batch\u001b[39;00m\n\u001b[0;32m---> 56\u001b[0m batch_indices, seq_indices, values \u001b[38;5;241m=\u001b[39m \u001b[43mget_max_activating_tokens\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     57\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcross_coder\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpythia1\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpythia2\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbatch_tokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlatent_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtop_k\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtopk\u001b[49m\n\u001b[1;32m     58\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     60\u001b[0m \u001b[38;5;66;03m# Adjust batch indices to global indices\u001b[39;00m\n\u001b[1;32m     61\u001b[0m batch_indices \u001b[38;5;241m=\u001b[39m batch_indices \u001b[38;5;241m+\u001b[39m i\n",
      "Cell \u001b[0;32mIn[7], line 9\u001b[0m, in \u001b[0;36mget_max_activating_tokens\u001b[0;34m(cross_coder, model_A, model_B, tokens, latent_idx, top_k)\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m      7\u001b[0m     \u001b[38;5;66;03m# Get activations from both models\u001b[39;00m\n\u001b[1;32m      8\u001b[0m     _, cache_A \u001b[38;5;241m=\u001b[39m model_A\u001b[38;5;241m.\u001b[39mrun_with_cache(tokens, names_filter\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mblocks.18.hook_resid_pre\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m----> 9\u001b[0m     _, cache_B \u001b[38;5;241m=\u001b[39m \u001b[43mmodel_B\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_with_cache\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtokens\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnames_filter\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mblocks.18.hook_resid_pre\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     11\u001b[0m     \u001b[38;5;66;03m# Stack activations [2, batch, seq_len, d_model]\u001b[39;00m\n\u001b[1;32m     12\u001b[0m     acts \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mstack([\n\u001b[1;32m     13\u001b[0m         cache_A[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mblocks.18.hook_resid_pre\u001b[39m\u001b[38;5;124m\"\u001b[39m],   \n\u001b[1;32m     14\u001b[0m         cache_B[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mblocks.18.hook_resid_pre\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m     15\u001b[0m     ], dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m0\u001b[39m)\n",
      "File \u001b[0;32m~/crosscoders/crosscoder-model-diff-replication/venv/lib/python3.10/site-packages/transformer_lens/HookedTransformer.py:658\u001b[0m, in \u001b[0;36mHookedTransformer.run_with_cache\u001b[0;34m(self, return_cache_object, remove_batch_dim, *model_args, **kwargs)\u001b[0m\n\u001b[1;32m    641\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrun_with_cache\u001b[39m(\n\u001b[1;32m    642\u001b[0m     \u001b[38;5;28mself\u001b[39m, \u001b[38;5;241m*\u001b[39mmodel_args, return_cache_object\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, remove_batch_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs\n\u001b[1;32m    643\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tuple[\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    650\u001b[0m     Union[ActivationCache, Dict[\u001b[38;5;28mstr\u001b[39m, torch\u001b[38;5;241m.\u001b[39mTensor]],\n\u001b[1;32m    651\u001b[0m ]:\n\u001b[1;32m    652\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Wrapper around `run_with_cache` in HookedRootModule.\u001b[39;00m\n\u001b[1;32m    653\u001b[0m \n\u001b[1;32m    654\u001b[0m \u001b[38;5;124;03m    If return_cache_object is True, this will return an ActivationCache object, with a bunch of\u001b[39;00m\n\u001b[1;32m    655\u001b[0m \u001b[38;5;124;03m    useful HookedTransformer specific methods, otherwise it will return a dictionary of\u001b[39;00m\n\u001b[1;32m    656\u001b[0m \u001b[38;5;124;03m    activations as in HookedRootModule.\u001b[39;00m\n\u001b[1;32m    657\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 658\u001b[0m     out, cache_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrun_with_cache\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    659\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mremove_batch_dim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mremove_batch_dim\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\n\u001b[1;32m    660\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    661\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m return_cache_object:\n\u001b[1;32m    662\u001b[0m         cache \u001b[38;5;241m=\u001b[39m ActivationCache(cache_dict, \u001b[38;5;28mself\u001b[39m, has_batch_dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;129;01mnot\u001b[39;00m remove_batch_dim)\n",
      "File \u001b[0;32m~/crosscoders/crosscoder-model-diff-replication/venv/lib/python3.10/site-packages/transformer_lens/hook_points.py:566\u001b[0m, in \u001b[0;36mHookedRootModule.run_with_cache\u001b[0;34m(self, names_filter, device, remove_batch_dim, incl_bwd, reset_hooks_end, clear_contexts, pos_slice, *model_args, **model_kwargs)\u001b[0m\n\u001b[1;32m    552\u001b[0m cache_dict, fwd, bwd \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mget_caching_hooks(\n\u001b[1;32m    553\u001b[0m     names_filter,\n\u001b[1;32m    554\u001b[0m     incl_bwd,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    557\u001b[0m     pos_slice\u001b[38;5;241m=\u001b[39mpos_slice,\n\u001b[1;32m    558\u001b[0m )\n\u001b[1;32m    560\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhooks(\n\u001b[1;32m    561\u001b[0m     fwd_hooks\u001b[38;5;241m=\u001b[39mfwd,\n\u001b[1;32m    562\u001b[0m     bwd_hooks\u001b[38;5;241m=\u001b[39mbwd,\n\u001b[1;32m    563\u001b[0m     reset_hooks_end\u001b[38;5;241m=\u001b[39mreset_hooks_end,\n\u001b[1;32m    564\u001b[0m     clear_contexts\u001b[38;5;241m=\u001b[39mclear_contexts,\n\u001b[1;32m    565\u001b[0m ):\n\u001b[0;32m--> 566\u001b[0m     model_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_args\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    567\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m incl_bwd:\n\u001b[1;32m    568\u001b[0m         model_out\u001b[38;5;241m.\u001b[39mbackward()\n",
      "File \u001b[0;32m~/crosscoders/crosscoder-model-diff-replication/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/crosscoders/crosscoder-model-diff-replication/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/crosscoders/crosscoder-model-diff-replication/venv/lib/python3.10/site-packages/transformer_lens/HookedTransformer.py:576\u001b[0m, in \u001b[0;36mHookedTransformer.forward\u001b[0;34m(self, input, return_type, loss_per_token, prepend_bos, padding_side, start_at_layer, tokens, shortformer_pos_embed, attention_mask, stop_at_layer, past_kv_cache)\u001b[0m\n\u001b[1;32m    571\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m shortformer_pos_embed \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    572\u001b[0m         shortformer_pos_embed \u001b[38;5;241m=\u001b[39m shortformer_pos_embed\u001b[38;5;241m.\u001b[39mto(\n\u001b[1;32m    573\u001b[0m             devices\u001b[38;5;241m.\u001b[39mget_device_for_block_index(i, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg)\n\u001b[1;32m    574\u001b[0m         )\n\u001b[0;32m--> 576\u001b[0m     residual \u001b[38;5;241m=\u001b[39m \u001b[43mblock\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    577\u001b[0m \u001b[43m        \u001b[49m\u001b[43mresidual\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    578\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Cache contains a list of HookedTransformerKeyValueCache objects, one for each\u001b[39;49;00m\n\u001b[1;32m    579\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# block\u001b[39;49;00m\n\u001b[1;32m    580\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_kv_cache_entry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_kv_cache\u001b[49m\u001b[43m[\u001b[49m\u001b[43mi\u001b[49m\u001b[43m]\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mpast_kv_cache\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[1;32m    581\u001b[0m \u001b[43m        \u001b[49m\u001b[43mshortformer_pos_embed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshortformer_pos_embed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    582\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    583\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# [batch, pos, d_model]\u001b[39;00m\n\u001b[1;32m    585\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m stop_at_layer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    586\u001b[0m     \u001b[38;5;66;03m# When we stop at an early layer, we end here rather than doing further computation\u001b[39;00m\n\u001b[1;32m    587\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m residual\n",
      "File \u001b[0;32m~/crosscoders/crosscoder-model-diff-replication/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/crosscoders/crosscoder-model-diff-replication/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/crosscoders/crosscoder-model-diff-replication/venv/lib/python3.10/site-packages/transformer_lens/components/transformer_block.py:160\u001b[0m, in \u001b[0;36mTransformerBlock.forward\u001b[0;34m(self, resid_pre, shortformer_pos_embed, past_kv_cache_entry, attention_mask)\u001b[0m\n\u001b[1;32m    153\u001b[0m     key_input \u001b[38;5;241m=\u001b[39m attn_in\n\u001b[1;32m    154\u001b[0m     value_input \u001b[38;5;241m=\u001b[39m attn_in\n\u001b[1;32m    156\u001b[0m attn_out \u001b[38;5;241m=\u001b[39m (\n\u001b[1;32m    157\u001b[0m     \u001b[38;5;66;03m# hook the residual stream states that are used to calculate the\u001b[39;00m\n\u001b[1;32m    158\u001b[0m     \u001b[38;5;66;03m# queries, keys and values, independently.\u001b[39;00m\n\u001b[1;32m    159\u001b[0m     \u001b[38;5;66;03m# Then take the layer norm of these inputs, and pass these to the attention module.\u001b[39;00m\n\u001b[0;32m--> 160\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mattn\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    161\u001b[0m \u001b[43m        \u001b[49m\u001b[43mquery_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mln1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    162\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mshortformer_pos_embed\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mshortformer_pos_embed\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    163\u001b[0m \u001b[43m        \u001b[49m\u001b[43mkey_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mln1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mkey_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    164\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m0.0\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mshortformer_pos_embed\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mis\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mshortformer_pos_embed\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalue_input\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mln1\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue_input\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[43m        \u001b[49m\u001b[43mpast_kv_cache_entry\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mpast_kv_cache_entry\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    167\u001b[0m \u001b[43m        \u001b[49m\u001b[43mattention_mask\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mattention_mask\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    168\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    169\u001b[0m )  \u001b[38;5;66;03m# [batch, pos, d_model]\u001b[39;00m\n\u001b[1;32m    170\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcfg\u001b[38;5;241m.\u001b[39muse_normalization_before_and_after:\n\u001b[1;32m    171\u001b[0m     \u001b[38;5;66;03m# If we use LayerNorm both before and after, then apply the second LN after the layer\u001b[39;00m\n\u001b[1;32m    172\u001b[0m     \u001b[38;5;66;03m# and before the hook. We do it before the hook so hook_attn_out captures \"that which\u001b[39;00m\n\u001b[1;32m    173\u001b[0m     \u001b[38;5;66;03m# is added to the residual stream\"\u001b[39;00m\n\u001b[1;32m    174\u001b[0m     attn_out \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mln1_post(attn_out)\n",
      "File \u001b[0;32m~/crosscoders/crosscoder-model-diff-replication/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/crosscoders/crosscoder-model-diff-replication/venv/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/crosscoders/crosscoder-model-diff-replication/venv/lib/python3.10/site-packages/transformer_lens/components/abstract_attention.py:196\u001b[0m, in \u001b[0;36mAbstractAttention.forward\u001b[0;34m(self, query_input, key_input, value_input, past_kv_cache_entry, additive_attention_mask, attention_mask, position_bias)\u001b[0m\n\u001b[1;32m    168\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m    169\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m    170\u001b[0m     query_input: Union[\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    187\u001b[0m     position_bias: Optional[Float[torch\u001b[38;5;241m.\u001b[39mTensor, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m1 head_index pos kv_pos\u001b[39m\u001b[38;5;124m\"\u001b[39m]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    188\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Float[torch\u001b[38;5;241m.\u001b[39mTensor, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch pos d_model\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m    189\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    190\u001b[0m \u001b[38;5;124;03m    shortformer_pos_embed is only used if self.cfg.positional_embedding_type == \"shortformer\", else defaults to None and is irrelevant. See HookedTransformerConfig for more details\u001b[39;00m\n\u001b[1;32m    191\u001b[0m \u001b[38;5;124;03m    past_kv_cache_entry is an optional entry of past keys and values for this layer, only relevant if generating text. Defaults to None\u001b[39;00m\n\u001b[1;32m    192\u001b[0m \u001b[38;5;124;03m    additive_attention_mask is an optional mask to add to the attention weights. Defaults to None.\u001b[39;00m\n\u001b[1;32m    193\u001b[0m \u001b[38;5;124;03m    attention_mask is the attention mask for padded tokens. Defaults to None.\u001b[39;00m\n\u001b[1;32m    194\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 196\u001b[0m     q, k, v \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcalculate_qkv_matrices\u001b[49m\u001b[43m(\u001b[49m\u001b[43mquery_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkey_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mvalue_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    198\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m past_kv_cache_entry \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    199\u001b[0m         \u001b[38;5;66;03m# Appends the new keys and values to the cached values, and automatically updates the cache\u001b[39;00m\n\u001b[1;32m    200\u001b[0m         kv_cache_pos_offset \u001b[38;5;241m=\u001b[39m past_kv_cache_entry\u001b[38;5;241m.\u001b[39mpast_keys\u001b[38;5;241m.\u001b[39msize(\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m~/crosscoders/crosscoder-model-diff-replication/venv/lib/python3.10/site-packages/transformer_lens/components/abstract_attention.py:396\u001b[0m, in \u001b[0;36mAbstractAttention.calculate_qkv_matrices\u001b[0;34m(self, query_input, key_input, value_input)\u001b[0m\n\u001b[1;32m    380\u001b[0m     v \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhook_v(\n\u001b[1;32m    381\u001b[0m         \u001b[38;5;66;03m# call bitsandbytes method to dequantize and multiply\u001b[39;00m\n\u001b[1;32m    382\u001b[0m         bnb\u001b[38;5;241m.\u001b[39mmatmul_4bit(\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    393\u001b[0m         \u001b[38;5;241m+\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mb_V\n\u001b[1;32m    394\u001b[0m     )\n\u001b[1;32m    395\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m--> 396\u001b[0m     v \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhook_v(\u001b[43mattn_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mvalue_input\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mW_V\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mb_V\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[1;32m    398\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m q, k, v\n",
      "File \u001b[0;32m~/crosscoders/crosscoder-model-diff-replication/venv/lib/python3.10/site-packages/transformer_lens/utilities/attention.py:17\u001b[0m, in \u001b[0;36msimple_attn_linear\u001b[0;34m(input, w, b)\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21msimple_attn_linear\u001b[39m(\n\u001b[1;32m     12\u001b[0m     \u001b[38;5;28minput\u001b[39m: Float[torch\u001b[38;5;241m.\u001b[39mTensor, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch pos d_model\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     13\u001b[0m     w: Float[torch\u001b[38;5;241m.\u001b[39mTensor, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhead_index d_model d_head\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     14\u001b[0m     b: Float[torch\u001b[38;5;241m.\u001b[39mTensor, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhead_index d_head\u001b[39m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     15\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Float[torch\u001b[38;5;241m.\u001b[39mTensor, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mbatch pos head_index d_head\u001b[39m\u001b[38;5;124m\"\u001b[39m]:\n\u001b[1;32m     16\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Linear layer for attention calculation.\"\"\"\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m     w \u001b[38;5;241m=\u001b[39m \u001b[43meinops\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mrearrange\u001b[49m\u001b[43m(\u001b[49m\u001b[43mw\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhead_index d_model d_head -> (head_index d_head) d_model\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m     18\u001b[0m     b_ \u001b[38;5;241m=\u001b[39m einops\u001b[38;5;241m.\u001b[39mrearrange(b, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhead_index d_head -> (head_index d_head)\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m     19\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m F\u001b[38;5;241m.\u001b[39mlinear(\u001b[38;5;28minput\u001b[39m, w, b_)\u001b[38;5;241m.\u001b[39mreshape(\u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], \u001b[38;5;28minput\u001b[39m\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m], b\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m0\u001b[39m], b\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m])\n",
      "File \u001b[0;32m~/crosscoders/crosscoder-model-diff-replication/venv/lib/python3.10/site-packages/einops/einops.py:591\u001b[0m, in \u001b[0;36mrearrange\u001b[0;34m(tensor, pattern, **axes_lengths)\u001b[0m\n\u001b[1;32m    536\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mrearrange\u001b[39m(tensor: Union[Tensor, List[Tensor]], pattern: \u001b[38;5;28mstr\u001b[39m, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39maxes_lengths) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[1;32m    537\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m    538\u001b[0m \u001b[38;5;124;03m    einops.rearrange is a reader-friendly smart element reordering for multidimensional tensors.\u001b[39;00m\n\u001b[1;32m    539\u001b[0m \u001b[38;5;124;03m    This operation includes functionality of transpose (axes permutation), reshape (view), squeeze, unsqueeze,\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    589\u001b[0m \n\u001b[1;32m    590\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m--> 591\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mreduce\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpattern\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mrearrange\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43maxes_lengths\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/crosscoders/crosscoder-model-diff-replication/venv/lib/python3.10/site-packages/einops/einops.py:523\u001b[0m, in \u001b[0;36mreduce\u001b[0;34m(tensor, pattern, reduction, **axes_lengths)\u001b[0m\n\u001b[1;32m    521\u001b[0m     shape \u001b[38;5;241m=\u001b[39m backend\u001b[38;5;241m.\u001b[39mshape(tensor)\n\u001b[1;32m    522\u001b[0m     recipe \u001b[38;5;241m=\u001b[39m _prepare_transformation_recipe(pattern, reduction, axes_names\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mtuple\u001b[39m(axes_lengths), ndim\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mlen\u001b[39m(shape))\n\u001b[0;32m--> 523\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_apply_recipe\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    524\u001b[0m \u001b[43m        \u001b[49m\u001b[43mbackend\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrecipe\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcast\u001b[49m\u001b[43m(\u001b[49m\u001b[43mTensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mreduction_type\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mreduction\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maxes_lengths\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mhashable_axes_lengths\u001b[49m\n\u001b[1;32m    525\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    526\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m EinopsError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m    527\u001b[0m     message \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m Error while processing \u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m-reduction pattern \u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;241m.\u001b[39mformat(reduction, pattern)\n",
      "File \u001b[0;32m~/crosscoders/crosscoder-model-diff-replication/venv/lib/python3.10/site-packages/einops/einops.py:250\u001b[0m, in \u001b[0;36m_apply_recipe\u001b[0;34m(backend, recipe, tensor, reduction_type, axes_lengths)\u001b[0m\n\u001b[1;32m    248\u001b[0m     tensor \u001b[38;5;241m=\u001b[39m backend\u001b[38;5;241m.\u001b[39madd_axes(tensor, n_axes\u001b[38;5;241m=\u001b[39mn_axes_w_added, pos2len\u001b[38;5;241m=\u001b[39madded_axes)\n\u001b[1;32m    249\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m final_shapes \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m--> 250\u001b[0m     tensor \u001b[38;5;241m=\u001b[39m \u001b[43mbackend\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfinal_shapes\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    251\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m tensor\n",
      "File \u001b[0;32m~/crosscoders/crosscoder-model-diff-replication/venv/lib/python3.10/site-packages/einops/_backends.py:92\u001b[0m, in \u001b[0;36mAbstractBackend.reshape\u001b[0;34m(self, x, shape)\u001b[0m\n\u001b[1;32m     91\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mreshape\u001b[39m(\u001b[38;5;28mself\u001b[39m, x, shape):\n\u001b[0;32m---> 92\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mx\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mreshape\u001b[49m\u001b[43m(\u001b[49m\u001b[43mshape\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "mask = relative_norms > 0.99\n",
    "indices_0 = mask.nonzero().squeeze()\n",
    "for latent_idx in indices_0:\n",
    "    analyse_max_act_tok_batched(latent_idx, batch_size = 256)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "26d93ba6-6446-40ea-90e1-1477ffe1dab2",
   "metadata": {},
   "outputs": [],
   "source": [
    "del all_encoded\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "68127788-36c1-4650-bf17-85b820afd114",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "00%|████████████████████████████████████████████████████████████████████████| 40/40 [03:46<00:00,  5.66s/it]"
     ]
    },
    {
     "ename": "OutOfMemoryError",
     "evalue": "CUDA out of memory. Tried to allocate 10.00 GiB. GPU 0 has a total capacity of 39.38 GiB of which 6.92 GiB is free. Including non-PyTorch memory, this process has 32.45 GiB memory in use. Of the allocated memory 28.40 GiB is allocated by PyTorch, and 3.56 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mOutOfMemoryError\u001b[0m                          Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[17], line 27\u001b[0m\n\u001b[1;32m     24\u001b[0m             all_encoded\u001b[38;5;241m.\u001b[39mappend(encoded)\n\u001b[1;32m     26\u001b[0m \u001b[38;5;66;03m# Concatenate all batches\u001b[39;00m\n\u001b[0;32m---> 27\u001b[0m all_encoded \u001b[38;5;241m=\u001b[39m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcat\u001b[49m\u001b[43m(\u001b[49m\u001b[43mall_encoded\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdim\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m0\u001b[39;49m\u001b[43m)\u001b[49m  \u001b[38;5;66;03m# [(total_batch*seq_len), d_hidden]\u001b[39;00m\n\u001b[1;32m     29\u001b[0m \u001b[38;5;66;03m# Now measure sparsity metrics\u001b[39;00m\n\u001b[1;32m     30\u001b[0m threshold \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1e-5\u001b[39m\n",
      "\u001b[0;31mOutOfMemoryError\u001b[0m: CUDA out of memory. Tried to allocate 10.00 GiB. GPU 0 has a total capacity of 39.38 GiB of which 6.92 GiB is free. Including non-PyTorch memory, this process has 32.45 GiB memory in use. Of the allocated memory 28.40 GiB is allocated by PyTorch, and 3.56 GiB is reserved by PyTorch but unallocated. If reserved but unallocated memory is large try setting PYTORCH_CUDA_ALLOC_CONF=expandable_segments:True to avoid fragmentation.  See documentation for Memory Management  (https://pytorch.org/docs/stable/notes/cuda.html#environment-variables)"
     ]
    }
   ],
   "source": [
    "batch_size = 256\n",
    "all_encoded = []  # Store all encoded activations\n",
    "\n",
    "for i in tqdm(range(0, len(test_tokens), batch_size)):\n",
    "        batch_tokens = test_tokens[i:i+batch_size].to(device)\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            # Your existing code for running models and getting activations\n",
    "            _, cache_A = pythia1.run_with_cache(batch_tokens, names_filter=\"blocks.18.hook_resid_pre\")\n",
    "            _, cache_B = pythia2.run_with_cache(batch_tokens, names_filter=\"blocks.18.hook_resid_pre\")\n",
    "            \n",
    "            acts = torch.stack([\n",
    "                cache_A[\"blocks.18.hook_resid_pre\"],   \n",
    "                cache_B[\"blocks.18.hook_resid_pre\"]\n",
    "            ], dim=0)\n",
    "            \n",
    "            acts = einops.rearrange(acts, \n",
    "                \"n_models batch seq_len d_model -> (batch seq_len) n_models d_model\")\n",
    "            \n",
    "            # Get encoded activations\n",
    "            encoded = cross_coder.encode(acts)\n",
    "            \n",
    "            # Store batch encodings\n",
    "            all_encoded.append(encoded)\n",
    "\n",
    "# Concatenate all batches\n",
    "all_encoded = torch.cat(all_encoded, dim=0)  # [(total_batch*seq_len), d_hidden]\n",
    "\n",
    "# Now measure sparsity metrics\n",
    "threshold = 1e-5\n",
    "l0_sparsity = (all_encoded.abs() > threshold).float().mean() * 100\n",
    "l1_norm = all_encoded.abs().mean()\n",
    "dead_features = (~(all_encoded.abs() > threshold).any(dim=0)).sum()\n",
    "\n",
    "print(f\"L0 Sparsity: {l0_sparsity:.2f}% features active\")\n",
    "print(f\"L1 Norm: {l1_norm:.3f}\")\n",
    "print(f\"Dead features: {dead_features}\")\n",
    "\n",
    "# Plot distribution\n",
    "fig = plot_activation_histogram(all_encoded)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1d58744b-27e2-49de-b4a2-4c1146f36672",
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_activation_histogram_split(latents):\n",
    "    flat_acts = latents.flatten().cpu().numpy()\n",
    "    \n",
    "    fig = go.Figure()\n",
    "    \n",
    "    # Positive activations\n",
    "    fig.add_trace(go.Histogram(\n",
    "        x=flat_acts[flat_acts >= 0],\n",
    "        name='Positive',\n",
    "        nbinsx=50,\n",
    "        marker_color='blue'\n",
    "    ))\n",
    "    \n",
    "    # Negative activations\n",
    "    fig.add_trace(go.Histogram(\n",
    "        x=flat_acts[flat_acts < 0],\n",
    "        name='Negative',\n",
    "        nbinsx=50,\n",
    "        marker_color='red'\n",
    "    ))\n",
    "    \n",
    "    fig.update_layout(\n",
    "        barmode='overlay',\n",
    "        title='Latent Activation Distribution',\n",
    "        xaxis_title='Activation Value',\n",
    "        yaxis_title='Count'\n",
    "    )\n",
    "    \n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7515cf0-ae4f-407d-b9b1-96a367b0d896",
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plot_activation_histogram_split(all_encoded)\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac24309b-aa92-4a09-9468-3af057a1b1be",
   "metadata": {},
   "source": [
    "## now what about those latents unique to Pythia 1.3b checkpoint 30?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab1646a1-a6e7-47b2-ad4e-d2715ecd994d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mask = relative_norms < 0.1\n",
    "indices_0 = mask.nonzero().squeeze()\n",
    "for latent_idx in indices_0:\n",
    "    analyse_max_act_tok_batched(latent_idx, batch_size = 256)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "742b3631-ce9e-4f01-adc2-53f105601f0f",
   "metadata": {},
   "source": [
    "There may be an issue with the crosscoder in terms of its sparsity. Maybe this should be logged during the training runs?\n",
    "Multiple features activating highly on vý token- so feature splitting? or just dense latents."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "290e81e9-49a1-4391-bf41-42a6825dfef3",
   "metadata": {},
   "source": [
    "## Analyzing shared latents\n",
    "Curious to see how these will be."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0aac8abd-fc83-417d-a77f-c42002164b33",
   "metadata": {},
   "outputs": [],
   "source": [
    "mask = (relative_norms > 0.49) & (relative_norms < 0.51)\n",
    "indices_0 = mask.nonzero().squeeze()\n",
    "print(\"Shared latents: \", indices_0, \" of shape \", indices_0.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8406fe4a-dd3a-4375-96a0-784f3e24b44f",
   "metadata": {},
   "source": [
    "Let's only take the first 10 for now. There seem to be way too many latents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "09f44306-4a8d-44d8-8294-5b604f09cc00",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "median_latents = indices_0[:10]\n",
    "for latent in median_latents:\n",
    "    analyse_max_act_tok_batched(latent, batch_size = 256)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5eb4751f-b27e-48ee-88ed-fa61af011c66",
   "metadata": {},
   "source": [
    "Now we can take a peak at the next 40?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "08e66964-e489-408f-a59c-2ebc91d6e8ce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--------------------------------------------------\n",
      "LatentIDX: 21\n",
      "torch.Size([2, 500, 64, 2048])\n",
      "Sequence indices:  tensor([60,  3, 55, 35, 55, 18,  2,  3,  1,  0], device='cuda:0')\n",
      "Batch indices:  tensor([166, 267, 231, 477, 281, 166,   0,   0,   0,   0], device='cuda:0')\n",
      "Top batch tokens shape  torch.Size([10, 64])\n",
      "The top 10 tokens are: \n",
      " 0 0[ 0 _0.mankab\n",
      "They were found in the following batches of text [']$ is the single mode squeezing operator with real squeezing parameter $r$ and optical vacuum $|0 \\\\rangle$. In particular we focus on three cases, the Glauber-coherent state ($r=0$), the amplitude squeezed state ($r>0$) and the phase squeezed state ($r<0$), which,', '3) < 0)\\n\\nthis seems like the rational first step to the problem, since I should be replacing x with the function as no value is given for x.\\n\\nCan someone please explain how they came up with the 3/4 figure? And how that was used to solve the question (c)?', '\\r\\n\"\"\"\\r\\n\\r\\ndef reverse_sort(array):\\r\\n\\tfor i in range(len(array) - 1):\\r\\n\\t\\tfor n in range(len(array) - 1):\\r\\n\\t\\t\\ta = array[n]\\r\\n\\t\\t\\tif (a < array[i]):\\r\\n\\t\\t\\t\\ttem = array[', 'type=\"table\"}. Similarly, high proliferation index, as measured by Ki-67, was more frequent with increasing NPI value, being statistically significant between the groups (*P*\\\\< 0.01, Figure\\xa0[1](#F1){ref-type=\"fig\"} and Table\\xa0[3](#T3){ref-', ' dr[_paramDtMappings[i]];\\r\\n                }\\r\\n            }\\r\\n\\r\\n            public static SqlParameter[] GetParams()\\r\\n            {\\r\\n                var newParam = new SqlParameter[_outputParams.Length];\\r\\n\\r\\n                for (var i = 0; i < _outputParams.Length; i++)\\r\\n', ']$ is the single mode squeezing operator with real squeezing parameter $r$ and optical vacuum $|0 \\\\rangle$. In particular we focus on three cases, the Glauber-coherent state ($r=0$), the amplitude squeezed state ($r>0$) and the phase squeezed state ($r<0$), which,', 'abank.m 10028 2017-08-11 16:39:37Z dmb $\\r\\n%\\r\\n%   VOICEBOX is a MATLAB toolbox for speech processing.\\r\\n%   Home page: http://www.ee.ic.ac.uk/hp/staff/d', 'abank.m 10028 2017-08-11 16:39:37Z dmb $\\r\\n%\\r\\n%   VOICEBOX is a MATLAB toolbox for speech processing.\\r\\n%   Home page: http://www.ee.ic.ac.uk/hp/staff/d', 'abank.m 10028 2017-08-11 16:39:37Z dmb $\\r\\n%\\r\\n%   VOICEBOX is a MATLAB toolbox for speech processing.\\r\\n%   Home page: http://www.ee.ic.ac.uk/hp/staff/d', 'abank.m 10028 2017-08-11 16:39:37Z dmb $\\r\\n%\\r\\n%   VOICEBOX is a MATLAB toolbox for speech processing.\\r\\n%   Home page: http://www.ee.ic.ac.uk/hp/staff/d']\n",
      "--------------------------------------------------\n",
      "LatentIDX: 22\n",
      "torch.Size([2, 500, 64, 2048])\n",
      "Sequence indices:  tensor([49, 11, 24, 61, 38, 16, 63, 32, 27, 55], device='cuda:0')\n",
      "Batch indices:  tensor([174,   0, 421, 486, 498, 498, 476, 415, 476, 472], device='cuda:0')\n",
      "Top batch tokens shape  torch.Size([10, 64])\n",
      "The top 10 tokens are: \n",
      "  16 16 16 16 17 19 8 6 224 6\n",
      "They were found in the following batches of text [' home the NBAâ\\x80\\x99s highest individual honor. With about 50 games down, neither has disappointed. With Harden and Westbrook as the current front-runners for MVP, here are each of their cases for 2017-02-03 16:03:062/1: ESNY- A Big Man&#', 'abank.m 10028 2017-08-11 16:39:37Z dmb $\\r\\n%\\r\\n%   VOICEBOX is a MATLAB toolbox for speech processing.\\r\\n%   Home page: http://www.ee.ic.ac.uk/hp/staff/d', ' I mean, here’s a guy who lies about his age to join the military at 15 years old (making him 16 years old when this happens) then spends the next several years on the most dangerous and complicated equipment in the world in the middle of a war zone. He has a great memory too, especially about', ' five mental disorders (conduct disorder, major depressive episode, posttraumatic stress disorder, alcohol abuse, and drug abuse) based on UM-CIDI and DISC-R structured interviews from the baseline interviews of a longitudinal diagnostic study of 428 (187 males; 241 females) homeless and runaway adolescents aged 16-19', '\\nLoughnane defeated Frenchman Steve Polifonte at BAMMA 19 by a dominant decision after TKOing Florian Rousseau in the 1st round back at BAMMA 17 in December 2015.\\n\\nIt was also announced today that the Sambo specialist Duquesnoy has signed a new contract', '\\nLoughnane defeated Frenchman Steve Polifonte at BAMMA 19 by a dominant decision after TKOing Florian Rousseau in the 1st round back at BAMMA 17 in December 2015.\\n\\nIt was also announced today that the Sambo specialist Duquesnoy has signed a new contract', ' at PS Store through the weekend! Offer ends August 7 at 8 am PST.StartChar: uni0136\\nEncoding: 310 310 224\\nGlifName: uni0136\\nWidth: 681\\nVWidth: 0\\nFlags: HMW\\nLayerCount: 3\\nFore\\nRefer: 128 8', ' problem pavements, neighbour disputes, derelict property and squatters, etc. You can find out when your rubbish is collected, etc. by entering BH20 6JA into the search facility.\\n\\nSite with advice on all aspects of pregnancy - find pregnancy exercise classes and Mums groups in BH20. Information about', ' at PS Store through the weekend! Offer ends August 7 at 8 am PST.StartChar: uni0136\\nEncoding: 310 310 224\\nGlifName: uni0136\\nWidth: 681\\nVWidth: 0\\nFlags: HMW\\nLayerCount: 3\\nFore\\nRefer: 128 8', ' shallow recesses proximate to outlet openings on the outside of the mask cylinder. Thus, the surface areas of the label material can also be covered with adhesive.\\nA rotary application head that includes a rotating hollow cylinder in the fashion of a mask cylinder is known from DE 198 54 634 C1. However, the mask']\n",
      "--------------------------------------------------\n",
      "LatentIDX: 23\n",
      "torch.Size([2, 500, 64, 2048])\n",
      "Sequence indices:  tensor([14,  4, 59,  9,  5,  9, 36,  0,  0,  6], device='cuda:0')\n",
      "Batch indices:  tensor([ 29, 263, 263, 465, 248, 383, 252, 216, 280, 381], device='cuda:0')\n",
      "Top batch tokens shape  torch.Size([10, 64])\n",
      "The top 10 tokens are: \n",
      "  but but till but but but But but but but\n",
      "They were found in the following batches of text [' raindrops which\\npresently came driving down upon the storm; but they could not pacify\\nthe unruly earth, and dust and rain together formed an atmospheric mud\\nocean, churned by the wind into whirlpools and breakers. Never have I\\nridden through such a hurricane. Six', ' steady splendour; but at the tip-top,  \\nThere hangs by unseen film, an orbed drop  \\nOf light, and that is love: its influence,  \\nThrown in our eyes, genders a novel sense,  \\nAt which we start and fret; till in the end,', ' steady splendour; but at the tip-top,  \\nThere hangs by unseen film, an orbed drop  \\nOf light, and that is love: its influence,  \\nThrown in our eyes, genders a novel sense,  \\nAt which we start and fret; till in the end,', ', there is; not ad nauseum, but it’s enough to make you shell-shocked.\\n\\nThe bad guys want to use the behemoths for an evil purpose that involves weapons of destruction. All of the subterfuge, angst and cause célèbre animal rights activism is', '> Joker_-_: but there are several options\\n<abhi_nav> yah its ok galioin\\n<galion> where is the rite channel\\n<stracqua> !list\\n<ubottu> This is not a file sharing channel (or network); be sure to read the channel', \"kingdom within a kingdom' after all, but as a kingdom whose circle of influence overlapped, like a Venn diagram, with a multitude of other kingdoms wherever the waves carried it.\\n\\n### Ambitions of Empire\\n\\nBy the late twelfth century, the relationship between the Isles and the mainland had\", '! I saw it!\"\\n\\n\"Moshe!\"\\n\\n\"Judith—\" said a quieter voice behind me.\\n\\nI was too stunned to cry out. But all around me there was a steadily rising sound of horror and despair, which began as a low choking wail and mounted until it', \" but they should be careful not to 'disturb the conventional virtues of Japanese women' in this way again.\\n\\n  The imperial family at home, in _A Mirror of Japanese Nobility_ (Toyohara Chikanobu, 1887)\\n\\nHiratsuka ignored the advice and republished her\", ' but he would no longer be bothering me. It looks like you have another, nicer, rooster out there, too? I would keep that one.\\n\\nSuzanne,\\n1) Whack him with a broom\\n2) Dump a bucket of water on him\\nYou carry one\\n', ' of a shock for you, but it will all become clear soon... well, at least a portion of it will be.\" She looked directly at Elle. \"I\\'m sorry I had to take away your memories. There was no other way, you see. You were going down the wrong path. And you were turning']\n",
      "--------------------------------------------------\n",
      "LatentIDX: 25\n",
      "torch.Size([2, 500, 64, 2048])\n",
      "Sequence indices:  tensor([20, 42, 63, 42, 53, 28, 63, 13, 37, 44], device='cuda:0')\n",
      "Batch indices:  tensor([122, 122, 122, 291, 408, 279, 408, 347, 430, 433], device='cuda:0')\n",
      "Top batch tokens shape  torch.Size([10, 64])\n",
      "The top 10 tokens are: \n",
      " ('('('=\" ' (\" ' ofAM calls\n",
      "They were found in the following batches of text [\"\\n        debug = True if debug == 'y' else False\\n\\n        email = raw_input('Superuser email: ')\\n        while '@' not in email:\\n            email = raw_input('Superuser email (must be valid): ')\\n\\n        while True:\\n            password = getpass('\", \"\\n        debug = True if debug == 'y' else False\\n\\n        email = raw_input('Superuser email: ')\\n        while '@' not in email:\\n            email = raw_input('Superuser email (must be valid): ')\\n\\n        while True:\\n            password = getpass('\", \"\\n        debug = True if debug == 'y' else False\\n\\n        email = raw_input('Superuser email: ')\\n        while '@' not in email:\\n            email = raw_input('Superuser email (must be valid): ')\\n\\n        while True:\\n            password = getpass('\", 'reference internal\" href=\"../search.html\"><span class=\"std std-ref\">搜索页面</span></a></p></li>\\n</ul>\\n<img src=\"https://s05.flagcounter.com/count2/Hyjs/bg_FFFFFF/', \" findings are compatible with mildly impaired diastolic function in treated haemochromatosis, with delayed relaxation in the younger tertile, and an elevated filling pressure and pseudonormalisation with increasing age.#!/bin/bash\\nif [ -z $1 ]; then\\necho '~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~'\\necho '\", ' things like textboxes and stuff are in here too\\n\\n        GUILayout.BeginVertical();\\n            if (GUILayout.Button (\"Okay\"))//(GUI.Button(new Rect((Screen.width/4)-30, (float)(Screen.height/1.2)-30,60, 25', \" findings are compatible with mildly impaired diastolic function in treated haemochromatosis, with delayed relaxation in the younger tertile, and an elevated filling pressure and pseudonormalisation with increasing age.#!/bin/bash\\nif [ -z $1 ]; then\\necho '~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~'\\necho '\", 'References\\n\\nExternal links\\n\\nA historic photograph of the entrance of the forest by I.C. Adams\\n\\nCategory:Parks in Sonoma County, California\\nCategory:Petrified forests\\nCategory:Paleobotany\\nCategory:California Historical Landmarks\\nCategory:Eocene volcanism', ';&gt;&gt; Move to open Start / All programs/wmm-&gt; Task Pane <br> 1. Import video editing application streaming remotes **- VCAM, importing images and music <br> 2. Edit-drag and drop video files-&gt; timeline &amp; enhance', ', made an agreement with her and then breached that agreement.\\nSee 2010 WL 3442212, at *4. She further alleged that, in efforts to collect a debt,\\nCalstar lied to her in phone calls and writings directed at Texas. Id. The court of\\nappeals determined that these pleadings alleged']\n",
      "--------------------------------------------------\n",
      "LatentIDX: 26\n",
      "torch.Size([2, 500, 64, 2048])\n",
      "Sequence indices:  tensor([21, 17, 30, 41, 21, 34,  0,  4, 42, 49], device='cuda:0')\n",
      "Batch indices:  tensor([236, 333, 333, 333, 333, 333,  11, 277, 404, 333], device='cuda:0')\n",
      "Top batch tokens shape  torch.Size([10, 64])\n",
      "The top 10 tokens are: \n",
      "  contemporary contemporary contemporaryemporary modern modern centurycentury ancient fashion\n",
      "They were found in the following batches of text ['ently and strategically” worry that the way Corbyn seems to have “stormed through the crash barriers of contemporary politics” suggests that the conventional rules of politics are shifting. The center-ground of British politics, in other words, appears to be moving to the left and, moreover, a Corbyn victory threatens to drag it', ', I would consider a retro-system as anything that a reasonable person would not consider contemporary to what is modernly available. \\n\\n…not considered contemporary to what is modernly available. \\n\\nContemporary does not mean \"went out of fashion yesterday.\" I know that leaves things a bit fuzzy, but it\\'s', ', I would consider a retro-system as anything that a reasonable person would not consider contemporary to what is modernly available. \\n\\n…not considered contemporary to what is modernly available. \\n\\nContemporary does not mean \"went out of fashion yesterday.\" I know that leaves things a bit fuzzy, but it\\'s', ', I would consider a retro-system as anything that a reasonable person would not consider contemporary to what is modernly available. \\n\\n…not considered contemporary to what is modernly available. \\n\\nContemporary does not mean \"went out of fashion yesterday.\" I know that leaves things a bit fuzzy, but it\\'s', ', I would consider a retro-system as anything that a reasonable person would not consider contemporary to what is modernly available. \\n\\n…not considered contemporary to what is modernly available. \\n\\nContemporary does not mean \"went out of fashion yesterday.\" I know that leaves things a bit fuzzy, but it\\'s', ', I would consider a retro-system as anything that a reasonable person would not consider contemporary to what is modernly available. \\n\\n…not considered contemporary to what is modernly available. \\n\\nContemporary does not mean \"went out of fashion yesterday.\" I know that leaves things a bit fuzzy, but it\\'s', \" century has often been nostalgically attributed to the Ottoman Empire, in the pages of Rigas's _New Civil Government_ becomes harnessed to a modernizing programme that might have turned the cities of the eastern Mediterranean into pluralist, democratic, law-governed communities long before London, Paris or New York. Rig\", ' the next half-century the only direct public application of Copernicus\\' theories was for this very practical purpose. Yet this \"proof\" of the truth of Copernicus\\' system was not by Copernicus himself and was presented in such a way as not to seem an endorsement of any risky cosmological shift.\\n', ' l of nature, and the loss of all higher technical dexterities3 the practice of painting and sculpture which again degenerated into mechanical drudgery, still adhered however to many of the principles and forms of ancient art. The Christian reli- 2 gion appropriated at first for the decoration of churches7 tombs', ', I would consider a retro-system as anything that a reasonable person would not consider contemporary to what is modernly available. \\n\\n…not considered contemporary to what is modernly available. \\n\\nContemporary does not mean \"went out of fashion yesterday.\" I know that leaves things a bit fuzzy, but it\\'s']\n",
      "--------------------------------------------------\n",
      "LatentIDX: 27\n",
      "torch.Size([2, 500, 64, 2048])\n",
      "Sequence indices:  tensor([40, 54, 43, 31,  0, 46, 29, 20, 50, 54], device='cuda:0')\n",
      "Batch indices:  tensor([ 50,  48, 491, 317, 244, 442, 445, 317, 328, 343], device='cuda:0')\n",
      "Top batch tokens shape  torch.Size([10, 64])\n",
      "The top 10 tokens are: \n",
      " ,,,, see, you, above\n",
      "They were found in the following batches of text [' always possible to communicate. BUT, if evening rolls around and we still\\ndon’t hear from you well that quarter horse just turned into an Appaloosa of a\\nwhole other color. See, we take ‘in communicado’ as ‘uninterested’ or\\n‘otherwise occupied’ - either of which being', ' each interpretation leads to a different result. The distant relationship in question and the purpose of the exclusion at issue both serve to distinguish this case from Jackson and Vernatter. Additionally, we have considered, but do not find persuasive, the other cases cited by American Family. See, e.g., Groves v. State', 'önigsberg 70,000, Munich 65,000, while Magdeburg, Leipzig, Nuremberg and Linz each had some 60,000.\\n\\n###### Notes\\n\\n1. See, for example, the order from the 20th Motorized Infantry Div. of September 17, 1941,', 'Previous psychological studies observed that style words made up approximately 55% of all the words people speak, hear, and read \\\\[[@ref25]\\\\]. The style words include, but are not restricted to, function words and relativity words. In the MDD group, the style words (as represented by function words and relativity) accounted for', ' see people come to us scared, discouraged, and filled with self-loathing. I watch them bloom like a flower as they experience the same sense of empowerment that I did when I first began.\\n\\nWhen that happens, I grip more tightly to my own sobriety and feel inspired by the strength of the', ' questions concerning defendant\\'s infraction of prison rules sought to discredit the defendant by showing that the defendant had falsely characterized himself. *658 The purpose of the prosecutor\\'s examination enumerated above went to the defendant\\'s credibility.\"\\nWe feel, however, that a man\\'s reputation, especially where he is also the criminal defendant-', ' is new and doesn\\'t show on GPS.\\n\\nI\\'m thinking about, \"I\\'m going out with a new friend for dinner, see you guys later!\"\\n\\nGood instincts. I\\'d second them. All those in favor signify by saying \"Ay\"\\n\\n[This message edited by better4me', 'Previous psychological studies observed that style words made up approximately 55% of all the words people speak, hear, and read \\\\[[@ref25]\\\\]. The style words include, but are not restricted to, function words and relativity words. In the MDD group, the style words (as represented by function words and relativity) accounted for', ' . . paying off debt is never quick or easy. While the Baby Steps are simple, they do take some work. And your progress only moves at the speed of your motivation.The 49ers unveiled a 70th-anniversary patch yesterday (see above; further info here). It’s a muddled design that', \" to prior physical abuse, indicate that appellant intentionally rather than\\r\\nrecklessly caused J.G's death.  We do not believe a rational jury would disregard such\\r\\nevidence and consider it not to be probative of appellant's intent to murder the child.  See\\r\\nYanez, 187 S.W\"]\n",
      "--------------------------------------------------\n",
      "LatentIDX: 29\n",
      "torch.Size([2, 500, 64, 2048])\n",
      "Sequence indices:  tensor([58, 27, 22,  7,  9,  1, 28, 18, 13,  0], device='cuda:0')\n",
      "Batch indices:  tensor([ 40, 459, 264, 422, 366, 337, 274, 390, 374, 307], device='cuda:0')\n",
      "Top batch tokens shape  torch.Size([10, 64])\n",
      "The top 10 tokens are: \n",
      " quant quantity Qual NatCompantavanaussâtjust\n",
      "They were found in the following batches of text [' it needs it. Put your presistent settings in SharedPreferences and onResume load them back.\\nEvery Activity which is onResume state (hidden from the user) can be automaticaly destroyed and then reacreated when needed.\\n\\n\\n\\nNot so swift - rquantz\\nhttp://www', ', lines 14-16; TR 117, lines 23-25.)\\n29. The Site currently has no useful function because of the quantity of debris on it and the risk of fire. (TR 25, lines 7-10.)\\n30. Defendants left approximately 1,029,900 cubic yards of waste at the', ' public facilities.\\n                                 Kolling et al.                                                                Tanzania (2010)                                 Qualitative    Patients drew supports from their social networks within their local communities to support their medication.\\n                                 Kühlbrandt et al.                                                             Armenia, Belarus, Moldova,', ' the May budget.\\n\\nDi Natale will say the new Greens policy will include a plan to get rid of stamp duty. “Stamp duty raises the price of housing and stops people from moving between homes even when they want to so it’s about time we levelled the playing field and got rid of it', ' EOE.\\nTire Service Tech-Competi-\\ntive Pay & Benefits! Must\\nhave 2 yrs exp-heavy duty\\ntire maintenance. Apply:\\n1050 SE 6th St. Lake\\nButler, FL.\\nOWN A COMPUTER? Put\\n\\nIt to work', 'kiant suklaidinti mūsų vartotojus, kad šie produktai saugūs ir atitinka ES standartus. Šiandien mūsų diskusijos svarbiausia tema ir mūsų vart', '. \"Piven, if he still lives, is an incapacitated youth. You believe he could be my enemy?\"\\n\\nRavan nodded. \"He is. He plans to kill you.\"\\n\\n\"And Leo,\" Roddy added, panting as though exhausted or dying, Loethar couldn\\'t', \"istic Literature\\n\\n_Edited by Martine Cuypers and James J. Clauss_\\n\\nA Companion to Vergil's _Aeneid_ and its Tradition\\n\\n_Edited by Joseph Farrell and Michael C. J. Putnam_\\n\\nA Companion to Horace\", \" construire des édifices stables : quand on bâtit le Temple de Jérusalem, « les pierres furent amenées toutes telles qu'elles devaient être, de sorte que, en bâtissant la maison, on n'entendît ni marteau\", 'just cause\" to terminate Green. The crux of City\\'s contention was that Green\\'s failure to include the words \"just cause\" in his grievance, was a fatal flaw. Accordingly, City argued, arbitrator\\'s decision in this regard could not be considered a \"specific issue or action being appealed.\" Thus, arbitrator\\'s']\n",
      "--------------------------------------------------\n",
      "LatentIDX: 30\n",
      "torch.Size([2, 500, 64, 2048])\n",
      "Sequence indices:  tensor([38, 21, 40, 53, 24, 59, 46, 54, 23, 29], device='cuda:0')\n",
      "Batch indices:  tensor([ 96, 302, 302, 402,  96, 446, 319, 466, 446, 466], device='cuda:0')\n",
      "Top batch tokens shape  torch.Size([10, 64])\n",
      "The top 10 tokens are: \n",
      " .... (.....\n",
      "They were found in the following batches of text [' 11*sqrt(5)\\nSimplify sqrt(425) + (2*sqrt(425)*-2)**2 + (sqrt(425)*2 + 2 - sqrt(425))**2.\\n25*sqrt(17) + 7229\\nSimplify ((sqrt(104)*2 - sqrt(104))*-3)/((', ' 308 = l. Is p prime?\\nFalse\\nLet j(w) = -w - 4. Let o be j(-6). Let h be -21*(-3 + o)/1. Is h*1/(9/6) prime?\\nFalse\\nIs (-16 - (-19)/1)*(-', ' 308 = l. Is p prime?\\nFalse\\nLet j(w) = -w - 4. Let o be j(-6). Let h be -21*(-3 + o)/1. Is h*1/(9/6) prime?\\nFalse\\nIs (-16 - (-19)/1)*(-', ' y_i\\\\equiv 0$; and $$2z=\\\\gamma\\\\alpha t - \\\\sum_{i:A_i>0} A_i^2\\\\sin\\\\left(\\\\gamma a_i^2t/\\\\alpha\\\\right).$$\\n\\n2.  If $\\\\gamma=0$, then for each', ' 11*sqrt(5)\\nSimplify sqrt(425) + (2*sqrt(425)*-2)**2 + (sqrt(425)*2 + 2 - sqrt(425))**2.\\n25*sqrt(17) + 7229\\nSimplify ((sqrt(104)*2 - sqrt(104))*-3)/((', '957\\nSort 0, 15, -5, -16, -1, 1, -52 in descending order.\\n15, 1, 0, -1, -5, -16, -52\\nSort 4, 2, -3, 1088, -142 in ascending order.\\n-142,', 'ij} = \\\\\\\\chi c_i q_{ij}.\\n$$\\n](A978-3-319-03026-5_8_Chapter_TeX2GIF_Equ62.gif)\\n\\n(8.69)\\n\\nActually, system (8.68) can be conveniently rescaled', ' w rounded to the nearest integer?\\n-3\\nLet c = 620.012 - -12.688. Round c to the nearest 10.\\n630\\nLet j = -0.687953794 + 0.688. Round j to 6 decimal places.\\n0.000046\\nLet w =', '957\\nSort 0, 15, -5, -16, -1, 1, -52 in descending order.\\n15, 1, 0, -1, -5, -16, -52\\nSort 4, 2, -3, 1088, -142 in ascending order.\\n-142,', ' w rounded to the nearest integer?\\n-3\\nLet c = 620.012 - -12.688. Round c to the nearest 10.\\n630\\nLet j = -0.687953794 + 0.688. Round j to 6 decimal places.\\n0.000046\\nLet w =']\n",
      "--------------------------------------------------\n",
      "LatentIDX: 32\n",
      "torch.Size([2, 500, 64, 2048])\n",
      "Sequence indices:  tensor([61, 53, 41, 41, 40, 49, 52, 58, 47, 19], device='cuda:0')\n",
      "Batch indices:  tensor([ 86,  34, 165, 186,  17, 164, 262,   7,  28,  28], device='cuda:0')\n",
      "Top batch tokens shape  torch.Size([10, 64])\n",
      "The top 10 tokens are: \n",
      " ..........\n",
      "They were found in the following batches of text [\"il (MMF) en route to the operating room for the facial transplant procedure. The shaded area indicates the initiation of maintenance immunosuppression.](CRIT2018-7691072.001){#fig1}\\n\\n![Patient\\\\'s maintenance tacrolimus trough levels recorded in the posttransplant period. Shaded\", '   87    0.321\\n\\n**^a^** Results for immediate posttest survey reflect those from matched pre-test post-test surveys; **^b^** Results for follow-up survey reflect those from matched pre-test post-test follow-up surveys.\\n\\nijerph-13-00948-t', '-02177]\\\\] and Discrete Event System Specification (DEVS) \\\\[[@B58-sensors-17-02177]\\\\].\\n\\nHLA standard is mainly focused on continuous time (CT) simulations. This standard defines an interface, an object model and a set of rules in order to allow simulation tools to communicate', 'type=\"fig\"} *a*). Data acquisitions performed by the same user (*i.e.* with the same experimental logging) are divided into sessions according to the date when experiments were (or are) performed. There are currently two main types of experiments carried out at synchrotron-based BioSAXS facilities: data acquisition', ' determinant for this TE superfamily. [Table\\xa01](#evx261-T1){ref-type=\"table\"} presents the assignment of protein domains to DNA TE superfamilies in Fungi. Table 1Summary of DNA TE Superfamilies in RepBase, [@evx261-B74], and Transpos', \"' original file for figure 4Authors' original file for figure 5\\n\\n**Competing interests**\\n\\nDR, GD, FS and LB are paid employees of the GlaxoSmithKline group of companies, the funder of this study. GD, FS and LB own stocks or shares in GlaxoSmith\", '\\n\\nEthics approval and consent to participate {#FPar10}\\n==========================================\\n\\nThe University of Florida Institutional Review Board provided the approval for this study (IRB201501210). All subjects provided verbal informed consent after reviewing the IRB-approved consent form. The study was performed under a waiver of documentation of informed', 'endronate led to nodular scleritis and rechallenge caused recurrence of scleritis.Microgram (mcg) peptide measurements are used to find dosage in each unit and tick mark on an insulin syringe.\\n\\nHow to Measure Peptides for Research\\n\\nml = milliliter. This is a VOL', '------------\\n\\nThis three generation family included 5 affected individuals with congenital nuclear cataract and 2 unaffected individuals. The proband (II:1), a 44-year-old male, was diagnosed with bilateral cataract at his first decade of life. Later on, his female sib also complained of blurred vision in her early teens.', '------------\\n\\nThis three generation family included 5 affected individuals with congenital nuclear cataract and 2 unaffected individuals. The proband (II:1), a 44-year-old male, was diagnosed with bilateral cataract at his first decade of life. Later on, his female sib also complained of blurred vision in her early teens.']\n",
      "--------------------------------------------------\n",
      "LatentIDX: 34\n",
      "torch.Size([2, 500, 64, 2048])\n",
      "Sequence indices:  tensor([56, 33, 40, 23, 27, 40, 47, 55, 37, 22], device='cuda:0')\n",
      "Batch indices:  tensor([164, 434, 357, 422, 485, 344, 357, 376, 376, 326], device='cuda:0')\n",
      "Top batch tokens shape  torch.Size([10, 64])\n",
      "The top 10 tokens are: \n",
      "  stocks Holdings markets stamp stars portfolio Markets piles trades down\n",
      "They were found in the following batches of text [\"' original file for figure 4Authors' original file for figure 5\\n\\n**Competing interests**\\n\\nDR, GD, FS and LB are paid employees of the GlaxoSmithKline group of companies, the funder of this study. GD, FS and LB own stocks or shares in GlaxoSmith\", ' line for Royal Robbins worldwide, and for the profitability of Royal Robbins. Millenacker will also serve on the Board of Directors of BRS Outdoor Holdings, LLC, the controlling entity of Royal Robbins and Evolv Sports & Designs, LLC.\\n\\nADVERTISEMENT\\n\\nThanks for watching!', ' Markets Magazine Micro MediaKit\\n\\nBloomberg Markets Magazine\\n\\nBloomberg Markets is the only magazine for the global financial elite, with in-depth stories on the companies and people who move markets.\\n\\nBloomberg Markets magazine has won more than 200 journalism and design awards, including the Gerald Loeb', ' the May budget.\\n\\nDi Natale will say the new Greens policy will include a plan to get rid of stamp duty. “Stamp duty raises the price of housing and stops people from moving between homes even when they want to so it’s about time we levelled the playing field and got rid of it', ' i said i just cant see a reason why Brazil will not win this , they have amazing quality in every position and i see there young stars showing off here , the fact that pretty much there whole team plays consistently for top clubs is also another huge factor , the players will be match fit and also not overwhelmed by the experience', ' Citi Private Bank. Frank oversees hedge fund research and manager selection for the Citi Private Bank platform, and his business is focused on direct investment in single-manager hedge funds and custom hedge fund portfolio construction and management. The Citi Private Bank hedge fund platform business manages roughly $4bn globally in single hedge fund', ' Markets Magazine Micro MediaKit\\n\\nBloomberg Markets Magazine\\n\\nBloomberg Markets is the only magazine for the global financial elite, with in-depth stories on the companies and people who move markets.\\n\\nBloomberg Markets magazine has won more than 200 journalism and design awards, including the Gerald Loeb', ' or selling, as the case may be, among insiders in the fast money trading complex. These wavelets periodically attract reinforcements, thereby imparting momentum and more replication of the original trades.\\n\\nAt length, full-powered momentum trades become energized, and money piles on from the four corners of the hedge', ' or selling, as the case may be, among insiders in the fast money trading complex. These wavelets periodically attract reinforcements, thereby imparting momentum and more replication of the original trades.\\n\\nAt length, full-powered momentum trades become energized, and money piles on from the four corners of the hedge', \" and dedicated staff capable\\nof providing immediate answers to enquiries and technical questions.\\ufeffEve Irvine sits down with Margrethe Vestager, the woman who has angered the US and Ireland by punishing Apple.\\n\\nAdvertising\\n\\nBy slapping a record bill on the world's most profitable\"]\n",
      "--------------------------------------------------\n",
      "LatentIDX: 37\n",
      "torch.Size([2, 500, 64, 2048])\n",
      "Sequence indices:  tensor([53, 33, 54, 18, 53, 28, 53, 53, 57, 38], device='cuda:0')\n",
      "Batch indices:  tensor([ 55,  55, 384, 312, 364, 443, 323, 418, 472, 463], device='cuda:0')\n",
      "Top batch tokens shape  torch.Size([10, 64])\n",
      "The top 10 tokens are: \n",
      " TTTApAgenericTE CT\n",
      "They were found in the following batches of text ['\"ns3.google.com\",\\n    \"ns4.google.com\"\\n  ],\\n  \"creationDate\": \"1999-06-08T00:00:00\",\\n  \"expirationDate\": \"2020-07-08T00:00:00\",\\n  \"owner', '\"ns3.google.com\",\\n    \"ns4.google.com\"\\n  ],\\n  \"creationDate\": \"1999-06-08T00:00:00\",\\n  \"expirationDate\": \"2020-07-08T00:00:00\",\\n  \"owner', ' The process will differ company to\\ncompany, and should derive by working backwards from the goal you want to\\nachieve: \"We want to solve the right problems for our customers\".\\n\\nWhat that ends up looking like, what you ship, what you DON\\'T ship, and how\\nyou do/don', 'Ind. Ct. App. 1993).\\n\\n       Court of Appeals of Indiana | Opinion 49A02-1405-CR-307 | February 20, 2015                       Page 11 of 13\\n\\x0c       App. p. 60 (“Defense Counsel argued that the time needed to obtain this\\n\\n       information via a prescriptions[-]', ' provision of reliable, safe, and affordable power above the interests of its shareholders.”Square Enix have sent out a press release regarding Kingdom Hearts III, the recently announced Kingdom Hearts title for PlayStation 4 and Xbox One. This press release links to the 1080p upload of the announcement trailer, provides a clean copy', 'cean ridges (Fig. F11).\\n\\nAn alternative hypothesis is that the relatively primitive gabbronorites from Hole 1268A crystallized at depths corresponding to pressures of 0.4 to 1 GPa, where orthopyroxene forms relatively early during crystallization of primitive MORB. This idea is', ' ubuntu depois de uma atualizaÃ§Ã£o nÃ£o tava funcionando direito. dai apaguei a imagem 3.19.0-31-generic e retornei para 3.19.0-30-generic e atÃ© agora estÃ¡ t', ' solar abundances [@Wilms2000] and the [vern]{} photoionization cross-section [@Verner96].\\n\\n### [[*RXTE*]{}]{}\\xa0and [[*Chandra*]{}]{}\\xa0Spectroscopy\\n\\nTo isolate the purely pulsed emission for the [[*RXTE*]{}]{}\\xa0data, we used the scaled off', ' shallow recesses proximate to outlet openings on the outside of the mask cylinder. Thus, the surface areas of the label material can also be covered with adhesive.\\nA rotary application head that includes a rotating hollow cylinder in the fashion of a mask cylinder is known from DE 198 54 634 C1. However, the mask', '38.1 ± 0.8          0.9936   0.011        −7.10                −7.57    −8.13\\n\\n  SiO~2~-TETA      9.42 ± 0.36    49.8 ± 1.1     0.9972              0']\n",
      "--------------------------------------------------\n",
      "LatentIDX: 39\n",
      "torch.Size([2, 500, 64, 2048])\n",
      "Sequence indices:  tensor([17,  4,  4, 48,  2,  0,  3, 30, 55, 39], device='cuda:0')\n",
      "Batch indices:  tensor([114, 387, 390, 424, 313,  55, 355, 268, 281, 387], device='cuda:0')\n",
      "Top batch tokens shape  torch.Size([10, 64])\n",
      "The top 10 tokens are: \n",
      "  _ __\n",
      " _\" \" _ _ Then\n",
      "They were found in the following batches of text [' all assholes are straight, not all straight guys are assholes.\"\\n\\n\" _Hell_ yeah. _I\\'m_ cool, for one. Not so much my dad.\"\\n\\n\"You\\'re not giving him much slack.\"\\n\\n\"He reeled it all in,\" Marvin says, \"when he', ' female voice said \" _Christinka, we have a message for you from your grandmother–she wants you to know that she loves you very much and just wants you to be happy._ \" Then I felt my entire body being \"x-rayed,\" \"scanned,\" \"flooded\" with radiant white', \"istic Literature\\n\\n_Edited by Martine Cuypers and James J. Clauss_\\n\\nA Companion to Vergil's _Aeneid_ and its Tradition\\n\\n_Edited by Joseph Farrell and Michael C. J. Putnam_\\n\\nA Companion to Horace\", ' and fans who rely on it.\\n\\n“This cooperation can and should continue as it benefits not only the parties to this lawsuit, but more importantly, it benefits independent artists and their millions of fans,” the answer reads.\\n\\n—\\n\\nSpinrilla’s full answer to the complaint is available here (', \" nodded. _Invite him onward._ It had a range of meanings, from comfortable retirement to disembowelment.\\n\\n'An old-fashioned coup,' he said. 'Are you sure of support?'\\n\\n'Oh yes.'\\n\\nAlameche nodded. 'Good,' he said. '\", '\"ns3.google.com\",\\n    \"ns4.google.com\"\\n  ],\\n  \"creationDate\": \"1999-06-08T00:00:00\",\\n  \"expirationDate\": \"2020-07-08T00:00:00\",\\n  \"owner', '\\'t eat\" \"Youngerster, don\\'t block my sight\" \"What are you doing?\" \"Trying to steal?\" \"help yourselves, help yourselves\" \"What are you doing?\" \"Go hide yourself\" \"What now?\" \"Jade\" \"He\\'II be filled with energy after I touch him', ' att »sätta näsan i vädret« när det gällde honom. Viktigast var kanske den speciella _fattigstoltheten_ som gör att många fattiga när de tvingas iaktta vissa seder och bruk', ' dr[_paramDtMappings[i]];\\r\\n                }\\r\\n            }\\r\\n\\r\\n            public static SqlParameter[] GetParams()\\r\\n            {\\r\\n                var newParam = new SqlParameter[_outputParams.Length];\\r\\n\\r\\n                for (var i = 0; i < _outputParams.Length; i++)\\r\\n', ' female voice said \" _Christinka, we have a message for you from your grandmother–she wants you to know that she loves you very much and just wants you to be happy._ \" Then I felt my entire body being \"x-rayed,\" \"scanned,\" \"flooded\" with radiant white']\n",
      "--------------------------------------------------\n",
      "LatentIDX: 40\n",
      "torch.Size([2, 500, 64, 2048])\n",
      "Sequence indices:  tensor([58, 47, 34, 63, 43, 19, 54, 47,  1, 45], device='cuda:0')\n",
      "Batch indices:  tensor([ 58, 396, 244, 460, 440, 295, 329,  80, 378, 379], device='cuda:0')\n",
      "Top batch tokens shape  torch.Size([10, 64])\n",
      "The top 10 tokens are: \n",
      "  did did did did did did Did did did did\n",
      "They were found in the following batches of text ['ivamente strutturatisi in Svezia. Rispetto al primo filone, si potrebbe menzionare che i più antichi giochi, gare e attività ludiche furono incorporate all’interno dei percorsi didattici delle scu', ' When violent suicide attempts were analysed, it was found that mothers with antibodies against T. gondii had an 81% increased risk (relative risk 1.81, 95% confidence interval 1.13 to 2.84).\\n\\nHow did the researchers interpret the results?\\n\\nThe researchers say, “women with a', ' see people come to us scared, discouraged, and filled with self-loathing. I watch them bloom like a flower as they experience the same sense of empowerment that I did when I first began.\\n\\nWhen that happens, I grip more tightly to my own sobriety and feel inspired by the strength of the', \"t')\\\\rangle_{\\\\beta} = \\\\langle E_x(\\\\x,t)E_x(\\\\x,t')\\\\rangle_{\\\\beta}$. Using the above results, the finite temperature dispersions $\\\\langle(\\\\Delta v_j)^2\\\\rangle_{{}_\\\\beta}$ can be obtained in the same way as we did\", 'inel, which is about a dead policeman, an Egyptian god of vengeance, and a secret cult of magicians who worship the New York subway system. You can see some photos from the panel here. Afterwards, I did an interview for I Want To Be A Book, which contains one or two snippets of info about', 'No, I don\\'t.\" \"Lucky girl.\" \"Yeah, she is.\" \"When did you start having bleeding in your gums?\" \"Last night, when I was brushing my teeth.\" \"It\\'s just a little bit of spotting.\" \"I haven\\'t been to the dentist in a while.\" \"', ', so foreign. I saw a haze in the distance, a bright mist, and then my nose turned downward. My right wing had lost its way, my mind heard a voice, George, \"I\\'m losing him, Dick. What the hell is happening? Did a terrorist shoot him? Damn, damn', ' to Europeans.\\nHe noted that fundamentalist Christians embrace theories of Armageddon and even\\nknow where it will take place:\"thirty-five miles southwest of Haifa,\" as their\\nmost popular books predict. Europeans, he did not need to add, find this sort\\nof thing bizarre. About Kagan', ' how did Mary of Magdala become a prostitute some several hundred years after her death?\\n\\nThe short answer is that Mary Magdalene has been confused with several other women in the Bible, most significantly-- and ultimately problematically-with the unnamed sinner in Chapter 7 of Luke. In that story, a', ' the other\\n\\ndefendants and sought to minimize charges. Neuman was unaware of both\\n\\nLyons’s and Larkin’s proffer discussions with the government. Certainly, Neuman\\n\\nand his counsel did not approve Larkin’s disclosure of the Confidential Memo to\\n\\nthe']\n",
      "--------------------------------------------------\n",
      "LatentIDX: 41\n",
      "torch.Size([2, 500, 64, 2048])\n",
      "Sequence indices:  tensor([19, 14, 16, 19, 23, 21, 36, 12, 60, 55], device='cuda:0')\n",
      "Batch indices:  tensor([164, 118, 499, 152, 173, 292, 401, 309,  65, 311], device='cuda:0')\n",
      "Top batch tokens shape  torch.Size([10, 64])\n",
      "The top 10 tokens are: \n",
      " \n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "\n",
      "They were found in the following batches of text [\"' original file for figure 4Authors' original file for figure 5\\n\\n**Competing interests**\\n\\nDR, GD, FS and LB are paid employees of the GlaxoSmithKline group of companies, the funder of this study. GD, FS and LB own stocks or shares in GlaxoSmith\", 'akbulletin 153_ ).\\n\\n**13.e5**\\n\\nA slightly premature push. It will turn out later that the e-pawn does not radiate any power. On the contrary – it will become a source of worry for White. Correct was the preventive move 13.♔b1', ' came out, Mark was grinning like the Cheshire Cat.\\n\\n***\\n\\nPlanning\\n\\nPhysically, Mark was a fine advert for a speed-only diet. Tall, lean and muscular, he remained in perfect health. The amphetamines made his veins and muscles bulge like a boxer pumped', 'stiltskin Dees began spinning their tragedy into gold:\\n\\nJuly 26, 2011\\n\\n“Dear Friend,\\n\\nThe terrorist attack that took the lives of so many children in Norway is a sobering reminder that hate and extremism can drive people to commit unspeakable acts of violence.\\n\\n', '\\n*sms* & Telephone & sms & number,message\\\\\\n\\n\\\\[table:Features\\\\]\\n\\nAs it gives a universal view of the Object, D-LITe has to offer an access to each Object functionalities. The SALT language makes the use of this D-LIT', \" the trousers should always be in the same silk used on the lapels.Pages\\n\\n28 August 2014\\n\\nFindmypast has recently published Kevin Asplin's Indian Mutiny medal roll: 56,608 officers and men who were awarded this medal and the various clasps.\\n\\nThis is at least\", \" meant to go from one silo to the next. Bobby was the one who told me how difficult that thing was to turn. It was aimed somewhere.'\\n\\n'Where?'\\n\\n'I don't know. I would need that map to tell. Unless—' She turned to Raph, whose pale face she\", '\\n26.8\\n\\n107.3 (29)\\n\\n8.8 (33)\\n\\nArkansas St\\n\\n199.5\\n\\n268.4\\n\\n33.1\\n\\n200.0\\n\\n249.8\\n\\n34.5\\n\\n18.2 (68)', \" you mean impractical?\\n\\nAMORY: Oh—drive a car, but can't change a tire.\\n\\nROSALIND: What are you going to do?\\n\\nAMORY: Can't say—run for President, write—\\n\\nROSALIND : Greenwich Village?\\n\\nAMORY\", \" my besties baby shower is the perfect occasion to put them to use!! Lots of wonderful memories of this day.\\n\\nToday I'm going to share the front of the file folder. The colors of this collection are just amazing!\\n\\nThursday, May 15, 2014\\n\\nI have to admit that this one\"]\n",
      "--------------------------------------------------\n",
      "LatentIDX: 42\n",
      "torch.Size([2, 500, 64, 2048])\n",
      "Sequence indices:  tensor([58, 45, 59, 29, 62, 18, 48, 54, 63, 51], device='cuda:0')\n",
      "Batch indices:  tensor([234, 342,  56, 262, 139, 189, 164, 262, 189, 314], device='cuda:0')\n",
      "Top batch tokens shape  torch.Size([10, 64])\n",
      "The top 10 tokens are: \n",
      "  study study study study study study study study studies research\n",
      "They were found in the following batches of text [' in utero, and growth deficiencies in infancy. No statistically significant associations were observed between maternal exposure to September 11 and birth defects, preterm birth, and growth deficiencies in utero or in infancy. Detailed results from the alternative analyses are not shown.\\n\\nDiscussion\\n==========\\n\\nIn this study, we analyzed specific health', 'B30]). Therefore, more evidence needs to be gathered to support that BmSA1 is important for the invasion of *B. microti* into host cells in an *in vivo* environment.\\n\\nIn this study, we demonstrated that BmSA1 exists in parasites in two forms and is located on', '],[@B27]^ This confirms the necessity to pay attention to the problems the caregivers face in taking care of the SCI patients in daily life. Therefore, supportive systems have to be planned in order to investigate and follow the problems of this vulnerable group of the society.\\n\\nThe findings of the present study showed that the educational', '\\n\\nEthics approval and consent to participate {#FPar10}\\n==========================================\\n\\nThe University of Florida Institutional Review Board provided the approval for this study (IRB201501210). All subjects provided verbal informed consent after reviewing the IRB-approved consent form. The study was performed under a waiver of documentation of informed', ' countries. Given the implicit interests in this study in understanding potential roles for municipalities with established and operational governance structures, we feel that the breadth of data retrieved from the abstracts that *were*reviewed remains applicable and relevant to jurisdictions that may have been under-represented in our analysis.\\n\\nAnother limitation of this study was', ' and that the proportion remained virtually unchanged after 6\\u2009months of follow-up. A further study by Cases-Amenos *et al.* \\\\[[@sfx060-B13]\\\\] in Spain found an even higher percentage with anaemia (58.5%) and significant undertreatment of iron deficiency (ID). These studies', \"' original file for figure 4Authors' original file for figure 5\\n\\n**Competing interests**\\n\\nDR, GD, FS and LB are paid employees of the GlaxoSmithKline group of companies, the funder of this study. GD, FS and LB own stocks or shares in GlaxoSmith\", '\\n\\nEthics approval and consent to participate {#FPar10}\\n==========================================\\n\\nThe University of Florida Institutional Review Board provided the approval for this study (IRB201501210). All subjects provided verbal informed consent after reviewing the IRB-approved consent form. The study was performed under a waiver of documentation of informed', ' and that the proportion remained virtually unchanged after 6\\u2009months of follow-up. A further study by Cases-Amenos *et al.* \\\\[[@sfx060-B13]\\\\] in Spain found an even higher percentage with anaemia (58.5%) and significant undertreatment of iron deficiency (ID). These studies', ' integration,security, analytics, development tools, life-cycle management, various mobile stakeholders, and the overall enterprise mobile ecosystem.\\n\\nComplex hybrid environments can make it difficult to track interdependencies, increasing the risk of disrupting critical business services. In this research paper by EMA, you’ll learn how application discovery']\n",
      "--------------------------------------------------\n",
      "LatentIDX: 44\n",
      "torch.Size([2, 500, 64, 2048])\n",
      "Sequence indices:  tensor([48, 57, 58, 49, 41, 32, 29, 55, 51, 58], device='cuda:0')\n",
      "Batch indices:  tensor([196, 196, 196, 196, 196, 371, 289, 196, 476, 476], device='cuda:0')\n",
      "Top batch tokens shape  torch.Size([10, 64])\n",
      "The top 10 tokens are: \n",
      " \n",
      "\n",
      "                \n",
      "\n",
      ";):\n",
      "\n",
      "\n",
      "They were found in the following batches of text [\").startswith('<function g'))\\n        else:\\n            self.assertTrue(repr(f).startswith('<function x'))\\n\\n    def test_argcount(self):\\n        def foo0(): pass\\n        def foo1(*args): pass\\n        def foo2(**args\", \").startswith('<function g'))\\n        else:\\n            self.assertTrue(repr(f).startswith('<function x'))\\n\\n    def test_argcount(self):\\n        def foo0(): pass\\n        def foo1(*args): pass\\n        def foo2(**args\", \").startswith('<function g'))\\n        else:\\n            self.assertTrue(repr(f).startswith('<function x'))\\n\\n    def test_argcount(self):\\n        def foo0(): pass\\n        def foo1(*args): pass\\n        def foo2(**args\", \").startswith('<function g'))\\n        else:\\n            self.assertTrue(repr(f).startswith('<function x'))\\n\\n    def test_argcount(self):\\n        def foo0(): pass\\n        def foo1(*args): pass\\n        def foo2(**args\", \").startswith('<function g'))\\n        else:\\n            self.assertTrue(repr(f).startswith('<function x'))\\n\\n    def test_argcount(self):\\n        def foo0(): pass\\n        def foo1(*args): pass\\n        def foo2(**args\", ' trs.reshape((-1, 2))\\n            if c == Path.LINETO:\\n                (t, r), = trs\\n                if t == last_t:  # Same angle: draw a straight line.\\n                    xys.extend(self.transform_non_', ';\\r\\nend;\\r\\n\\r\\nfunction TBasicRichEditOleCallback.ContextSensitiveHelp(fEnterMode: BOOL): HResult;\\r\\nbegin\\r\\n  Result := S_OK;\\r\\nend;\\r\\n\\r\\nfunction TBasicRichEditOleCallback.GetClipboardData(const chrg', \").startswith('<function g'))\\n        else:\\n            self.assertTrue(repr(f).startswith('<function x'))\\n\\n    def test_argcount(self):\\n        def foo0(): pass\\n        def foo1(*args): pass\\n        def foo2(**args\", ' at PS Store through the weekend! Offer ends August 7 at 8 am PST.StartChar: uni0136\\nEncoding: 310 310 224\\nGlifName: uni0136\\nWidth: 681\\nVWidth: 0\\nFlags: HMW\\nLayerCount: 3\\nFore\\nRefer: 128 8', ' at PS Store through the weekend! Offer ends August 7 at 8 am PST.StartChar: uni0136\\nEncoding: 310 310 224\\nGlifName: uni0136\\nWidth: 681\\nVWidth: 0\\nFlags: HMW\\nLayerCount: 3\\nFore\\nRefer: 128 8']\n",
      "--------------------------------------------------\n",
      "LatentIDX: 46\n",
      "torch.Size([2, 500, 64, 2048])\n",
      "Sequence indices:  tensor([32, 34, 58, 43, 27, 29, 48, 49, 33, 21], device='cuda:0')\n",
      "Batch indices:  tensor([179, 269, 459, 486, 386, 389, 371, 371, 472, 359], device='cuda:0')\n",
      "Top batch tokens shape  torch.Size([10, 64])\n",
      "The top 10 tokens are: \n",
      "  linearilinear cubic longitudinal polynomials loop straight line rotary sequential\n",
      "They were found in the following batches of text [' cannot be accessed by open-skull surgery.\\n\\nStereotactic radiosurgery are mostly done using the Gamma Knife machine and by using a linear accelerator machine. Gamma Knife is a static machine used mostly on tumors and blood vessels. It can deliver a very accurate radiation to the target. Stere', \"meida'\\n- 'Juliana C. Precioso'\\ntitle: 'Existence and symmetries of solutions in Besov-Morrey spaces for a semilinear heat-wave type equation'\\n---\\n\\n[Fractional partial differential equation,Riemann-Liouville derivative,Symmetries\", ', lines 14-16; TR 117, lines 23-25.)\\n29. The Site currently has no useful function because of the quantity of debris on it and the risk of fire. (TR 25, lines 7-10.)\\n30. Defendants left approximately 1,029,900 cubic yards of waste at the', ' five mental disorders (conduct disorder, major depressive episode, posttraumatic stress disorder, alcohol abuse, and drug abuse) based on UM-CIDI and DISC-R structured interviews from the baseline interviews of a longitudinal diagnostic study of 428 (187 males; 241 females) homeless and runaway adolescents aged 16-19', '|\\\\,k=1,\\\\ldots,N\\\\}= {\\\\mathbb{R}}[X]_{\\\\leq N-1},$$ the space of polynomials of degree $\\\\leq N-1$. For any $p\\\\in{\\\\mathbb{R}}[X]_{\\\\leq N-1}$ we obtain $$p(x) = \\\\', ' in place.** Install the stop boards with 2 × 2 frames for backing; fasten the frames to the form sides with screws. Tie a loop of wire through each set of tie wire holes and position a spacer near each loop. Use a stick to twist the loop strands together, pulling the form sides inward, tight', ' trs.reshape((-1, 2))\\n            if c == Path.LINETO:\\n                (t, r), = trs\\n                if t == last_t:  # Same angle: draw a straight line.\\n                    xys.extend(self.transform_non_', ' trs.reshape((-1, 2))\\n            if c == Path.LINETO:\\n                (t, r), = trs\\n                if t == last_t:  # Same angle: draw a straight line.\\n                    xys.extend(self.transform_non_', ' shallow recesses proximate to outlet openings on the outside of the mask cylinder. Thus, the surface areas of the label material can also be covered with adhesive.\\nA rotary application head that includes a rotating hollow cylinder in the fashion of a mask cylinder is known from DE 198 54 634 C1. However, the mask', '-based methods of determining secondary structure and could prove to be particularly useful in light of the recent development of sequential assignment techniques which are now almost NOE-independent [Ikura, M., Kay, L. E., & Bax, A. (1990) Biochemistry 29, 4659-4667]. We suggest']\n",
      "--------------------------------------------------\n",
      "LatentIDX: 47\n",
      "torch.Size([2, 500, 64, 2048])\n",
      "Sequence indices:  tensor([59, 19,  6, 23, 32,  6, 12,  2, 22, 61], device='cuda:0')\n",
      "Batch indices:  tensor([149, 149, 149, 439, 345, 330, 431, 266, 266, 493], device='cuda:0')\n",
      "Top batch tokens shape  torch.Size([10, 64])\n",
      "The top 10 tokens are: \n",
      " }}}}}}}}}(^}}}\n",
      "They were found in the following batches of text ['ational composition: ${\\\\cal X} \\\\circ r = r$ for any relation ${{{\\\\cal X}} \\\\stackrel{{r}}{\\\\rightharpoondown} {{\\\\cal Y}}}$. Composition preserves homset order. The opposite operator is an involution.\\n\\nFor any monotonic function ${{{\\\\cal X}} \\\\stackrel{{h', 'ational composition: ${\\\\cal X} \\\\circ r = r$ for any relation ${{{\\\\cal X}} \\\\stackrel{{r}}{\\\\rightharpoondown} {{\\\\cal Y}}}$. Composition preserves homset order. The opposite operator is an involution.\\n\\nFor any monotonic function ${{{\\\\cal X}} \\\\stackrel{{h', 'ational composition: ${\\\\cal X} \\\\circ r = r$ for any relation ${{{\\\\cal X}} \\\\stackrel{{r}}{\\\\rightharpoondown} {{\\\\cal Y}}}$. Composition preserves homset order. The opposite operator is an involution.\\n\\nFor any monotonic function ${{{\\\\cal X}} \\\\stackrel{{h', ')}_{j,{\\\\textrm{thr}}}(0)} \\\\big ] + {C_{j,{\\\\textrm{thr}}}^{(3)}(0)} \\\\big [{\\\\partial_\\\\tau C^{(1)}_{j,{\\\\textrm{thr}}}(0)} \\\\big ]\\\\\\\\\\n - \\\\big[{C_{j,{\\\\textrm{', 'right\\\\vert \\\\geq\\\\varepsilon\\\\right\\\\} \\\\right\\\\vert \\\\mathcal{F}^{T}\\\\right)\\\\overset{\\\\widetilde{\\\\mathbb{P}}}{\\\\rightarrow}0.\\\\label{eq:LindebergMt}$$\\n\\nSince the l.h.s. of (\\\\[eq:LindebergMt', \" dE\\\\, {\\\\bf G}(E,r,r'),$ calculated in two different ways, generates a resolution of the identity. This question of a representation and a contour is the subject of Section II, the main part of our argument. Additional considerations on the two ways of calculating this integral make the subject of Section\", ' ]\\\\wedge \\\\xi_E$, lies in $\\\\Lambda^2\\\\big(E^\\\\perp\\\\big)$ and hence plays no role in the calculation of the polar equations of\\xa0$E$. Hence, the polar spaces for an integral flag of\\xa0$E$ can be calculated using only $-\\\\bigl( [\\\\alpha', '{aligned}\\n\\\\epsilon_{xx} & = & \\\\epsilon_{xx}^d + F_{xx} \\\\nonumber \\\\\\\\\\n& = & \\\\frac{1}{2}( \\\\partial_x u_x+ \\\\partial_x u_x) + \\\\frac{1}{2} (\\\\partial_', '{aligned}\\n\\\\epsilon_{xx} & = & \\\\epsilon_{xx}^d + F_{xx} \\\\nonumber \\\\\\\\\\n& = & \\\\frac{1}{2}( \\\\partial_x u_x+ \\\\partial_x u_x) + \\\\frac{1}{2} (\\\\partial_', '\\n$$\\\\frac{1}{w} \\\\frac{ \\\\partial p }{ \\\\partial r } = - \\\\frac{ 1 }{ 2 } \\\\frac{\\n    \\\\partial }{ \\\\partial r } \\\\log g_{00},\\n\\\\label{eqA1}$$\\n\\nwhere $ g_{00} $ is']\n",
      "--------------------------------------------------\n",
      "LatentIDX: 50\n",
      "torch.Size([2, 500, 64, 2048])\n",
      "Sequence indices:  tensor([12,  6,  2, 62, 12, 23, 36, 32, 33, 59], device='cuda:0')\n",
      "Batch indices:  tensor([132, 374, 472, 435, 449, 399, 438, 374, 336, 374], device='cuda:0')\n",
      "Top batch tokens shape  torch.Size([10, 64])\n",
      "The top 10 tokens are: \n",
      " eseseses aboutasisCEesoutît\n",
      "They were found in the following batches of text [' wood fern) and the sexual *D. oreades* (mountain male fern; Fraser-Jenkins, [@B18]). The gametophyte of this species forms male but no female reproductive organs and, when cultured *in vitro*, reproduces by apogamy. Once the gamet', \" construire des édifices stables : quand on bâtit le Temple de Jérusalem, « les pierres furent amenées toutes telles qu'elles devaient être, de sorte que, en bâtissant la maison, on n'entendît ni marteau\", ' shallow recesses proximate to outlet openings on the outside of the mask cylinder. Thus, the surface areas of the label material can also be covered with adhesive.\\nA rotary application head that includes a rotating hollow cylinder in the fashion of a mask cylinder is known from DE 198 54 634 C1. However, the mask', ']), identificaron la prevalencia de las condiciones crónicas en las poblaciones afectadas por el conflicto armado en Siria, siendo la hipertensión arterial y los problemas músculo esqueléticos las enfermedades más frecuentes con', \" the journey to meet our child! Can't wait to read about the rest of your week 🙂 May God continue to bless this wonderful journey for you!\\n\\nThe movie you referred there is not The Hunt for the Red October [1], that one is about a Soviet Navy Officer that defects to the US taking with him\", ' page design journey\\n\\nCompany name\\n\\nOverview\\n\\nBeamto.us is an uncluttered oasis of music, news, information, discussion board and social networking for electronic music. A homegrown algorithm determines the ranking of each beam with inputs such as number of times played, downloaded, comments, vote', ' ACKS\\n#define PERFMODE_SENDANDRCV     3           // client sends to server, server sends to client\\n#define PERFMODE_RECEIVE        4           // server sends to client\\n#define PERFMODE_REQANDRCV      5           // server sends to', \" construire des édifices stables : quand on bâtit le Temple de Jérusalem, « les pierres furent amenées toutes telles qu'elles devaient être, de sorte que, en bâtissant la maison, on n'entendît ni marteau\", ', first of all the Hodgkin Huxley model of nerve fibers together with the electrical field effects are reviewed and then the methods of projective control theory and washout filters are presented. Next the approach of this research is described in detail.\\n\\nMaterials and Methods \\n======================\\n\\nHodgkin H', \" construire des édifices stables : quand on bâtit le Temple de Jérusalem, « les pierres furent amenées toutes telles qu'elles devaient être, de sorte que, en bâtissant la maison, on n'entendît ni marteau\"]\n",
      "--------------------------------------------------\n",
      "LatentIDX: 51\n",
      "torch.Size([2, 500, 64, 2048])\n",
      "Sequence indices:  tensor([43,  3, 45, 16, 37, 29, 43, 13, 24, 41], device='cuda:0')\n",
      "Batch indices:  tensor([112, 333, 261, 333, 343, 333, 435, 423, 423, 293], device='cuda:0')\n",
      "Top batch tokens shape  torch.Size([10, 64])\n",
      "The top 10 tokens are: \n",
      "  consider consider consider consider consider considered problem be be consideration\n",
      "They were found in the following batches of text [' del 2019 estos trabajadores podrán aplicar como deducción hasta el 15% de lo pagado por los servicios recibidos en restaurantes, hoteles, bares y cantinas, considerando incluso los impuestos correspondientes (IGV e Impuesto Municipal).\\n\\n', ', I would consider a retro-system as anything that a reasonable person would not consider contemporary to what is modernly available. \\n\\n…not considered contemporary to what is modernly available. \\n\\nContemporary does not mean \"went out of fashion yesterday.\" I know that leaves things a bit fuzzy, but it\\'s', ' for success, and to better prepare them to navigate the highly competitive Vancouver real estate market. The real estate industry is evolving, and I will continue adding to and updating this series as necessary.\\n\\nThere are many factors to consider when searching for a home. Part of my job as your Realtor is to help', ', I would consider a retro-system as anything that a reasonable person would not consider contemporary to what is modernly available. \\n\\n…not considered contemporary to what is modernly available. \\n\\nContemporary does not mean \"went out of fashion yesterday.\" I know that leaves things a bit fuzzy, but it\\'s', \" to prior physical abuse, indicate that appellant intentionally rather than\\r\\nrecklessly caused J.G's death.  We do not believe a rational jury would disregard such\\r\\nevidence and consider it not to be probative of appellant's intent to murder the child.  See\\r\\nYanez, 187 S.W\", ', I would consider a retro-system as anything that a reasonable person would not consider contemporary to what is modernly available. \\n\\n…not considered contemporary to what is modernly available. \\n\\nContemporary does not mean \"went out of fashion yesterday.\" I know that leaves things a bit fuzzy, but it\\'s', ']), identificaron la prevalencia de las condiciones crónicas en las poblaciones afectadas por el conflicto armado en Siria, siendo la hipertensión arterial y los problemas músculo esqueléticos las enfermedades más frecuentes con', \" shears, keys, dragons, lilies, buckshot, beards, hogs, lamps, bellows, beehives, soupladles, stars, snakes, anvils, boxes of vaseline, bells, crutches, forceps, stags' horns, watertight boots,\", \" shears, keys, dragons, lilies, buckshot, beards, hogs, lamps, bellows, beehives, soupladles, stars, snakes, anvils, boxes of vaseline, bells, crutches, forceps, stags' horns, watertight boots,\", 'ner was offered this recuperation of his theory and chose not to accept it, insisting that his own causal account was perfectly adequate.85 One reason for his insistence is probably that his theory derives from a consideration of Austro-Hungary. In his last years in Prague he liked to refer, surely correctly, to']\n",
      "--------------------------------------------------\n",
      "LatentIDX: 52\n",
      "torch.Size([2, 500, 64, 2048])\n",
      "Sequence indices:  tensor([46, 56,  8, 45, 27, 30, 49, 20, 43, 32], device='cuda:0')\n",
      "Batch indices:  tensor([247, 497, 290, 290, 290, 286, 247, 286, 289, 131], device='cuda:0')\n",
      "Top batch tokens shape  torch.Size([10, 64])\n",
      "The top 10 tokens are: \n",
      " })}))))}}$end}\n",
      "They were found in the following batches of text ['}\\n            else if (request.command == \"state_putong\")\\n            {\\n                \\n               \\n\\t\\t\\t\\n               state=1;\\n\\t\\t\\t  \\n                sendResponse({\\n                    command : \"ok\"\\n                })\\n            }\\n         else{\\n\\t\\t\\t \\t\\n            if (request.command ==', '}^{\\\\alpha}_A(X_\\\\nu)=0.\\\\end{aligned}$$ So we have for $W=\\\\beta_\\\\nu X_\\\\nu+W^{v}\\\\in\\\\Chp{\\\\JE}$ $$\\\\begin{aligned}\\n\\\\Ocan(W,\\\\mvec{X})\\n&=&\\n-\\\\derp{\\\\', ' ]\\t(\\t\"local\"\\t)\\nrst\\t[ 0\\tlocks=0 ]\\t(\\t\"srt\"\\t)\\nxyz\\t[ 0\\tlocks=0 ]\\t(\\t\"xyz\"\\t)\\ntranslate\\t[ 0\\tlocks=0 ]\\t(\\t0\\t0\\t0', ' ]\\t(\\t\"local\"\\t)\\nrst\\t[ 0\\tlocks=0 ]\\t(\\t\"srt\"\\t)\\nxyz\\t[ 0\\tlocks=0 ]\\t(\\t\"xyz\"\\t)\\ntranslate\\t[ 0\\tlocks=0 ]\\t(\\t0\\t0\\t0', ' ]\\t(\\t\"local\"\\t)\\nrst\\t[ 0\\tlocks=0 ]\\t(\\t\"srt\"\\t)\\nxyz\\t[ 0\\tlocks=0 ]\\t(\\t\"xyz\"\\t)\\ntranslate\\t[ 0\\tlocks=0 ]\\t(\\t0\\t0\\t0', 'result = $key;\\n                break;\\n            }\\n            else\\n            {\\n                $proSum -= $proCur;\\n            }\\n        }\\n\\n        unset ($proArr);\\n        return $result;\\n    }\\n}david mamet has long been my favorite screenwriter', '}\\n            else if (request.command == \"state_putong\")\\n            {\\n                \\n               \\n\\t\\t\\t\\n               state=1;\\n\\t\\t\\t  \\n                sendResponse({\\n                    command : \"ok\"\\n                })\\n            }\\n         else{\\n\\t\\t\\t \\t\\n            if (request.command ==', 'result = $key;\\n                break;\\n            }\\n            else\\n            {\\n                $proSum -= $proCur;\\n            }\\n        }\\n\\n        unset ($proArr);\\n        return $result;\\n    }\\n}david mamet has long been my favorite screenwriter', ';\\r\\nend;\\r\\n\\r\\nfunction TBasicRichEditOleCallback.ContextSensitiveHelp(fEnterMode: BOOL): HResult;\\r\\nbegin\\r\\n  Result := S_OK;\\r\\nend;\\r\\n\\r\\nfunction TBasicRichEditOleCallback.GetClipboardData(const chrg', 'else\\n                                v = consts->i32[c];\\n\\n                        fprintf(fp, \"%\"PRIi64, v);\\n                } else if (is_uint || is_hex) {\\n                        uint64_t v;\\n\\n                        if (half && mod == midgard_']\n",
      "--------------------------------------------------\n",
      "LatentIDX: 53\n",
      "torch.Size([2, 500, 64, 2048])\n",
      "Sequence indices:  tensor([11, 13, 61, 22, 53, 32, 31,  0,  0, 23], device='cuda:0')\n",
      "Batch indices:  tensor([200, 393, 413, 453, 333, 426, 200, 455, 103, 457], device='cuda:0')\n",
      "Top batch tokens shape  torch.Size([10, 64])\n",
      "The top 10 tokens are: \n",
      "  know know know know know understand may know knowZa\n",
      "They were found in the following batches of text [\"\\n        }\\n    }\\n}\\nAs people know, I'm picking up my little ruby girl in anything between three and six weeks. As people may also know, I'm profoundly deaf. How should I approach the overnight thing with the new pup? With Holly (she was 12/13 weeks old) I\", ' here.\" \"I want to show you something.\" \"Do you know what just happened to us?\" \"They tried to hit Rocky again.\" \"And where do you want me to put my truck?\" \"Put it over there, Rocky.\" \"I heard about it over the police radio.\" \"You two guys okay?\"', 'ing it into a pot thrilled me. I had sent out roots and was taking hold in the soil of our earth. I was making a home for myself in the world. As I allowed myself to feel my emotions after a lifetime of fearing them, I began to grow straight and tall. Do you know that that', ' no reason to be afraid in Lowell. After all, it is only credit cards reporting of what you already know in Lowell all about. It should not come as a surprise in Lowell OH that you either have earned a great credit score in Lowell and rating or definitely have earned a negative one! A credit', ', I would consider a retro-system as anything that a reasonable person would not consider contemporary to what is modernly available. \\n\\n…not considered contemporary to what is modernly available. \\n\\nContemporary does not mean \"went out of fashion yesterday.\" I know that leaves things a bit fuzzy, but it\\'s', ' than a blanket proposal to arrest and detain thousands of Muslims living here, without due process I might add.\" \"Be that as it may, since, as I understand it, the terrorists have now acquired the capability to arm the three remaining nuclear weapons.\" \"I\\'m asking you to reconsider.\" \"And I thought I told', \"\\n        }\\n    }\\n}\\nAs people know, I'm picking up my little ruby girl in anything between three and six weeks. As people may also know, I'm profoundly deaf. How should I approach the overnight thing with the new pup? With Holly (she was 12/13 weeks old) I\", ' know anymore...\" \"if it\\'s sympathy or not.\" \"I\\'m not sure anymore.\" \"I just want to make her happy... as much as I can.\" \"I\\'ll do anything for that.\" \"What about your wife? but after I left her...\" \"I realized what a great woman she is.\" \"', \" know that's not the case because it would be cost prohibitive. So, if you buy Bravo, you'll still be getting hormones, they'll just be mushed up now. I'm not sure how much your dog(s) weigh, but prepackaged can get very expensive, very fast.\\n\", '> also, if a channel is logged, it should be in the topic or in the entry message\\n<MenZa> oh I agree\\n<MenZa> But I still feel we need a policy on it\\n<topyli> for -ot logging?\\n<tsimpson> add it to the']\n",
      "--------------------------------------------------\n",
      "LatentIDX: 55\n",
      "torch.Size([2, 500, 64, 2048])\n",
      "Sequence indices:  tensor([32, 33, 34, 36, 38, 28, 56, 42, 51, 40], device='cuda:0')\n",
      "Batch indices:  tensor([ 56,  56,  56,  56,  56,  56, 341,  56,  56,  56], device='cuda:0')\n",
      "Top batch tokens shape  torch.Size([10, 64])\n",
      "The top 10 tokens are: \n",
      "  have to be in to Therefore have the. and\n",
      "They were found in the following batches of text ['],[@B27]^ This confirms the necessity to pay attention to the problems the caregivers face in taking care of the SCI patients in daily life. Therefore, supportive systems have to be planned in order to investigate and follow the problems of this vulnerable group of the society.\\n\\nThe findings of the present study showed that the educational', '],[@B27]^ This confirms the necessity to pay attention to the problems the caregivers face in taking care of the SCI patients in daily life. Therefore, supportive systems have to be planned in order to investigate and follow the problems of this vulnerable group of the society.\\n\\nThe findings of the present study showed that the educational', '],[@B27]^ This confirms the necessity to pay attention to the problems the caregivers face in taking care of the SCI patients in daily life. Therefore, supportive systems have to be planned in order to investigate and follow the problems of this vulnerable group of the society.\\n\\nThe findings of the present study showed that the educational', '],[@B27]^ This confirms the necessity to pay attention to the problems the caregivers face in taking care of the SCI patients in daily life. Therefore, supportive systems have to be planned in order to investigate and follow the problems of this vulnerable group of the society.\\n\\nThe findings of the present study showed that the educational', '],[@B27]^ This confirms the necessity to pay attention to the problems the caregivers face in taking care of the SCI patients in daily life. Therefore, supportive systems have to be planned in order to investigate and follow the problems of this vulnerable group of the society.\\n\\nThe findings of the present study showed that the educational', '],[@B27]^ This confirms the necessity to pay attention to the problems the caregivers face in taking care of the SCI patients in daily life. Therefore, supportive systems have to be planned in order to investigate and follow the problems of this vulnerable group of the society.\\n\\nThe findings of the present study showed that the educational', ' an extra set of molars to make the larger mouth more productive. This was particularly essential as the body lacked the ability to sufficiently digest cellulose. As evolution made its selections, our diets changed, our jaws grew appropriately smaller, and our third molars became unnecessary. Some human populations have now all but completely stopped growing wisdom', '],[@B27]^ This confirms the necessity to pay attention to the problems the caregivers face in taking care of the SCI patients in daily life. Therefore, supportive systems have to be planned in order to investigate and follow the problems of this vulnerable group of the society.\\n\\nThe findings of the present study showed that the educational', '],[@B27]^ This confirms the necessity to pay attention to the problems the caregivers face in taking care of the SCI patients in daily life. Therefore, supportive systems have to be planned in order to investigate and follow the problems of this vulnerable group of the society.\\n\\nThe findings of the present study showed that the educational', '],[@B27]^ This confirms the necessity to pay attention to the problems the caregivers face in taking care of the SCI patients in daily life. Therefore, supportive systems have to be planned in order to investigate and follow the problems of this vulnerable group of the society.\\n\\nThe findings of the present study showed that the educational']\n",
      "--------------------------------------------------\n",
      "LatentIDX: 61\n",
      "torch.Size([2, 500, 64, 2048])\n",
      "Sequence indices:  tensor([ 7, 33,  6, 38, 15, 12, 27, 63, 61,  3], device='cuda:0')\n",
      "Batch indices:  tensor([231, 488, 333, 371, 418, 450, 496, 371, 371, 277], device='cuda:0')\n",
      "Top batch tokens shape  torch.Size([10, 64])\n",
      "The top 10 tokens are: \n",
      " _ transcription-_-_-__-\n",
      "They were found in the following batches of text ['\\r\\n\"\"\"\\r\\n\\r\\ndef reverse_sort(array):\\r\\n\\tfor i in range(len(array) - 1):\\r\\n\\t\\tfor n in range(len(array) - 1):\\r\\n\\t\\t\\ta = array[n]\\r\\n\\t\\t\\tif (a < array[i]):\\r\\n\\t\\t\\t\\ttem = array[', '\\\\]). The limited knowledge about the structure of intracellular retroviral complexes prohibits a detailed discussion, but there is supportive evidence that large molecules cannot enter the core particle in which reverse transcription occurs. For instance, it was shown that tRNA molecules can enter the core particle in virus-infected cells, but with an efficiency that is 4 to', ', I would consider a retro-system as anything that a reasonable person would not consider contemporary to what is modernly available. \\n\\n…not considered contemporary to what is modernly available. \\n\\nContemporary does not mean \"went out of fashion yesterday.\" I know that leaves things a bit fuzzy, but it\\'s', ' trs.reshape((-1, 2))\\n            if c == Path.LINETO:\\n                (t, r), = trs\\n                if t == last_t:  # Same angle: draw a straight line.\\n                    xys.extend(self.transform_non_', ' solar abundances [@Wilms2000] and the [vern]{} photoionization cross-section [@Verner96].\\n\\n### [[*RXTE*]{}]{}\\xa0and [[*Chandra*]{}]{}\\xa0Spectroscopy\\n\\nTo isolate the purely pulsed emission for the [[*RXTE*]{}]{}\\xa0data, we used the scaled off', ')\\n); \\nALTER TABLE foobar AUTO_INCREMENT=10;\\n\\nINSERT INTO foobar(moobar) values (\"abc\");\\nINSERT INTO foobar(moobar) values (\"def\");\\nINSERT INTO foobar(moobar) values (\"xyz\");\\n\\nselect * from', ' gave the pharmacokinetic parameters of 0.083 hours (Tmax) reaching a Cmax of 0.457ug/mL with a half-life of 7.5 hours and an AUC0-∞ of 12.202ug/h/mL.[27]\\n\\nAppears to be rapidly absorbed, but the', ' trs.reshape((-1, 2))\\n            if c == Path.LINETO:\\n                (t, r), = trs\\n                if t == last_t:  # Same angle: draw a straight line.\\n                    xys.extend(self.transform_non_', ' trs.reshape((-1, 2))\\n            if c == Path.LINETO:\\n                (t, r), = trs\\n                if t == last_t:  # Same angle: draw a straight line.\\n                    xys.extend(self.transform_non_', ' the next half-century the only direct public application of Copernicus\\' theories was for this very practical purpose. Yet this \"proof\" of the truth of Copernicus\\' system was not by Copernicus himself and was presented in such a way as not to seem an endorsement of any risky cosmological shift.\\n']\n",
      "--------------------------------------------------\n",
      "LatentIDX: 64\n",
      "torch.Size([2, 500, 64, 2048])\n",
      "Sequence indices:  tensor([14, 39, 11, 55, 13, 38, 47, 34, 60, 60], device='cuda:0')\n",
      "Batch indices:  tensor([112, 435, 435, 288, 435, 460, 464, 278, 390, 476], device='cuda:0')\n",
      "Top batch tokens shape  torch.Size([10, 64])\n",
      "The top 10 tokens are: \n",
      " ióniónionesionónionsunionionioner\n",
      "They were found in the following batches of text [' del 2019 estos trabajadores podrán aplicar como deducción hasta el 15% de lo pagado por los servicios recibidos en restaurantes, hoteles, bares y cantinas, considerando incluso los impuestos correspondientes (IGV e Impuesto Municipal).\\n\\n', ']), identificaron la prevalencia de las condiciones crónicas en las poblaciones afectadas por el conflicto armado en Siria, siendo la hipertensión arterial y los problemas músculo esqueléticos las enfermedades más frecuentes con', ']), identificaron la prevalencia de las condiciones crónicas en las poblaciones afectadas por el conflicto armado en Siria, siendo la hipertensión arterial y los problemas músculo esqueléticos las enfermedades más frecuentes con', '42 mmol), K~3~PO~4~ (0.089g, 0.42 mmol), and Pd(PPh~3~)~4~ (8 mg, 0.007 mmol) under nitrogen atmosphere. Dioxane (5 mL) and deionized water (0.1 mL)', ']), identificaron la prevalencia de las condiciones crónicas en las poblaciones afectadas por el conflicto armado en Siria, siendo la hipertensión arterial y los problemas músculo esqueléticos las enfermedades más frecuentes con', \"t')\\\\rangle_{\\\\beta} = \\\\langle E_x(\\\\x,t)E_x(\\\\x,t')\\\\rangle_{\\\\beta}$. Using the above results, the finite temperature dispersions $\\\\langle(\\\\Delta v_j)^2\\\\rangle_{{}_\\\\beta}$ can be obtained in the same way as we did\", 'inscription téléchargeable sur le site internet du conseil départemental www.cg974.fr.. Le document est également disponible à la Bibliothèque départementale de La Réunion.\\n\\nwww.ipreunion.comMain Menu\\n\\nDC Brew', 'ida.\"\\n\\n\"Rhodes?\"\\n\\n\"Let me take you back to your rooms, sire.\"\\n\\n\"Yes... yes. Where is Parmenion?\"\\n\\n\"In Elam, sire. But do not concern yourself. He will be dead by tomorrow. I sent three of our', \"istic Literature\\n\\n_Edited by Martine Cuypers and James J. Clauss_\\n\\nA Companion to Vergil's _Aeneid_ and its Tradition\\n\\n_Edited by Joseph Farrell and Michael C. J. Putnam_\\n\\nA Companion to Horace\", ' at PS Store through the weekend! Offer ends August 7 at 8 am PST.StartChar: uni0136\\nEncoding: 310 310 224\\nGlifName: uni0136\\nWidth: 681\\nVWidth: 0\\nFlags: HMW\\nLayerCount: 3\\nFore\\nRefer: 128 8']\n",
      "--------------------------------------------------\n",
      "LatentIDX: 66\n",
      "torch.Size([2, 500, 64, 2048])\n",
      "Sequence indices:  tensor([62, 29, 34,  6, 45, 11, 58, 60, 15, 42], device='cuda:0')\n",
      "Batch indices:  tensor([251, 225, 225, 425, 435,   9, 337, 328, 367, 337], device='cuda:0')\n",
      "Top batch tokens shape  torch.Size([10, 64])\n",
      "The top 10 tokens are: \n",
      "  m m d m m v m m m m\n",
      "They were found in the following batches of text ['os centros\".\\n\\n\"Es mentira cuando dicen, por ejemplo, que no hay suficientes recursos en Madrid para ayudar a las personas sintecho\" porque, en realidad, \"hay recursos de sobra, lo que pasa es que son incapaces de mover', \"\\n<Bril2> geef me zelf nog 2 uur voor dit en wifi\\n<CasW> Nouja, bij mij ging 'ie dus weg, toen ik de proprietary drivers had geÃ¯nstalleerd en alles had geÃ¼pdate.\\n\", \"\\n<Bril2> geef me zelf nog 2 uur voor dit en wifi\\n<CasW> Nouja, bij mij ging 'ie dus weg, toen ik de proprietary drivers had geÃ¯nstalleerd en alles had geÃ¼pdate.\\n\", \" les étudiants, la moyenne européenne est de 103 femmes pour 100 hommes. Avec 77 femmes pour 100 hommes, l' Allemagne est la lanterne rouge de l' UE. Quoi qu' il en soit, les diplômés sont plus souvent\", ']), identificaron la prevalencia de las condiciones crónicas en las poblaciones afectadas por el conflicto armado en Siria, siendo la hipertensión arterial y los problemas músculo esqueléticos las enfermedades más frecuentes con', 'emming van Christchurch,\\nstuur de vliegtuigen maar.\\n\\nEnglish: \\nMeanwhile in Christchurch, New Zealand...\\nWe need to use your airfield intensively for\\nthe upcoming months, you will be compensated.\\nWhy?\\nFor our project in Antarctica.', 'kiant suklaidinti mūsų vartotojus, kad šie produktai saugūs ir atitinka ES standartus. Šiandien mūsų diskusijos svarbiausia tema ir mūsų vart', ' . . paying off debt is never quick or easy. While the Baby Steps are simple, they do take some work. And your progress only moves at the speed of your motivation.The 49ers unveiled a 70th-anniversary patch yesterday (see above; further info here). It’s a muddled design that', \" Saint Cerbone, patron of Massa, nimbated and with a miter in a striped crown. The reverse legend, on the other hand, reads + S '• CE RBON', with the letter C open and the letter N reversed.\\n Denaro piccolo: One of the three variants\", 'kiant suklaidinti mūsų vartotojus, kad šie produktai saugūs ir atitinka ES standartus. Šiandien mūsų diskusijos svarbiausia tema ir mūsų vart']\n",
      "--------------------------------------------------\n",
      "LatentIDX: 68\n",
      "torch.Size([2, 500, 64, 2048])\n",
      "Sequence indices:  tensor([17, 26,  0, 16, 35, 53,  0,  0, 34,  2], device='cuda:0')\n",
      "Batch indices:  tensor([204, 352, 204, 290, 290, 290, 263,  21, 352, 266], device='cuda:0')\n",
      "Top batch tokens shape  torch.Size([10, 64])\n",
      "The top 10 tokens are: \n",
      " =: ||=== steady gl:}\n",
      "They were found in the following batches of text [' || March 28, 2008 || Mount Lemmon || Mount Lemmon Survey || NYS || align=right data-sort-value=\"0.69\" | 690 m || \\n|-id=073 bgcolor=#fefefe\\n| 336073 ||  || — || March 28, 2008 || Kitt Peak || Spacewatch || F', ': 0px; margin-right: auto; margin-bottom: 10px; margin-left: auto; text-align: center; cursor: pointer; width: 320px; height: 240px; \" /></span></span></span></b></span></span></div><div><span class=\"', ' || March 28, 2008 || Mount Lemmon || Mount Lemmon Survey || NYS || align=right data-sort-value=\"0.69\" | 690 m || \\n|-id=073 bgcolor=#fefefe\\n| 336073 ||  || — || March 28, 2008 || Kitt Peak || Spacewatch || F', ' ]\\t(\\t\"local\"\\t)\\nrst\\t[ 0\\tlocks=0 ]\\t(\\t\"srt\"\\t)\\nxyz\\t[ 0\\tlocks=0 ]\\t(\\t\"xyz\"\\t)\\ntranslate\\t[ 0\\tlocks=0 ]\\t(\\t0\\t0\\t0', ' ]\\t(\\t\"local\"\\t)\\nrst\\t[ 0\\tlocks=0 ]\\t(\\t\"srt\"\\t)\\nxyz\\t[ 0\\tlocks=0 ]\\t(\\t\"xyz\"\\t)\\ntranslate\\t[ 0\\tlocks=0 ]\\t(\\t0\\t0\\t0', ' ]\\t(\\t\"local\"\\t)\\nrst\\t[ 0\\tlocks=0 ]\\t(\\t\"srt\"\\t)\\nxyz\\t[ 0\\tlocks=0 ]\\t(\\t\"xyz\"\\t)\\ntranslate\\t[ 0\\tlocks=0 ]\\t(\\t0\\t0\\t0', ' steady splendour; but at the tip-top,  \\nThere hangs by unseen film, an orbed drop  \\nOf light, and that is love: its influence,  \\nThrown in our eyes, genders a novel sense,  \\nAt which we start and fret; till in the end,', \" glpiana, adesso per creare una swap cosa dovrei fare?\\n<glpiana> oneup, l'hai allargata troppo\\n<glpiana> ho sbagliato io\\n<glpiana> oneup, non hai applicato ancora,\", ': 0px; margin-right: auto; margin-bottom: 10px; margin-left: auto; text-align: center; cursor: pointer; width: 320px; height: 240px; \" /></span></span></span></b></span></span></div><div><span class=\"', '{aligned}\\n\\\\epsilon_{xx} & = & \\\\epsilon_{xx}^d + F_{xx} \\\\nonumber \\\\\\\\\\n& = & \\\\frac{1}{2}( \\\\partial_x u_x+ \\\\partial_x u_x) + \\\\frac{1}{2} (\\\\partial_']\n",
      "--------------------------------------------------\n",
      "LatentIDX: 69\n",
      "torch.Size([2, 500, 64, 2048])\n",
      "Sequence indices:  tensor([ 7, 45, 31, 49, 29, 32,  6, 56, 35,  3], device='cuda:0')\n",
      "Batch indices:  tensor([  0, 174,  86,  55,  55, 312, 284, 370, 430, 400], device='cuda:0')\n",
      "Top batch tokens shape  torch.Size([10, 64])\n",
      "The top 10 tokens are: \n",
      " -----                       - to- presidential\n",
      "They were found in the following batches of text ['abank.m 10028 2017-08-11 16:39:37Z dmb $\\r\\n%\\r\\n%   VOICEBOX is a MATLAB toolbox for speech processing.\\r\\n%   Home page: http://www.ee.ic.ac.uk/hp/staff/d', ' home the NBAâ\\x80\\x99s highest individual honor. With about 50 games down, neither has disappointed. With Harden and Westbrook as the current front-runners for MVP, here are each of their cases for 2017-02-03 16:03:062/1: ESNY- A Big Man&#', \"il (MMF) en route to the operating room for the facial transplant procedure. The shaded area indicates the initiation of maintenance immunosuppression.](CRIT2018-7691072.001){#fig1}\\n\\n![Patient\\\\'s maintenance tacrolimus trough levels recorded in the posttransplant period. Shaded\", '\"ns3.google.com\",\\n    \"ns4.google.com\"\\n  ],\\n  \"creationDate\": \"1999-06-08T00:00:00\",\\n  \"expirationDate\": \"2020-07-08T00:00:00\",\\n  \"owner', '\"ns3.google.com\",\\n    \"ns4.google.com\"\\n  ],\\n  \"creationDate\": \"1999-06-08T00:00:00\",\\n  \"expirationDate\": \"2020-07-08T00:00:00\",\\n  \"owner', 'Ind. Ct. App. 1993).\\n\\n       Court of Appeals of Indiana | Opinion 49A02-1405-CR-307 | February 20, 2015                       Page 11 of 13\\n\\x0c       App. p. 60 (“Defense Counsel argued that the time needed to obtain this\\n\\n       information via a prescriptions[-]', ' six teams that made those franchise-altering selections are on Tampa Bay’s slate this fall.\\n\\nIt started early on the first evening of the draft. As expected, the Carolina Panthers opened the proceedings with the selection of Auburn quarterback Cam Newton first overall. Not long after, the Tennessee Titans surprised many by grabbing', ' poster will be unveiled and the winner awarded a cash prize of $500.\\n\\nIn addition to the poster exhibition, we will have with us this year the following talent…internationally renowned opera singer Josaphat Contreras, Poet Laureate of Arlington from 2017 to summer of 2019, Cathie Des', ';&gt;&gt; Move to open Start / All programs/wmm-&gt; Task Pane <br> 1. Import video editing application streaming remotes **- VCAM, importing images and music <br> 2. Edit-drag and drop video files-&gt; timeline &amp; enhance', ' in the 2011 presidential and general electoral campaigns.\\n\\nAND when asked whether or not he would go to Mongu for this year’s Kuomboka traditional ceremony, given that the treason case that saw him and five others spend slightly over four months in prison emanated from there, Hichilema said he would']\n",
      "--------------------------------------------------\n",
      "LatentIDX: 70\n",
      "torch.Size([2, 500, 64, 2048])\n",
      "Sequence indices:  tensor([ 3,  5, 51, 61, 39, 43, 21, 13,  0, 40], device='cuda:0')\n",
      "Batch indices:  tensor([131, 264, 458, 458, 458, 264, 264, 264, 131, 458], device='cuda:0')\n",
      "Top batch tokens shape  torch.Size([10, 64])\n",
      "The top 10 tokens are: \n",
      "                                                                         else  \n",
      "They were found in the following batches of text ['else\\n                                v = consts->i32[c];\\n\\n                        fprintf(fp, \"%\"PRIi64, v);\\n                } else if (is_uint || is_hex) {\\n                        uint64_t v;\\n\\n                        if (half && mod == midgard_', ' public facilities.\\n                                 Kolling et al.                                                                Tanzania (2010)                                 Qualitative    Patients drew supports from their social networks within their local communities to support their medication.\\n                                 Kühlbrandt et al.                                                             Armenia, Belarus, Moldova,', ' petitioner’s counsel\\nJeffrey S. Pop, Esq.\\n\\n        The clerk of the court shall enter judgment in accordance herewith. 4\\n\\nIT IS SO ORDERED.\\n\\n                                                           s/Nora Beth Dorsey\\n                                                           Nora Beth Dorsey\\n                                                           Chief', ' petitioner’s counsel\\nJeffrey S. Pop, Esq.\\n\\n        The clerk of the court shall enter judgment in accordance herewith. 4\\n\\nIT IS SO ORDERED.\\n\\n                                                           s/Nora Beth Dorsey\\n                                                           Nora Beth Dorsey\\n                                                           Chief', ' petitioner’s counsel\\nJeffrey S. Pop, Esq.\\n\\n        The clerk of the court shall enter judgment in accordance herewith. 4\\n\\nIT IS SO ORDERED.\\n\\n                                                           s/Nora Beth Dorsey\\n                                                           Nora Beth Dorsey\\n                                                           Chief', ' public facilities.\\n                                 Kolling et al.                                                                Tanzania (2010)                                 Qualitative    Patients drew supports from their social networks within their local communities to support their medication.\\n                                 Kühlbrandt et al.                                                             Armenia, Belarus, Moldova,', ' public facilities.\\n                                 Kolling et al.                                                                Tanzania (2010)                                 Qualitative    Patients drew supports from their social networks within their local communities to support their medication.\\n                                 Kühlbrandt et al.                                                             Armenia, Belarus, Moldova,', ' public facilities.\\n                                 Kolling et al.                                                                Tanzania (2010)                                 Qualitative    Patients drew supports from their social networks within their local communities to support their medication.\\n                                 Kühlbrandt et al.                                                             Armenia, Belarus, Moldova,', 'else\\n                                v = consts->i32[c];\\n\\n                        fprintf(fp, \"%\"PRIi64, v);\\n                } else if (is_uint || is_hex) {\\n                        uint64_t v;\\n\\n                        if (half && mod == midgard_', ' petitioner’s counsel\\nJeffrey S. Pop, Esq.\\n\\n        The clerk of the court shall enter judgment in accordance herewith. 4\\n\\nIT IS SO ORDERED.\\n\\n                                                           s/Nora Beth Dorsey\\n                                                           Nora Beth Dorsey\\n                                                           Chief']\n",
      "--------------------------------------------------\n",
      "LatentIDX: 71\n",
      "torch.Size([2, 500, 64, 2048])\n",
      "Sequence indices:  tensor([52, 22, 36, 50,  0, 19, 23, 10,  2, 35], device='cuda:0')\n",
      "Batch indices:  tensor([199, 410, 431, 431, 354, 409, 410, 409, 409, 431], device='cuda:0')\n",
      "Top batch tokens shape  torch.Size([10, 64])\n",
      "The top 10 tokens are: \n",
      "     Eq (\\[   of\n",
      "They were found in the following batches of text ['\\\\_bz\\\\]Transverse magnetic field component $B_{z}$ of a laser reflecting and generating harmonics at an overdense plasma surface at normal incidence. The dashed line highlights the motion of the reflecting surface, fitted by a Gaussian function, corresponding to Eq.\\xa0 with $\\\\alpha=1.35$. Parameters are:', ' The last factor is the same phase space cut-off as imposed for the baryons (\\\\[param\\\\]). Eq.\\xa0(\\\\[enparameter\\\\]) contains only the non-baryonic energy to which the contribution connected with the net baryon density will be added. The parametrization has three unknowns (at each $\\\\vec\\\\rho', ' ]\\\\wedge \\\\xi_E$, lies in $\\\\Lambda^2\\\\big(E^\\\\perp\\\\big)$ and hence plays no role in the calculation of the polar equations of\\xa0$E$. Hence, the polar spaces for an integral flag of\\xa0$E$ can be calculated using only $-\\\\bigl( [\\\\alpha', ' ]\\\\wedge \\\\xi_E$, lies in $\\\\Lambda^2\\\\big(E^\\\\perp\\\\big)$ and hence plays no role in the calculation of the polar equations of\\xa0$E$. Hence, the polar spaces for an integral flag of\\xa0$E$ can be calculated using only $-\\\\bigl( [\\\\alpha', 'Eq. \\\\[chap4-eq-vm-place-feas-1\\\\] and \\\\[chap4-eq-db-place-feas-1\\\\]), it is checked if the bandwidth demand of the VDL can be satisfied by the available bandwidth of the corresponding PDL connecting the CN and SN. If it can be', ' M.\\xa0[Irfan]{}, S.\\xa0M. [AL]{}, and S.\\xa0Y. [Shin]{}, “Selective non-orthogonal multiple access ([NOMA]{}) and spatial modulation ([SM]{}) for improved spectral efficiency,” in *IEEE Int. Symp. Intelligent Signal Process. Commun', ' The last factor is the same phase space cut-off as imposed for the baryons (\\\\[param\\\\]). Eq.\\xa0(\\\\[enparameter\\\\]) contains only the non-baryonic energy to which the contribution connected with the net baryon density will be added. The parametrization has three unknowns (at each $\\\\vec\\\\rho', ' M.\\xa0[Irfan]{}, S.\\xa0M. [AL]{}, and S.\\xa0Y. [Shin]{}, “Selective non-orthogonal multiple access ([NOMA]{}) and spatial modulation ([SM]{}) for improved spectral efficiency,” in *IEEE Int. Symp. Intelligent Signal Process. Commun', ' M.\\xa0[Irfan]{}, S.\\xa0M. [AL]{}, and S.\\xa0Y. [Shin]{}, “Selective non-orthogonal multiple access ([NOMA]{}) and spatial modulation ([SM]{}) for improved spectral efficiency,” in *IEEE Int. Symp. Intelligent Signal Process. Commun', ' ]\\\\wedge \\\\xi_E$, lies in $\\\\Lambda^2\\\\big(E^\\\\perp\\\\big)$ and hence plays no role in the calculation of the polar equations of\\xa0$E$. Hence, the polar spaces for an integral flag of\\xa0$E$ can be calculated using only $-\\\\bigl( [\\\\alpha']\n",
      "--------------------------------------------------\n",
      "LatentIDX: 72\n",
      "torch.Size([2, 500, 64, 2048])\n",
      "Sequence indices:  tensor([37, 40, 28,  1, 42, 60, 13, 48, 25, 62], device='cuda:0')\n",
      "Batch indices:  tensor([  0, 262, 430, 441, 430, 409, 356, 265, 399, 314], device='cuda:0')\n",
      "Top batch tokens shape  torch.Size([10, 64])\n",
      "The top 10 tokens are: \n",
      "  speech verbal video spoken music Signal speakingognition music application\n",
      "They were found in the following batches of text ['abank.m 10028 2017-08-11 16:39:37Z dmb $\\r\\n%\\r\\n%   VOICEBOX is a MATLAB toolbox for speech processing.\\r\\n%   Home page: http://www.ee.ic.ac.uk/hp/staff/d', '\\n\\nEthics approval and consent to participate {#FPar10}\\n==========================================\\n\\nThe University of Florida Institutional Review Board provided the approval for this study (IRB201501210). All subjects provided verbal informed consent after reviewing the IRB-approved consent form. The study was performed under a waiver of documentation of informed', ';&gt;&gt; Move to open Start / All programs/wmm-&gt; Task Pane <br> 1. Import video editing application streaming remotes **- VCAM, importing images and music <br> 2. Edit-drag and drop video files-&gt; timeline &amp; enhance', ' is spoken   \\nO Mary canst thou feel the past   \\nAnd keep thy heart unbroken   \\nTo think how warm we loved and how   \\nThose hopes should blossom never   \\nTo think how we are parted now   \\nAnd parted oh for ever   \\nFare thee well\\n\\nThou', ';&gt;&gt; Move to open Start / All programs/wmm-&gt; Task Pane <br> 1. Import video editing application streaming remotes **- VCAM, importing images and music <br> 2. Edit-drag and drop video files-&gt; timeline &amp; enhance', ' M.\\xa0[Irfan]{}, S.\\xa0M. [AL]{}, and S.\\xa0Y. [Shin]{}, “Selective non-orthogonal multiple access ([NOMA]{}) and spatial modulation ([SM]{}) for improved spectral efficiency,” in *IEEE Int. Symp. Intelligent Signal Process. Commun', ' stood up against bad\\ntrends in this area - most recently speaking up against the EU data retention\\ndirective that would require ISPs to keep records about all electronic\\ncommunications sent between citizens of the EU (and Norway, which is strictly\\nspeaking not in the EU).\\n\\nThe problem is that Facebook is', ' multitude of layers. What does this mean? With all the glitches and weird results in the digital world, that is hard to answer with complete certainty. However, when a print document is scanned, with OCR (Optical Character Recognition) active, it should, to the best of our professional knowledge and experience', ' page design journey\\n\\nCompany name\\n\\nOverview\\n\\nBeamto.us is an uncluttered oasis of music, news, information, discussion board and social networking for electronic music. A homegrown algorithm determines the ranking of each beam with inputs such as number of times played, downloaded, comments, vote', ' integration,security, analytics, development tools, life-cycle management, various mobile stakeholders, and the overall enterprise mobile ecosystem.\\n\\nComplex hybrid environments can make it difficult to track interdependencies, increasing the risk of disrupting critical business services. In this research paper by EMA, you’ll learn how application discovery']\n",
      "--------------------------------------------------\n",
      "LatentIDX: 74\n",
      "torch.Size([2, 500, 64, 2048])\n",
      "Sequence indices:  tensor([ 7, 25,  2,  2, 27, 62, 21,  5,  8,  7], device='cuda:0')\n",
      "Batch indices:  tensor([132, 442, 321, 372, 372, 450, 433, 372, 372, 321], device='cuda:0')\n",
      "Top batch tokens shape  torch.Size([10, 64])\n",
      "The top 10 tokens are: \n",
      "  * * * * * * * * * *\n",
      "They were found in the following batches of text [' wood fern) and the sexual *D. oreades* (mountain male fern; Fraser-Jenkins, [@B18]). The gametophyte of this species forms male but no female reproductive organs and, when cultured *in vitro*, reproduces by apogamy. Once the gamet', ' questions concerning defendant\\'s infraction of prison rules sought to discredit the defendant by showing that the defendant had falsely characterized himself. *658 The purpose of the prosecutor\\'s examination enumerated above went to the defendant\\'s credibility.\"\\nWe feel, however, that a man\\'s reputation, especially where he is also the criminal defendant-', 'iii) *Neo* and *Ter*~*neo*~ (primers KANARTER_for/KANARTER_rev, on pCEV-G2-Km, Addgene \\\\#46815), *Pro*~*TDH3*~ (primers TDHG_for/TDHG', '\\n+ *\\n+ *\\n+ * ALTERNATIVELY, this software may be distributed under the terms of the\\n+ * GNU General Public License (\"GPL\") as published by the Free Software\\n+ * Foundation, either version 2 of that License or (at your option) any\\n+ * later version', '\\n+ *\\n+ *\\n+ * ALTERNATIVELY, this software may be distributed under the terms of the\\n+ * GNU General Public License (\"GPL\") as published by the Free Software\\n+ * Foundation, either version 2 of that License or (at your option) any\\n+ * later version', ')\\n); \\nALTER TABLE foobar AUTO_INCREMENT=10;\\n\\nINSERT INTO foobar(moobar) values (\"abc\");\\nINSERT INTO foobar(moobar) values (\"def\");\\nINSERT INTO foobar(moobar) values (\"xyz\");\\n\\nselect * from', ', made an agreement with her and then breached that agreement.\\nSee 2010 WL 3442212, at *4. She further alleged that, in efforts to collect a debt,\\nCalstar lied to her in phone calls and writings directed at Texas. Id. The court of\\nappeals determined that these pleadings alleged', '\\n+ *\\n+ *\\n+ * ALTERNATIVELY, this software may be distributed under the terms of the\\n+ * GNU General Public License (\"GPL\") as published by the Free Software\\n+ * Foundation, either version 2 of that License or (at your option) any\\n+ * later version', '\\n+ *\\n+ *\\n+ * ALTERNATIVELY, this software may be distributed under the terms of the\\n+ * GNU General Public License (\"GPL\") as published by the Free Software\\n+ * Foundation, either version 2 of that License or (at your option) any\\n+ * later version', 'iii) *Neo* and *Ter*~*neo*~ (primers KANARTER_for/KANARTER_rev, on pCEV-G2-Km, Addgene \\\\#46815), *Pro*~*TDH3*~ (primers TDHG_for/TDHG']\n",
      "--------------------------------------------------\n",
      "LatentIDX: 79\n",
      "torch.Size([2, 500, 64, 2048])\n",
      "Sequence indices:  tensor([42, 50, 17,  0, 58, 22, 60, 56, 47, 53], device='cuda:0')\n",
      "Batch indices:  tensor([ 14, 396, 469, 374, 351, 442, 287, 426, 290, 327], device='cuda:0')\n",
      "Top batch tokens shape  torch.Size([10, 64])\n",
      "The top 10 tokens are: \n",
      "  interpret interpret interpretations constru treating characterized signific reconsidertranslateunderstand\n",
      "They were found in the following batches of text [' they can only string together nonsense gibberish or random words. However, the party member with the LOWEST Intelligence score somehow easily understands the gibberish. The Player of the PC is allowed to freely interpret the nonsent as they see fit, but the Clearly Insane Person can vehimently indicate the negative', ' When violent suicide attempts were analysed, it was found that mothers with antibodies against T. gondii had an 81% increased risk (relative risk 1.81, 95% confidence interval 1.13 to 2.84).\\n\\nHow did the researchers interpret the results?\\n\\nThe researchers say, “women with a', '\": \"three equal horizontal bands of blue (top), black, and white; various interpretations are linked to the flag colors; blue represents faith, loyalty, and devotion, while also reminiscent of the sky, sea, and lakes of the country; black symbolizes the soil of the country and the dark past and suffering endured', \" construire des édifices stables : quand on bâtit le Temple de Jérusalem, « les pierres furent amenées toutes telles qu'elles devaient être, de sorte que, en bâtissant la maison, on n'entendît ni marteau\", 'ition to the United States this year, security experts have noted significant clashes within and among cartels as they jostle for supremacy.\\n\\nLas Varas, a farming and livestock community more than three hours from the state capital, has only one small clinic, which is not capable of treating the victims, said Eli', ' questions concerning defendant\\'s infraction of prison rules sought to discredit the defendant by showing that the defendant had falsely characterized himself. *658 The purpose of the prosecutor\\'s examination enumerated above went to the defendant\\'s credibility.\"\\nWe feel, however, that a man\\'s reputation, especially where he is also the criminal defendant-', ' about the meat, she said, “Sheep cheeks and tongue…good right?”\\nI smiled and said, “Really good, thanks.”\\n\\nLike the meal, living in commune is like that. The more you try new stuff, the better it gets.Q:\\n\\nO que significam as ret', ' than a blanket proposal to arrest and detain thousands of Muslims living here, without due process I might add.\" \"Be that as it may, since, as I understand it, the terrorists have now acquired the capability to arm the three remaining nuclear weapons.\" \"I\\'m asking you to reconsider.\" \"And I thought I told', ' ]\\t(\\t\"local\"\\t)\\nrst\\t[ 0\\tlocks=0 ]\\t(\\t\"srt\"\\t)\\nxyz\\t[ 0\\tlocks=0 ]\\t(\\t\"xyz\"\\t)\\ntranslate\\t[ 0\\tlocks=0 ]\\t(\\t0\\t0\\t0', 'ilege and is casteist. Though, how much of him she has understood,\\nis unfortunately, questionable. For someone who has such a control over\\nthe English language, this is surprising. So it is something else that\\nmakes her misquote and isunderstand what Babasaheb has said. She\\n']\n",
      "--------------------------------------------------\n",
      "LatentIDX: 80\n",
      "torch.Size([2, 500, 64, 2048])\n",
      "Sequence indices:  tensor([20,  8, 19, 18, 27, 15, 17, 42, 19, 16], device='cuda:0')\n",
      "Batch indices:  tensor([150, 209, 240,  72, 442, 458, 459, 182, 315, 276], device='cuda:0')\n",
      "Top batch tokens shape  torch.Size([10, 64])\n",
      "The top 10 tokens are: \n",
      "  TheThe TheThe TheThe TheTheThe The\n",
      "They were found in the following batches of text [' DO NOT ALTER OR REMOVE COPYRIGHT NOTICES OR THIS FILE HEADER.\\n *\\n * The contents of this file are subject to the terms of either the Universal Permissive License\\n * v 1.0 as shown at http://oss.oracle.com/licenses/upl\\n *\\n * or', 'Schäffer, 1854)\\nTheretra monteironis (Butler, 1882)\\nXanthopan morganii (Walker, 1856)\\n\\nThyrididae\\nArniocera albiguttata Talbot, 1928\\nArniocera amoena Jordan,', \" you can create the podcast from beginning to end, making it ready for upload.\\n\\n## The Sky's the Limit: Big-Budget Software\\n\\nIf you're lucky enough to have unlimited funds and resources to build your podcasting studio, this section on software is for you. Most podcasts are working on\", '> class.\\r\\n        /// </summary>\\r\\n        /// <param name=\"context\">The <see cref=\"IRepositoryContext\"/> object for initializing the current repository.</param>\\r\\n        public MongoDBRepository(IRepositoryContext context)\\r\\n            : base(context)\\r\\n        {\\r\\n            if', ' questions concerning defendant\\'s infraction of prison rules sought to discredit the defendant by showing that the defendant had falsely characterized himself. *658 The purpose of the prosecutor\\'s examination enumerated above went to the defendant\\'s credibility.\"\\nWe feel, however, that a man\\'s reputation, especially where he is also the criminal defendant-', ' petitioner’s counsel\\nJeffrey S. Pop, Esq.\\n\\n        The clerk of the court shall enter judgment in accordance herewith. 4\\n\\nIT IS SO ORDERED.\\n\\n                                                           s/Nora Beth Dorsey\\n                                                           Nora Beth Dorsey\\n                                                           Chief', ', lines 14-16; TR 117, lines 23-25.)\\n29. The Site currently has no useful function because of the quantity of debris on it and the risk of fire. (TR 25, lines 7-10.)\\n30. Defendants left approximately 1,029,900 cubic yards of waste at the', '    the   performance     of\\n\\nwell-established        rituals.”        Krieger       also     submitted      various\\n\\npleadings and several exhibits, including (1) “The Handbook of\\n\\nAsatru,” with a forward written by Valgard Murray; (2) a', ' our brand color\\n‘Button One Hover Border Radius’ will\\nbe 2 pixels\\nThe last thing we’ll do is show you how\\nto add some custom CSS to your design.\\nTo our knowledge there isn’t an easy way\\nto add padding to the buttons to increase\\nthe actual size', \"Discover More at Renderosity! Week 4 Winners!\\n\\nGet The Most From Your Renderosity Membership\\n\\nAre you interested in saving time, energy and money\\nas well as learning new and valuable information?\\n\\nHopefully you answered the previous question with a\\nresounding 'YES'\"]\n",
      "--------------------------------------------------\n",
      "LatentIDX: 86\n",
      "torch.Size([2, 500, 64, 2048])\n",
      "Sequence indices:  tensor([43, 19, 54, 34, 27, 29,  9, 46, 32, 53], device='cuda:0')\n",
      "Batch indices:  tensor([124, 416, 284, 474, 474, 257, 449, 474, 409, 428], device='cuda:0')\n",
      "Top batch tokens shape  torch.Size([10, 64])\n",
      "The top 10 tokens are: \n",
      " Nullan long_AtSuccess waitAtogonal wanting\n",
      "They were found in the following batches of text ['Descriptor {\\n\\n\\tprivate Image baseImage;\\n\\tprivate int flags;\\n\\tprivate Point size;\\n\\n\\tprotected AbstractCompositeImageDescriptor(Image baseImage, int flags) {\\n\\t\\tAssert.notNull(baseImage);\\n\\t\\tthis.baseImage = baseImage;\\n\\t\\tthis.flags =', ' Public School, has revealed in a social media post that he was very angry with the principal Notan Lal for scolding him. Since he had not memorised his lesson, the principal had scolded him. This prompted him to make false allegations of blasphemy against the principal. He added that he had no', ' six teams that made those franchise-altering selections are on Tampa Bay’s slate this fall.\\n\\nIt started early on the first evening of the draft. As expected, the Carolina Panthers opened the proceedings with the selection of Auburn quarterback Cam Newton first overall. Not long after, the Tennessee Titans surprised many by grabbing', ' testOnlyText() {\\n        Version version = new Version(\"gwhwrthw\");\\n        assertTrue(version.isAtLeast(Version.NOT_FOUND));\\n        assertTrue(version.isAtLeast(new Version(\"1.1\")));\\n        assertTrue(version', ' testOnlyText() {\\n        Version version = new Version(\"gwhwrthw\");\\n        assertTrue(version.isAtLeast(Version.NOT_FOUND));\\n        assertTrue(version.isAtLeast(new Version(\"1.1\")));\\n        assertTrue(version', '{\\n        Entry& entry = getEntry(result.getCallID().server_node_id);\\n\\n        if (result.isSuccessful())\\n        {\\n            /*\\n             * Updating the uptime here allows to properly handle a corner case where the service response arrives\\n             * after the', \" the journey to meet our child! Can't wait to read about the rest of your week 🙂 May God continue to bless this wonderful journey for you!\\n\\nThe movie you referred there is not The Hunt for the Red October [1], that one is about a Soviet Navy Officer that defects to the US taking with him\", ' testOnlyText() {\\n        Version version = new Version(\"gwhwrthw\");\\n        assertTrue(version.isAtLeast(Version.NOT_FOUND));\\n        assertTrue(version.isAtLeast(new Version(\"1.1\")));\\n        assertTrue(version', ' M.\\xa0[Irfan]{}, S.\\xa0M. [AL]{}, and S.\\xa0Y. [Shin]{}, “Selective non-orthogonal multiple access ([NOMA]{}) and spatial modulation ([SM]{}) for improved spectral efficiency,” in *IEEE Int. Symp. Intelligent Signal Process. Commun', \"ons of cigarettes for several bottles of Tiger beer. The young boy that Smitty is trading with is complaining that he doesn't want Kools, he wants Salems, but he reluctantly accepts the Kools, and Smitty gets his Tiger beer. Not wanting to screw up Smitty's deal before it\"]\n",
      "--------------------------------------------------\n",
      "LatentIDX: 88\n",
      "torch.Size([2, 500, 64, 2048])\n",
      "Sequence indices:  tensor([39, 29, 38,  0,  0,  0,  0,  0, 22,  4], device='cuda:0')\n",
      "Batch indices:  tensor([225, 299, 225,  80, 467, 368, 343, 375, 441, 261], device='cuda:0')\n",
      "Top batch tokens shape  torch.Size([10, 64])\n",
      "The top 10 tokens are: \n",
      "  to to, to to to to toTo to\n",
      "They were found in the following batches of text [\"\\n<Bril2> geef me zelf nog 2 uur voor dit en wifi\\n<CasW> Nouja, bij mij ging 'ie dus weg, toen ik de proprietary drivers had geÃ¯nstalleerd en alles had geÃ¼pdate.\\n\", 'terjadi\\n\\nPolish: \\nI wszysko wydarzyło się w jednym momencie, to beznadziejne.\\nwiem że się martwisz, ale niedługo zadzwonię, obiecuję', \"\\n<Bril2> geef me zelf nog 2 uur voor dit en wifi\\n<CasW> Nouja, bij mij ging 'ie dus weg, toen ik de proprietary drivers had geÃ¯nstalleerd en alles had geÃ¼pdate.\\n\", ' to Europeans.\\nHe noted that fundamentalist Christians embrace theories of Armageddon and even\\nknow where it will take place:\"thirty-five miles southwest of Haifa,\" as their\\nmost popular books predict. Europeans, he did not need to add, find this sort\\nof thing bizarre. About Kagan', ' to the 20% that was already destroyed in the last 40 years. This makes Conservation International’s ambitious project all the more necessary.\\n\\n“If the world is to hit the 1.2°C or 2°C (34.16°F or 35.6°F) [degrees of warming', ' to compare the effects of the p300/CBP HAT and bromodomain inhibition to develop the most potent p300/CBP inhibitors.\\n\\nNMC, one of the most lethal solid tumors, responds poorly to chemo- and radiotherapy. Since the discovery of BET proteins in the tumorigenesis of NMC,', \" to prior physical abuse, indicate that appellant intentionally rather than\\r\\nrecklessly caused J.G's death.  We do not believe a rational jury would disregard such\\r\\nevidence and consider it not to be probative of appellant's intent to murder the child.  See\\r\\nYanez, 187 S.W\", ' to make mistakes. And I expect to learn from them.\\n\\nMy own background is military medical in nature. I am going to try to keep this as \"realistic\" as I possibly can. Player input is always appreciated, however, especially if you have ideas on other issues that may or will arise.\\n', ' is spoken   \\nO Mary canst thou feel the past   \\nAnd keep thy heart unbroken   \\nTo think how warm we loved and how   \\nThose hopes should blossom never   \\nTo think how we are parted now   \\nAnd parted oh for ever   \\nFare thee well\\n\\nThou', ' for success, and to better prepare them to navigate the highly competitive Vancouver real estate market. The real estate industry is evolving, and I will continue adding to and updating this series as necessary.\\n\\nThere are many factors to consider when searching for a home. Part of my job as your Realtor is to help']\n",
      "--------------------------------------------------\n",
      "LatentIDX: 91\n",
      "torch.Size([2, 500, 64, 2048])\n",
      "Sequence indices:  tensor([ 9, 36,  7, 42, 26,  5,  4, 62, 14, 25], device='cuda:0')\n",
      "Batch indices:  tensor([206, 206, 306, 369, 491, 305, 316, 369, 450, 305], device='cuda:0')\n",
      "Top batch tokens shape  torch.Size([10, 64])\n",
      "The top 10 tokens are: \n",
      " chchchchzasshchCRorph\n",
      "They were found in the following batches of text [' Revolution Politicks. The Career of Daniel Finch, Second Earl of Nottingham, 1647–1730 (Cambridge: Cambridge University Press, 1968).\\nHenry Horwitz, Finch,  Daniel, second earl of Nottingham and seventh earl of Winchilsea  (1647–1730), Oxford', ' Revolution Politicks. The Career of Daniel Finch, Second Earl of Nottingham, 1647–1730 (Cambridge: Cambridge University Press, 1968).\\nHenry Horwitz, Finch,  Daniel, second earl of Nottingham and seventh earl of Winchilsea  (1647–1730), Oxford', ' your pants with sparkly crotch charms\\n\\nMORE: Finally, someone’s made a silicone mask that turns your face into a vagina\\n\\nAdvertisement AdvertisementThis is a 1955 recording of T.S. Eliot reading ‘Ash Wednesday’ – strangely, it sounds much older, like an old phonograph', ' circumstances. In 1995, the Northern Territory Parliament passed an act allowing euthanasia and assisted suicide, and four people utilized that law to hasten death, all with guidance from euthanasia advocate Dr. Philip Nitschke. In 1997, the national parliament overturned the Northern Territory law, but Dr. Nitschke', 'önigsberg 70,000, Munich 65,000, while Magdeburg, Leipzig, Nuremberg and Linz each had some 60,000.\\n\\n###### Notes\\n\\n1. See, for example, the order from the 20th Motorized Infantry Div. of September 17, 1941,', \" (JP), Karen Strassman (U.S.)\\n\\nThe former leader of a bandit gang, before Endorph usurped her position. She seems to hate everyone, especially the poor. Later on, it's revealed that she shares a bit of history with Tricia. When Thuris commits suicide\", \"em and Hinh had become murderous. . . . Finally, we learned that Hinh was close to action; he had selected 26 October as the morning for an attack on the Presidential Palace. Hinh was counting heavily on Lt-Col Lan's special forces and on Captain Giai who was\", ' circumstances. In 1995, the Northern Territory Parliament passed an act allowing euthanasia and assisted suicide, and four people utilized that law to hasten death, all with guidance from euthanasia advocate Dr. Philip Nitschke. In 1997, the national parliament overturned the Northern Territory law, but Dr. Nitschke', ')\\n); \\nALTER TABLE foobar AUTO_INCREMENT=10;\\n\\nINSERT INTO foobar(moobar) values (\"abc\");\\nINSERT INTO foobar(moobar) values (\"def\");\\nINSERT INTO foobar(moobar) values (\"xyz\");\\n\\nselect * from', \" (JP), Karen Strassman (U.S.)\\n\\nThe former leader of a bandit gang, before Endorph usurped her position. She seems to hate everyone, especially the poor. Later on, it's revealed that she shares a bit of history with Tricia. When Thuris commits suicide\"]\n",
      "--------------------------------------------------\n",
      "LatentIDX: 93\n",
      "torch.Size([2, 500, 64, 2048])\n",
      "Sequence indices:  tensor([57, 20, 27, 42, 43,  5, 14, 27, 51, 48], device='cuda:0')\n",
      "Batch indices:  tensor([ 80, 454, 405, 374, 201, 326, 338, 400, 259, 186], device='cuda:0')\n",
      "Top batch tokens shape  torch.Size([10, 64])\n",
      "The top 10 tokens are: \n",
      " of ofofe ofofssaf of\n",
      "They were found in the following batches of text [' to Europeans.\\nHe noted that fundamentalist Christians embrace theories of Armageddon and even\\nknow where it will take place:\"thirty-five miles southwest of Haifa,\" as their\\nmost popular books predict. Europeans, he did not need to add, find this sort\\nof thing bizarre. About Kagan', ' part of Vista is available only in Vista\\'s most expensive version).\\n\\nConnectivity: Whatever kind of device you want to connect to, eg using Wifi or Bluetooth, Vista will make it easier; and a new \"meeting room\" allows users to share a virtual workspace between computers in the same area.\\n', \" fell, entered the dark\\nouter room.\\n\\n'Well, lads,' his loud bass resounded through the low-roofed room\\ndrowning all the other voices, 'I'm going with you. You'll watch for\\nChechens and I for boars!'\\n\\n\\n\\n\\nChapter VIII\\n\\n\", \" construire des édifices stables : quand on bâtit le Temple de Jérusalem, « les pierres furent amenées toutes telles qu'elles devaient être, de sorte que, en bâtissant la maison, on n'entendît ni marteau\", 'éraphîta_ , the mirror is used to describe \"Le Voyant\" and in the Preface to _La Peau de chagrin_ , the ideal author \"must have within himself some kind of concentric mirror in which . . . the universe is reflected.\" The figuration of creative imagination as', \" and dedicated staff capable\\nof providing immediate answers to enquiries and technical questions.\\ufeffEve Irvine sits down with Margrethe Vestager, the woman who has angered the US and Ireland by punishing Apple.\\n\\nAdvertising\\n\\nBy slapping a record bill on the world's most profitable\", ' on as the bicyclists sped down the roadway, their\\nsafeties gleaming brightly in the sunlight. Everybody was in fine\\ncondition, and the race promised to prove a spirited one. Each racer\\nwore a blue sweater with the letters P. H. on the breast.\\n\\n', ' in the 2011 presidential and general electoral campaigns.\\n\\nAND when asked whether or not he would go to Mongu for this year’s Kuomboka traditional ceremony, given that the treason case that saw him and five others spend slightly over four months in prison emanated from there, Hichilema said he would', \"\\n\\nThe famous Egyptian geographer Ptolemy fairly accurately locates the islands' position, tracing an imaginary meridian line marking the end of the known world through El Hierro.\\n\\n1312\\n\\nThe Genoese explorer and seafarer Lanzarotto Malocello lands on the fart\", 'type=\"fig\"} *a*). Data acquisitions performed by the same user (*i.e.* with the same experimental logging) are divided into sessions according to the date when experiments were (or are) performed. There are currently two main types of experiments carried out at synchrotron-based BioSAXS facilities: data acquisition']\n",
      "--------------------------------------------------\n",
      "LatentIDX: 95\n",
      "torch.Size([2, 500, 64, 2048])\n",
      "Sequence indices:  tensor([45, 15, 63, 47, 57, 12, 48,  2, 34, 32], device='cuda:0')\n",
      "Batch indices:  tensor([153, 453, 453, 453, 434, 442, 430, 339, 433, 306], device='cuda:0')\n",
      "Top batch tokens shape  torch.Size([10, 64])\n",
      "The top 10 tokens are: \n",
      "  Credit credit credit creditADVERTISEMENTredit EditUTERS debtAdvertisement\n",
      "They were found in the following batches of text [\"'s clinics rotate in from other cities such as El Paso or Alpine. Rice settled down in Presidio after working for years in Guatemala. He says the problems Presidio faces in rural Texas aren't so different. Credit: Matt Lankes/CPI\\n\\nFor emergency medical care, where a long\", ' no reason to be afraid in Lowell. After all, it is only credit cards reporting of what you already know in Lowell all about. It should not come as a surprise in Lowell OH that you either have earned a great credit score in Lowell and rating or definitely have earned a negative one! A credit', ' no reason to be afraid in Lowell. After all, it is only credit cards reporting of what you already know in Lowell all about. It should not come as a surprise in Lowell OH that you either have earned a great credit score in Lowell and rating or definitely have earned a negative one! A credit', ' no reason to be afraid in Lowell. After all, it is only credit cards reporting of what you already know in Lowell all about. It should not come as a surprise in Lowell OH that you either have earned a great credit score in Lowell and rating or definitely have earned a negative one! A credit', ' line for Royal Robbins worldwide, and for the profitability of Royal Robbins. Millenacker will also serve on the Board of Directors of BRS Outdoor Holdings, LLC, the controlling entity of Royal Robbins and Evolv Sports & Designs, LLC.\\n\\nADVERTISEMENT\\n\\nThanks for watching!', ' questions concerning defendant\\'s infraction of prison rules sought to discredit the defendant by showing that the defendant had falsely characterized himself. *658 The purpose of the prosecutor\\'s examination enumerated above went to the defendant\\'s credibility.\"\\nWe feel, however, that a man\\'s reputation, especially where he is also the criminal defendant-', ';&gt;&gt; Move to open Start / All programs/wmm-&gt; Task Pane <br> 1. Import video editing application streaming remotes **- VCAM, importing images and music <br> 2. Edit-drag and drop video files-&gt; timeline &amp; enhance', '\\nREUTERS/Mohammed Salem\\n\\nView more photo galleries — Follow NP Photos on Twitter\\n\\nA group of Palestinian youngsters aged 12 to 23, from Khan Younis in the southern Gaza Strip, showcased their gravity-defying stunts for the camera. They practice in cemeteries and in', ', made an agreement with her and then breached that agreement.\\nSee 2010 WL 3442212, at *4. She further alleged that, in efforts to collect a debt,\\nCalstar lied to her in phone calls and writings directed at Texas. Id. The court of\\nappeals determined that these pleadings alleged', ' your pants with sparkly crotch charms\\n\\nMORE: Finally, someone’s made a silicone mask that turns your face into a vagina\\n\\nAdvertisement AdvertisementThis is a 1955 recording of T.S. Eliot reading ‘Ash Wednesday’ – strangely, it sounds much older, like an old phonograph']\n",
      "--------------------------------------------------\n",
      "LatentIDX: 97\n",
      "torch.Size([2, 500, 64, 2048])\n",
      "Sequence indices:  tensor([ 9, 19, 56, 27, 43, 47, 54, 25, 44, 19], device='cuda:0')\n",
      "Batch indices:  tensor([248, 192, 372, 297, 261, 381, 330, 275, 261, 432], device='cuda:0')\n",
      "Top batch tokens shape  torch.Size([10, 64])\n",
      "The top 10 tokens are: \n",
      "  options option option alternatives factors way ways suggestions to info\n",
      "They were found in the following batches of text ['> Joker_-_: but there are several options\\n<abhi_nav> yah its ok galioin\\n<galion> where is the rite channel\\n<stracqua> !list\\n<ubottu> This is not a file sharing channel (or network); be sure to read the channel', \" roll option.\\n\\nI'm gonna have to hog the glory on this one. The die option was my idea. Glad you like it!\\n\\nAs for clues or number of clues, this part will probably involve a little bit of story writing. Your MOC could be as literal as finding a map, or\", '\\n+ *\\n+ *\\n+ * ALTERNATIVELY, this software may be distributed under the terms of the\\n+ * GNU General Public License (\"GPL\") as published by the Free Software\\n+ * Foundation, either version 2 of that License or (at your option) any\\n+ * later version', \" lives. I'm not sure that squatting on land with non-existent sanitary conditions is the right approach, but what are the alternatives?\\nNow for the people that have chosen to drop out of society - and there are more than a few at CTN - survival is on them, and they should get nothing\", ' for success, and to better prepare them to navigate the highly competitive Vancouver real estate market. The real estate industry is evolving, and I will continue adding to and updating this series as necessary.\\n\\nThere are many factors to consider when searching for a home. Part of my job as your Realtor is to help', ' of a shock for you, but it will all become clear soon... well, at least a portion of it will be.\" She looked directly at Elle. \"I\\'m sorry I had to take away your memories. There was no other way, you see. You were going down the wrong path. And you were turning', \" dE\\\\, {\\\\bf G}(E,r,r'),$ calculated in two different ways, generates a resolution of the identity. This question of a representation and a contour is the subject of Section II, the main part of our argument. Additional considerations on the two ways of calculating this integral make the subject of Section\", \"18]\\\\]. An intervention that appears more effective in a better-off population may widen the disparity gap, and there are strong suggestions that individually-focussed 'downstream' interventions, such as SMS, can increase disparity \\\\[[@CR17], [@CR19], [@CR20]\\\\]. Specific targeting of disadvantaged groups is\", ' for success, and to better prepare them to navigate the highly competitive Vancouver real estate market. The real estate industry is evolving, and I will continue adding to and updating this series as necessary.\\n\\nThere are many factors to consider when searching for a home. Part of my job as your Realtor is to help', \" the trouble there\\n<hazmat> niemeyer, no worries, thanks for the info, i'll see if i can run the tests with that.. the remote version of launchpad.net/ensemble/go/schema is more recent than the one in the branch, so it gets undefined symbols\"]\n"
     ]
    }
   ],
   "source": [
    "median_latents = indices_0[10:50]\n",
    "for latent in median_latents:\n",
    "    analyse_max_act_tok_batched(latent, batch_size = 256)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91057c84-0122-48d9-9891-46c8e99a28b5",
   "metadata": {},
   "source": [
    "## Top Logits Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15deef12-844f-45f8-bf84-de50078e9eb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_top_logits(\n",
    "    model,\n",
    "    crosscoder,\n",
    "    latent_idx,\n",
    "    k,\n",
    "    n_models\n",
    "):\n",
    "    \"\"\"\n",
    "    Displays the top & bottom logits for a particular latent.\n",
    "    \"\"\"\n",
    "    print('-' * 50)\n",
    "    print(f'Now analyzing latent: {latent_idx.item()}')\n",
    "    for model_no in range(n_models):\n",
    "        logits = crosscoder.W_dec[latent_idx, model_no] @ model.W_U\n",
    "    \n",
    "        pos_logits, pos_token_ids = logits.topk(k)\n",
    "        pos_tokens = model.to_str_tokens(pos_token_ids)\n",
    "        neg_logits, neg_token_ids = logits.topk(k, largest=False)\n",
    "        neg_tokens = model.to_str_tokens(neg_token_ids)\n",
    "        print(\n",
    "            tabulate(\n",
    "                zip(map(repr, neg_tokens), neg_logits, map(repr, pos_tokens), pos_logits),\n",
    "                headers = [f\"Bottom tokens for model: {model_no}\", \"Value\", \"Top tokens\", \"Value\"],\n",
    "                tablefmt=\"simple_outline\",\n",
    "                stralign=\"right\",\n",
    "                numalign=\"left\",\n",
    "                floatfmt=\"+.3f\",\n",
    "            )\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1ec83fd-d0ab-40b6-994b-c2d3f6f50c0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "cross_coder.W_dec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d39d6475-88cd-4808-8b08-ef499f0d390a",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# mask = (relative_norms > 0.49) & (relative_norms < 0.51)\n",
    "mask = relative_norms < 0.1\n",
    "indices_0 = mask.nonzero().squeeze()\n",
    "median_latents = indices_0[:10]\n",
    "\n",
    "from tabulate import tabulate\n",
    "for latent in median_latents:\n",
    "    show_top_logits(pythia1, cross_coder, latent, 10, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b952ca93-7035-48b9-8311-f2e00d5c72ce",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# mask = (relative_norms > 0.49) & (relative_norms < 0.51)\n",
    "mask = relative_norms > 0.95\n",
    "indices_0 = mask.nonzero().squeeze()\n",
    "median_latents = indices_0[:10]\n",
    "\n",
    "from tabulate import tabulate\n",
    "for latent in median_latents:\n",
    "    show_top_logits(pythia1, cross_coder, latent, 10, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aa9000f4-ad23-4013-a35a-9d504cc43633",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "mask = (relative_norms > 0.49) & (relative_norms < 0.51)\n",
    "indices_0 = mask.nonzero().squeeze()\n",
    "median_latents = indices_0[:10]\n",
    "\n",
    "from tabulate import tabulate\n",
    "for latent in median_latents:\n",
    "    show_top_logits(pythia1, cross_coder, latent, 10, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "06bba0fd-cda9-46e6-b51f-6820039cc7b0",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "def untokenize_top_indices(tokenizer, tokens, top_indices):\n",
    "    \"\"\"\n",
    "    Given a tokenizer, a batch of tokens, and top indices, return the untokenized text.\n",
    "    \n",
    "    tokenizer: The tokenizer used for tokenization.\n",
    "    tokens: The original tokenized input data.\n",
    "    top_indices: The indices of the tokens to untokenize.\n",
    "    \"\"\"\n",
    "    # Extract the tokens corresponding to the top indices\n",
    "    top_tokens = tokens[top_indices]\n",
    "    \n",
    "    # Convert tokens to text\n",
    "    text = tokenizer.decode(top_tokens, skip_special_tokens=True)\n",
    "    \n",
    "    return text"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
